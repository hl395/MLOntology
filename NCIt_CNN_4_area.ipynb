{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\MLOntology\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "d:\\Anaconda3\\envs\\MLOntology\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import multiprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variabls\n",
    "\n",
    "directory_path =  \"D:/MLOntology/NCIt/\"\n",
    "data_path = directory_path + \"data/area/\"\n",
    "vector_model_path = directory_path +\"vectorModel/\"\n",
    "cnn_model_path = directory_path +\"cnnModel/area/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_trailing_number(s):\n",
    "    m = re.search(r'\\d+$', s)\n",
    "    return m.group() if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prostate carcinoma\n",
      "stage ia esophageal cancer ajcc v7\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#read class label file\n",
    "#create mapping from id to labels  \n",
    "#iso-8859-1 , encoding=\"iso-8859-1\"\n",
    "conceptLabelDict={}\n",
    "errors=[]\n",
    "\n",
    "def read_label(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                conceptID = get_trailing_number(splitted[1])\n",
    "                conceptLabelDict[conceptID] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "label_file = data_path + \"ontClassLabels_owl_ncit.txt\"\n",
    "read_label(label_file)\n",
    "print(conceptLabelDict[\"4863\"])\n",
    "print(conceptLabelDict[\"115117\"])\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['4861', '7318', 1], ['87152', '87150', 1], ['87153', '140032', 1], ['87154', '87153', 1], ['87155', '87153', 1]]\n",
      "16533\n"
     ]
    }
   ],
   "source": [
    "conceptPairDict={}\n",
    "errors=[]\n",
    "conceptPairList=[]\n",
    "\n",
    "def read_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                childID = get_trailing_number(splitted[1])\n",
    "                parentID = get_trailing_number(splitted[2].replace(\"\\r\\n\", \"\"))\n",
    "                conceptPairList.append([childID, parentID , 1])\n",
    "#                 conceptPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "pair_file = data_path + \"ontHierarchy_owl_ncit.txt\"\n",
    "read_pair(pair_file)\n",
    "\n",
    "checkpairs = conceptPairList[10:15]\n",
    "print(checkpairs)\n",
    "print(len(conceptPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['86053', '88414', 0], ['8784', '7917', 0], ['141358', '141347', 0], ['141358', '141353', 0], ['141358', '141350', 0]]\n",
      "10574\n"
     ]
    }
   ],
   "source": [
    "conceptNotPairDict={}\n",
    "conceptNotPairList=[]\n",
    "\n",
    "def read_not_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==2:\n",
    "                childID = get_trailing_number(splitted[0])\n",
    "                notparentID = get_trailing_number(splitted[1].replace(\"\\r\\n\", \"\"))\n",
    "                conceptNotPairList.append([childID, notparentID, 0])\n",
    "#                 conceptNotPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "notPair_file = data_path + \"taxNotPairs_owl_ncit.txt\"\n",
    "read_not_pair(notPair_file)\n",
    "\n",
    "\n",
    "first2pairs =conceptNotPairList[10:15]\n",
    "print(first2pairs)\n",
    "print(len(conceptNotPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5959\n"
     ]
    }
   ],
   "source": [
    "if len(conceptPairList) < len(conceptNotPairList):\n",
    "    # In-place shuffle\n",
    "    random.shuffle(conceptNotPairList)\n",
    "    leftPairList = conceptNotPairList[len(conceptPairList):]\n",
    "    conceptNotPairList = conceptNotPairList[:len(conceptPairList)]\n",
    "else:\n",
    "    # Updown sampling negative samples\n",
    "    random.shuffle(conceptNotPairList)\n",
    "    duplicatedList = conceptNotPairList[:len(conceptPairList) - len(conceptNotPairList)]\n",
    "    print(len(duplicatedList))\n",
    "    random.shuffle(conceptNotPairList)\n",
    "    conceptNotPairList.extend(duplicatedList)\n",
    "\n",
    "assert len(conceptPairList) == len(conceptNotPairList), \"Mistmatch in Positive & Negative samples!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('40335', 0.6330592632293701),\n",
      " ('3841', 0.6313962936401367),\n",
      " ('99086', 0.6313452124595642),\n",
      " ('4234', 0.626358687877655),\n",
      " ('3944', 0.6225557923316956),\n",
      " ('66754', 0.6132376194000244),\n",
      " ('40331', 0.6099046468734741),\n",
      " ('40330', 0.6097063422203064),\n",
      " ('4486', 0.606782078742981),\n",
      " ('6555', 0.6034256219863892)]\n"
     ]
    }
   ],
   "source": [
    "#  PV-DBOW\n",
    "vector_model_file_0 = vector_model_path + \"model0\"\n",
    "\n",
    "vector_model_0 = gensim.models.Doc2Vec.load(vector_model_file_0)\n",
    "\n",
    "inferred_vector_0= vector_model_0.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(vector_model_0.docvecs.most_similar([inferred_vector_0], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3801', 0.5686438083648682),\n",
      " ('7387', 0.534963071346283),\n",
      " ('7158', 0.5242812633514404),\n",
      " ('7087', 0.5191395282745361),\n",
      " ('66803', 0.5119830965995789),\n",
      " ('6409', 0.5109609365463257),\n",
      " ('136619', 0.49623847007751465),\n",
      " ('3191', 0.495505690574646),\n",
      " ('8502', 0.494106262922287),\n",
      " ('4412', 0.47189944982528687)]\n"
     ]
    }
   ],
   "source": [
    "# PV-DM seems better??\n",
    "vector_model_file = vector_model_path + \"model1\"\n",
    "\n",
    "vector_model = gensim.models.Doc2Vec.load(vector_model_file)\n",
    "\n",
    "inferred_vector = vector_model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(vector_model.docvecs.most_similar([inferred_vector], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.12278104e-01,  6.86569437e-02, -1.24297813e-01,  2.23319721e-03,\n",
       "        3.53817977e-02, -1.57626167e-01,  9.55056846e-02, -6.64356165e-03,\n",
       "        5.35981506e-02, -1.73459724e-02,  6.37169927e-02,  2.59661172e-02,\n",
       "       -3.96479517e-02,  5.85773867e-03,  1.54108971e-01, -2.09995508e-02,\n",
       "        3.63172963e-02,  6.07878082e-02,  1.01029929e-02,  8.57971609e-02,\n",
       "        9.79144797e-02, -1.28200814e-01, -7.13667497e-02, -3.62776853e-02,\n",
       "       -8.94697011e-02, -1.46133035e-01,  6.03192374e-02, -2.75994018e-02,\n",
       "       -1.33479005e-02, -1.47091411e-02, -5.71595430e-02, -3.07746418e-02,\n",
       "       -3.63636203e-02, -1.42001789e-02,  8.44926573e-03,  1.99984163e-01,\n",
       "        2.32352003e-01,  1.72088407e-02,  3.46314073e-01, -1.67805614e-04,\n",
       "        2.23070253e-02, -2.78270878e-02, -2.81399842e-02, -4.84447554e-02,\n",
       "        6.20759241e-02,  9.16333520e-04,  3.92444283e-02,  4.46287617e-02,\n",
       "       -9.79690775e-02,  3.11729629e-02, -2.01291181e-02,  6.88659623e-02,\n",
       "        5.21936752e-02,  2.84125730e-02,  9.16770622e-02,  1.06031291e-01,\n",
       "        3.64111625e-02,  2.42925495e-01,  5.42081036e-02, -3.10700340e-03,\n",
       "        2.85160486e-02,  5.56676686e-02,  2.55753130e-01, -3.20493169e-02,\n",
       "       -1.81914698e-02,  6.78487122e-02, -6.80873170e-02, -4.97266762e-02,\n",
       "       -9.30923074e-02, -3.70616615e-02, -3.33507136e-02, -8.35170746e-02,\n",
       "       -8.74761268e-02,  7.66466483e-02,  1.57033980e-01, -1.96643695e-01,\n",
       "        1.21560335e-01,  1.04021333e-01, -1.65873632e-01, -1.83580015e-02,\n",
       "        1.07067406e-01, -8.94410349e-03,  1.40662625e-01,  1.83419719e-01,\n",
       "        4.31755260e-02,  1.17201954e-02,  1.02126546e-01, -2.31964752e-01,\n",
       "        1.50453746e-02, -9.58114564e-02, -1.05506502e-01, -1.66527014e-02,\n",
       "       -3.40961032e-02,  2.00673752e-02, -2.22009216e-02,  1.01638418e-02,\n",
       "       -3.88681702e-02, -3.18282321e-02,  5.34584105e-04, -5.69385253e-02,\n",
       "        3.07964650e-03,  2.39626411e-03, -4.84261848e-02,  6.37608096e-02,\n",
       "        1.71928972e-01,  5.76475039e-02, -2.44507287e-02,  6.59685070e-03,\n",
       "        7.77475461e-02, -3.18709239e-02, -2.10209694e-02,  1.19519643e-01,\n",
       "        9.33007076e-02, -5.28470501e-02, -2.06025448e-02,  4.40602675e-02,\n",
       "        8.35411176e-02,  6.12104759e-02,  2.57603452e-02, -8.99347886e-02,\n",
       "       -5.84283546e-02,  2.82032397e-02, -4.50174361e-02, -4.55523543e-02,\n",
       "       -3.82486768e-02,  6.58656284e-02, -1.23088144e-01, -1.14243202e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_model.docvecs['7918']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def readFromPairList(id_pair_list, id_notPair_list):\n",
    "    pair_list = id_pair_list + id_notPair_list\n",
    "    random.shuffle(pair_list)\n",
    "    idpairs_list =[]\n",
    "    label_list =[]\n",
    "    for i, line in enumerate(pair_list):      \n",
    "        idpairs_list.append([line[0], line[1]])\n",
    "        label_list.append(line[2])\n",
    "    return idpairs_list, label_list\n",
    "\n",
    "idpairs_list, label_list= readFromPairList(conceptPairList, conceptNotPairList)\n",
    "\n",
    "print(label_list[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['137669', '137662'], ['133162', '133158'], ['65179', '65173'], ['134920', '134930'], ['4915', '6990'], ['7830', '128106'], ['3350', '4432'], ['6733', '5770'], ['67557', '133074'], ['27858', '27856'], ['133403', '133401'], ['139992', '139988'], ['133733', '9330'], ['134748', '134745'], ['88096', '6653'], ['9011', '4286'], ['8694', '7055'], ['129439', '3222'], ['6321', '9206'], ['5637', '7706']]\n",
      "[['3459', '27951'], ['134304', '134301'], ['115042', '87813'], ['40306', '40305'], ['40393', '8964'], ['8573', '8956'], ['9366', '5892'], ['9479', '7628'], ['4341', '7056'], ['27272', '27258'], ['6736', '5769'], ['4258', '3359'], ['140374', '140367'], ['139814', '139805'], ['150092', '61574'], ['4670', '9335'], ['27857', '7189'], ['6547', '6554'], ['9352', '7894'], ['41620', '35417']]\n",
      "[0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1]\n",
      "[0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(idpairs_list, label_list, test_size = 0.2, shuffle= True)\n",
    "print(X_train[:20])\n",
    "print(X_validation[:20])\n",
    "print(y_train[:20])\n",
    "print(y_validation[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVectorFromModel(concept_id, conceptLabelDict, model):\n",
    "    if concept_id in model.docvecs:\n",
    "        concept_vector= model.docvecs[concept_id]\n",
    "    else:\n",
    "        print(\"%s not found, get inferred vector \"%(concept_id))\n",
    "        concept_label = conceptLabelDict[concept_id]\n",
    "        concept_vector= model.infer_vector(concept_label.split())\n",
    "    return concept_vector\n",
    "\n",
    "def getVector(line, conceptLabelDict, model):        \n",
    "    a = getVectorFromModel(line[0], conceptLabelDict, model)\n",
    "    b = getVectorFromModel(line[1], conceptLabelDict, model)\n",
    "    c = np.array((a, b))\n",
    "    c = c.T \n",
    "#     c = np.expand_dims(c, axis=2)\n",
    "#     print(c.shape)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackVector(vector1, vector2):\n",
    "    return np.concatenate((vector1, vector2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=2 \n",
    "\n",
    "def get_batches(x_samples, y_samples, batch_size=64):\n",
    "    samples = list(zip(x_samples, y_samples))\n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    shuffle(samples)\n",
    "    for offset in range(0, num_samples, batch_size):\n",
    "        batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "        X_samples = []\n",
    "        Y_samples= []\n",
    "        for batch_sample in batch_samples:\n",
    "            pair_list = batch_sample[0]\n",
    "#             data_vector= getVector(pair_list, conceptLabelDict, vector_model)\n",
    "            pvdm_vector = getVector(pair_list, conceptLabelDict, vector_model)\n",
    "            pvdbow_vector = getVector(pair_list, conceptLabelDict, vector_model_0)\n",
    "            data_vector = stackVector(pvdm_vector, pvdbow_vector)\n",
    "#             print(data_vector.shape)\n",
    "            X_samples.append(data_vector)\n",
    "            class_label = batch_sample[1] \n",
    "            Y_samples.append(class_label)\n",
    "\n",
    "        X_samples = np.array(X_samples).astype('float32')\n",
    "        Y_samples = np.eye(n_classes)[Y_samples]\n",
    "#             print('one batch ready')\n",
    "        yield shuffle(X_samples, Y_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_batches(X, y, batch_size = 100):\n",
    "    \"\"\" Return a generator for batches \"\"\"\n",
    "    n_batches = len(X) // batch_size\n",
    "    X, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over batches and yield\n",
    "    for b in range(0, len(X), batch_size):\n",
    "        yield X[b:b+batch_size], y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-ba0f9633d9c4>:58: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "# build the model??\n",
    "batch_size = 2000       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001\n",
    "epochs = 1000\n",
    "lambda_loss_amount = 0.001\n",
    "\n",
    "n_classes = 2\n",
    "n_channels = 4\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')\n",
    "\n",
    "    \n",
    "with graph.as_default():\n",
    "    # (batch, 128, 2) --> (batch, 64, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 64, 18) --> (batch, 32, 36)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=36, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 32, 36) --> (batch, 16, 72)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=72, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 16, 72) --> (batch, 8, 144)\n",
    "    conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=144, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=2, strides=2, padding='same')\n",
    "\n",
    "\n",
    "with graph.as_default():\n",
    "    # Flatten and add dropout\n",
    "    flat = tf.reshape(max_pool_4, (-1, 8*144))\n",
    "    flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat, n_classes)\n",
    "    # Loss, optimizer and evaluation\n",
    "    l2 = lambda_loss_amount * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()) \n",
    "    # L2 loss prevents this overkill neural network to overfit the data\n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))+l2\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists( cnn_model_path + 'checkpoints-cnn') == False):\n",
    "    os.makedirs( cnn_model_path + 'checkpoints-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/1000 Iteration: 50 Train loss: 0.762267 Train acc: 0.575500\n",
      "Epoch: 7/1000 Iteration: 100 Train loss: 0.735291 Train acc: 0.686000\n",
      "Epoch: 7/1000 Iteration: 100 Validation loss: 0.732402 Validation acc: 0.715028\n",
      "Epoch: 10/1000 Iteration: 150 Train loss: 0.684022 Train acc: 0.717000\n",
      "Epoch: 14/1000 Iteration: 200 Train loss: 0.614498 Train acc: 0.744500\n",
      "Epoch: 14/1000 Iteration: 200 Validation loss: 0.610910 Validation acc: 0.761300\n",
      "Epoch: 17/1000 Iteration: 250 Train loss: 0.571168 Train acc: 0.759500\n",
      "Epoch: 21/1000 Iteration: 300 Train loss: 0.536468 Train acc: 0.775000\n",
      "Epoch: 21/1000 Iteration: 300 Validation loss: 0.522252 Validation acc: 0.790733\n",
      "Epoch: 24/1000 Iteration: 350 Train loss: 0.495178 Train acc: 0.805310\n",
      "Epoch: 28/1000 Iteration: 400 Train loss: 0.489128 Train acc: 0.802500\n",
      "Epoch: 28/1000 Iteration: 400 Validation loss: 0.491383 Validation acc: 0.808055\n",
      "Epoch: 32/1000 Iteration: 450 Train loss: 0.484170 Train acc: 0.819500\n",
      "Epoch: 35/1000 Iteration: 500 Train loss: 0.484047 Train acc: 0.817000\n",
      "Epoch: 35/1000 Iteration: 500 Validation loss: 0.473279 Validation acc: 0.819183\n",
      "Epoch: 39/1000 Iteration: 550 Train loss: 0.464473 Train acc: 0.822500\n",
      "Epoch: 42/1000 Iteration: 600 Train loss: 0.481705 Train acc: 0.817000\n",
      "Epoch: 42/1000 Iteration: 600 Validation loss: 0.459267 Validation acc: 0.824405\n",
      "Epoch: 46/1000 Iteration: 650 Train loss: 0.468095 Train acc: 0.819500\n",
      "Epoch: 49/1000 Iteration: 700 Train loss: 0.426114 Train acc: 0.851770\n",
      "Epoch: 49/1000 Iteration: 700 Validation loss: 0.447693 Validation acc: 0.827780\n",
      "Epoch: 53/1000 Iteration: 750 Train loss: 0.444365 Train acc: 0.826500\n",
      "Epoch: 57/1000 Iteration: 800 Train loss: 0.440042 Train acc: 0.841500\n",
      "Epoch: 57/1000 Iteration: 800 Validation loss: 0.438645 Validation acc: 0.835441\n",
      "Epoch: 60/1000 Iteration: 850 Train loss: 0.438568 Train acc: 0.845500\n",
      "Epoch: 64/1000 Iteration: 900 Train loss: 0.427727 Train acc: 0.843500\n",
      "Epoch: 64/1000 Iteration: 900 Validation loss: 0.428635 Validation acc: 0.839916\n",
      "Epoch: 67/1000 Iteration: 950 Train loss: 0.447471 Train acc: 0.838000\n",
      "Epoch: 71/1000 Iteration: 1000 Train loss: 0.431985 Train acc: 0.834000\n",
      "Epoch: 71/1000 Iteration: 1000 Validation loss: 0.420809 Validation acc: 0.844855\n",
      "Epoch: 74/1000 Iteration: 1050 Train loss: 0.385850 Train acc: 0.873894\n",
      "Epoch: 78/1000 Iteration: 1100 Train loss: 0.415973 Train acc: 0.841000\n",
      "Epoch: 78/1000 Iteration: 1100 Validation loss: 0.413897 Validation acc: 0.847327\n",
      "Epoch: 82/1000 Iteration: 1150 Train loss: 0.409560 Train acc: 0.853500\n",
      "Epoch: 85/1000 Iteration: 1200 Train loss: 0.413892 Train acc: 0.851000\n",
      "Epoch: 85/1000 Iteration: 1200 Validation loss: 0.407341 Validation acc: 0.852987\n",
      "Epoch: 89/1000 Iteration: 1250 Train loss: 0.405095 Train acc: 0.849500\n",
      "Epoch: 92/1000 Iteration: 1300 Train loss: 0.430379 Train acc: 0.842000\n",
      "Epoch: 92/1000 Iteration: 1300 Validation loss: 0.401894 Validation acc: 0.857838\n",
      "Epoch: 96/1000 Iteration: 1350 Train loss: 0.409975 Train acc: 0.844000\n",
      "Epoch: 99/1000 Iteration: 1400 Train loss: 0.368599 Train acc: 0.876106\n",
      "Epoch: 99/1000 Iteration: 1400 Validation loss: 0.396585 Validation acc: 0.858362\n",
      "Epoch: 103/1000 Iteration: 1450 Train loss: 0.404340 Train acc: 0.843000\n",
      "Epoch: 107/1000 Iteration: 1500 Train loss: 0.389121 Train acc: 0.860000\n",
      "Epoch: 107/1000 Iteration: 1500 Validation loss: 0.392545 Validation acc: 0.857859\n",
      "Epoch: 110/1000 Iteration: 1550 Train loss: 0.397299 Train acc: 0.854500\n",
      "Epoch: 114/1000 Iteration: 1600 Train loss: 0.385393 Train acc: 0.856500\n",
      "Epoch: 114/1000 Iteration: 1600 Validation loss: 0.387106 Validation acc: 0.863366\n",
      "Epoch: 117/1000 Iteration: 1650 Train loss: 0.404150 Train acc: 0.853000\n",
      "Epoch: 121/1000 Iteration: 1700 Train loss: 0.391006 Train acc: 0.858000\n",
      "Epoch: 121/1000 Iteration: 1700 Validation loss: 0.383221 Validation acc: 0.864055\n",
      "Epoch: 124/1000 Iteration: 1750 Train loss: 0.340103 Train acc: 0.893805\n",
      "Epoch: 128/1000 Iteration: 1800 Train loss: 0.385598 Train acc: 0.849000\n",
      "Epoch: 128/1000 Iteration: 1800 Validation loss: 0.379614 Validation acc: 0.863052\n",
      "Epoch: 132/1000 Iteration: 1850 Train loss: 0.372278 Train acc: 0.866000\n",
      "Epoch: 135/1000 Iteration: 1900 Train loss: 0.394304 Train acc: 0.853500\n",
      "Epoch: 135/1000 Iteration: 1900 Validation loss: 0.375945 Validation acc: 0.865427\n",
      "Epoch: 139/1000 Iteration: 1950 Train loss: 0.370833 Train acc: 0.865500\n",
      "Epoch: 142/1000 Iteration: 2000 Train loss: 0.392970 Train acc: 0.867000\n",
      "Epoch: 142/1000 Iteration: 2000 Validation loss: 0.372877 Validation acc: 0.868055\n",
      "Epoch: 146/1000 Iteration: 2050 Train loss: 0.382549 Train acc: 0.854500\n",
      "Epoch: 149/1000 Iteration: 2100 Train loss: 0.329490 Train acc: 0.900442\n",
      "Epoch: 149/1000 Iteration: 2100 Validation loss: 0.369637 Validation acc: 0.869148\n",
      "Epoch: 153/1000 Iteration: 2150 Train loss: 0.368928 Train acc: 0.863500\n",
      "Epoch: 157/1000 Iteration: 2200 Train loss: 0.360603 Train acc: 0.872500\n",
      "Epoch: 157/1000 Iteration: 2200 Validation loss: 0.369291 Validation acc: 0.867830\n",
      "Epoch: 160/1000 Iteration: 2250 Train loss: 0.377487 Train acc: 0.864000\n",
      "Epoch: 164/1000 Iteration: 2300 Train loss: 0.358440 Train acc: 0.874500\n",
      "Epoch: 164/1000 Iteration: 2300 Validation loss: 0.364056 Validation acc: 0.872180\n",
      "Epoch: 167/1000 Iteration: 2350 Train loss: 0.384815 Train acc: 0.867500\n",
      "Epoch: 171/1000 Iteration: 2400 Train loss: 0.367508 Train acc: 0.870500\n",
      "Epoch: 171/1000 Iteration: 2400 Validation loss: 0.361947 Validation acc: 0.873777\n",
      "Epoch: 174/1000 Iteration: 2450 Train loss: 0.303146 Train acc: 0.918142\n",
      "Epoch: 178/1000 Iteration: 2500 Train loss: 0.361750 Train acc: 0.860000\n",
      "Epoch: 178/1000 Iteration: 2500 Validation loss: 0.359235 Validation acc: 0.874745\n",
      "Epoch: 182/1000 Iteration: 2550 Train loss: 0.354443 Train acc: 0.871500\n",
      "Epoch: 185/1000 Iteration: 2600 Train loss: 0.368392 Train acc: 0.866000\n",
      "Epoch: 185/1000 Iteration: 2600 Validation loss: 0.357861 Validation acc: 0.875055\n",
      "Epoch: 189/1000 Iteration: 2650 Train loss: 0.349345 Train acc: 0.884500\n",
      "Epoch: 192/1000 Iteration: 2700 Train loss: 0.371545 Train acc: 0.869000\n",
      "Epoch: 192/1000 Iteration: 2700 Validation loss: 0.355017 Validation acc: 0.878091\n",
      "Epoch: 196/1000 Iteration: 2750 Train loss: 0.363829 Train acc: 0.877500\n",
      "Epoch: 199/1000 Iteration: 2800 Train loss: 0.290502 Train acc: 0.911504\n",
      "Epoch: 199/1000 Iteration: 2800 Validation loss: 0.353139 Validation acc: 0.879373\n",
      "Epoch: 203/1000 Iteration: 2850 Train loss: 0.349711 Train acc: 0.865500\n",
      "Epoch: 207/1000 Iteration: 2900 Train loss: 0.345500 Train acc: 0.879000\n",
      "Epoch: 207/1000 Iteration: 2900 Validation loss: 0.352821 Validation acc: 0.877277\n",
      "Epoch: 210/1000 Iteration: 2950 Train loss: 0.363414 Train acc: 0.861500\n",
      "Epoch: 214/1000 Iteration: 3000 Train loss: 0.344369 Train acc: 0.881500\n",
      "Epoch: 214/1000 Iteration: 3000 Validation loss: 0.349187 Validation acc: 0.880748\n",
      "Epoch: 217/1000 Iteration: 3050 Train loss: 0.370399 Train acc: 0.871000\n",
      "Epoch: 221/1000 Iteration: 3100 Train loss: 0.356228 Train acc: 0.871000\n",
      "Epoch: 221/1000 Iteration: 3100 Validation loss: 0.348161 Validation acc: 0.881373\n",
      "Epoch: 224/1000 Iteration: 3150 Train loss: 0.299256 Train acc: 0.918142\n",
      "Epoch: 228/1000 Iteration: 3200 Train loss: 0.347613 Train acc: 0.869000\n",
      "Epoch: 228/1000 Iteration: 3200 Validation loss: 0.346710 Validation acc: 0.882716\n",
      "Epoch: 232/1000 Iteration: 3250 Train loss: 0.340146 Train acc: 0.882500\n",
      "Epoch: 235/1000 Iteration: 3300 Train loss: 0.354993 Train acc: 0.872000\n",
      "Epoch: 235/1000 Iteration: 3300 Validation loss: 0.345912 Validation acc: 0.884095\n",
      "Epoch: 239/1000 Iteration: 3350 Train loss: 0.339352 Train acc: 0.885500\n",
      "Epoch: 242/1000 Iteration: 3400 Train loss: 0.358365 Train acc: 0.876000\n",
      "Epoch: 242/1000 Iteration: 3400 Validation loss: 0.343284 Validation acc: 0.883720\n",
      "Epoch: 246/1000 Iteration: 3450 Train loss: 0.347076 Train acc: 0.879500\n",
      "Epoch: 249/1000 Iteration: 3500 Train loss: 0.273694 Train acc: 0.933628\n",
      "Epoch: 249/1000 Iteration: 3500 Validation loss: 0.341791 Validation acc: 0.884595\n",
      "Epoch: 253/1000 Iteration: 3550 Train loss: 0.337131 Train acc: 0.876500\n",
      "Epoch: 257/1000 Iteration: 3600 Train loss: 0.339908 Train acc: 0.875000\n",
      "Epoch: 257/1000 Iteration: 3600 Validation loss: 0.343188 Validation acc: 0.883752\n",
      "Epoch: 260/1000 Iteration: 3650 Train loss: 0.352588 Train acc: 0.868500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 264/1000 Iteration: 3700 Train loss: 0.324718 Train acc: 0.894500\n",
      "Epoch: 264/1000 Iteration: 3700 Validation loss: 0.339041 Validation acc: 0.886127\n",
      "Epoch: 267/1000 Iteration: 3750 Train loss: 0.363770 Train acc: 0.873000\n",
      "Epoch: 271/1000 Iteration: 3800 Train loss: 0.344903 Train acc: 0.882000\n",
      "Epoch: 271/1000 Iteration: 3800 Validation loss: 0.338244 Validation acc: 0.885595\n",
      "Epoch: 274/1000 Iteration: 3850 Train loss: 0.275249 Train acc: 0.920354\n",
      "Epoch: 278/1000 Iteration: 3900 Train loss: 0.331638 Train acc: 0.884000\n",
      "Epoch: 278/1000 Iteration: 3900 Validation loss: 0.336854 Validation acc: 0.889163\n",
      "Epoch: 282/1000 Iteration: 3950 Train loss: 0.329066 Train acc: 0.892500\n",
      "Epoch: 285/1000 Iteration: 4000 Train loss: 0.346382 Train acc: 0.877000\n",
      "Epoch: 285/1000 Iteration: 4000 Validation loss: 0.335699 Validation acc: 0.890163\n",
      "Epoch: 289/1000 Iteration: 4050 Train loss: 0.327147 Train acc: 0.888000\n",
      "Epoch: 292/1000 Iteration: 4100 Train loss: 0.353763 Train acc: 0.879500\n",
      "Epoch: 292/1000 Iteration: 4100 Validation loss: 0.334805 Validation acc: 0.888599\n",
      "Epoch: 296/1000 Iteration: 4150 Train loss: 0.339984 Train acc: 0.884000\n",
      "Epoch: 299/1000 Iteration: 4200 Train loss: 0.275266 Train acc: 0.920354\n",
      "Epoch: 299/1000 Iteration: 4200 Validation loss: 0.333584 Validation acc: 0.889913\n",
      "Epoch: 303/1000 Iteration: 4250 Train loss: 0.325215 Train acc: 0.887000\n",
      "Epoch: 307/1000 Iteration: 4300 Train loss: 0.323957 Train acc: 0.888500\n",
      "Epoch: 307/1000 Iteration: 4300 Validation loss: 0.334435 Validation acc: 0.889349\n",
      "Epoch: 310/1000 Iteration: 4350 Train loss: 0.346582 Train acc: 0.881500\n",
      "Epoch: 314/1000 Iteration: 4400 Train loss: 0.317645 Train acc: 0.900500\n",
      "Epoch: 314/1000 Iteration: 4400 Validation loss: 0.331568 Validation acc: 0.891445\n",
      "Epoch: 317/1000 Iteration: 4450 Train loss: 0.346146 Train acc: 0.883500\n",
      "Epoch: 321/1000 Iteration: 4500 Train loss: 0.332738 Train acc: 0.885000\n",
      "Epoch: 321/1000 Iteration: 4500 Validation loss: 0.331100 Validation acc: 0.889474\n",
      "Epoch: 324/1000 Iteration: 4550 Train loss: 0.264920 Train acc: 0.915929\n",
      "Epoch: 328/1000 Iteration: 4600 Train loss: 0.324589 Train acc: 0.889000\n",
      "Epoch: 328/1000 Iteration: 4600 Validation loss: 0.329777 Validation acc: 0.891038\n",
      "Epoch: 332/1000 Iteration: 4650 Train loss: 0.325721 Train acc: 0.888500\n",
      "Epoch: 335/1000 Iteration: 4700 Train loss: 0.344536 Train acc: 0.874500\n",
      "Epoch: 335/1000 Iteration: 4700 Validation loss: 0.329047 Validation acc: 0.891913\n",
      "Epoch: 339/1000 Iteration: 4750 Train loss: 0.321817 Train acc: 0.893500\n",
      "Epoch: 342/1000 Iteration: 4800 Train loss: 0.343372 Train acc: 0.883500\n",
      "Epoch: 342/1000 Iteration: 4800 Validation loss: 0.328248 Validation acc: 0.891538\n",
      "Epoch: 346/1000 Iteration: 4850 Train loss: 0.326798 Train acc: 0.892500\n",
      "Epoch: 349/1000 Iteration: 4900 Train loss: 0.262081 Train acc: 0.931416\n",
      "Epoch: 349/1000 Iteration: 4900 Validation loss: 0.327042 Validation acc: 0.893320\n",
      "Epoch: 353/1000 Iteration: 4950 Train loss: 0.318415 Train acc: 0.890500\n",
      "Epoch: 357/1000 Iteration: 5000 Train loss: 0.317495 Train acc: 0.885000\n",
      "Epoch: 357/1000 Iteration: 5000 Validation loss: 0.328756 Validation acc: 0.891849\n",
      "Epoch: 360/1000 Iteration: 5050 Train loss: 0.338848 Train acc: 0.885000\n",
      "Epoch: 364/1000 Iteration: 5100 Train loss: 0.316971 Train acc: 0.898500\n",
      "Epoch: 364/1000 Iteration: 5100 Validation loss: 0.325757 Validation acc: 0.894038\n",
      "Epoch: 367/1000 Iteration: 5150 Train loss: 0.342815 Train acc: 0.879000\n",
      "Epoch: 371/1000 Iteration: 5200 Train loss: 0.324557 Train acc: 0.894000\n",
      "Epoch: 371/1000 Iteration: 5200 Validation loss: 0.325096 Validation acc: 0.892445\n",
      "Epoch: 374/1000 Iteration: 5250 Train loss: 0.250670 Train acc: 0.929204\n",
      "Epoch: 378/1000 Iteration: 5300 Train loss: 0.322440 Train acc: 0.891000\n",
      "Epoch: 378/1000 Iteration: 5300 Validation loss: 0.325252 Validation acc: 0.895256\n",
      "Epoch: 382/1000 Iteration: 5350 Train loss: 0.316410 Train acc: 0.894000\n",
      "Epoch: 385/1000 Iteration: 5400 Train loss: 0.337027 Train acc: 0.886000\n",
      "Epoch: 385/1000 Iteration: 5400 Validation loss: 0.324404 Validation acc: 0.896195\n",
      "Epoch: 389/1000 Iteration: 5450 Train loss: 0.316096 Train acc: 0.900000\n",
      "Epoch: 392/1000 Iteration: 5500 Train loss: 0.342281 Train acc: 0.885500\n",
      "Epoch: 392/1000 Iteration: 5500 Validation loss: 0.323265 Validation acc: 0.893445\n",
      "Epoch: 396/1000 Iteration: 5550 Train loss: 0.321222 Train acc: 0.896500\n",
      "Epoch: 399/1000 Iteration: 5600 Train loss: 0.258461 Train acc: 0.924779\n",
      "Epoch: 399/1000 Iteration: 5600 Validation loss: 0.322356 Validation acc: 0.895070\n",
      "Epoch: 403/1000 Iteration: 5650 Train loss: 0.315448 Train acc: 0.894500\n",
      "Epoch: 407/1000 Iteration: 5700 Train loss: 0.312495 Train acc: 0.890500\n",
      "Epoch: 407/1000 Iteration: 5700 Validation loss: 0.322561 Validation acc: 0.896070\n",
      "Epoch: 410/1000 Iteration: 5750 Train loss: 0.332845 Train acc: 0.881500\n",
      "Epoch: 414/1000 Iteration: 5800 Train loss: 0.317328 Train acc: 0.902000\n",
      "Epoch: 414/1000 Iteration: 5800 Validation loss: 0.321220 Validation acc: 0.896570\n",
      "Epoch: 417/1000 Iteration: 5850 Train loss: 0.331227 Train acc: 0.890500\n",
      "Epoch: 421/1000 Iteration: 5900 Train loss: 0.324292 Train acc: 0.894500\n",
      "Epoch: 421/1000 Iteration: 5900 Validation loss: 0.320826 Validation acc: 0.894788\n",
      "Epoch: 424/1000 Iteration: 5950 Train loss: 0.250135 Train acc: 0.935841\n",
      "Epoch: 428/1000 Iteration: 6000 Train loss: 0.314636 Train acc: 0.890500\n",
      "Epoch: 428/1000 Iteration: 6000 Validation loss: 0.319677 Validation acc: 0.896570\n",
      "Epoch: 432/1000 Iteration: 6050 Train loss: 0.308603 Train acc: 0.891500\n",
      "Epoch: 435/1000 Iteration: 6100 Train loss: 0.327188 Train acc: 0.885500\n",
      "Epoch: 435/1000 Iteration: 6100 Validation loss: 0.320509 Validation acc: 0.898009\n",
      "Epoch: 439/1000 Iteration: 6150 Train loss: 0.305515 Train acc: 0.902000\n",
      "Epoch: 442/1000 Iteration: 6200 Train loss: 0.328131 Train acc: 0.892000\n",
      "Epoch: 442/1000 Iteration: 6200 Validation loss: 0.318745 Validation acc: 0.895038\n",
      "Epoch: 446/1000 Iteration: 6250 Train loss: 0.313492 Train acc: 0.901500\n",
      "Epoch: 449/1000 Iteration: 6300 Train loss: 0.244771 Train acc: 0.931416\n",
      "Epoch: 449/1000 Iteration: 6300 Validation loss: 0.318090 Validation acc: 0.896602\n",
      "Epoch: 453/1000 Iteration: 6350 Train loss: 0.308273 Train acc: 0.895000\n",
      "Epoch: 457/1000 Iteration: 6400 Train loss: 0.309110 Train acc: 0.899000\n",
      "Epoch: 457/1000 Iteration: 6400 Validation loss: 0.320596 Validation acc: 0.895602\n",
      "Epoch: 460/1000 Iteration: 6450 Train loss: 0.327677 Train acc: 0.881000\n",
      "Epoch: 464/1000 Iteration: 6500 Train loss: 0.307751 Train acc: 0.900000\n",
      "Epoch: 464/1000 Iteration: 6500 Validation loss: 0.316968 Validation acc: 0.898445\n",
      "Epoch: 467/1000 Iteration: 6550 Train loss: 0.329269 Train acc: 0.892000\n",
      "Epoch: 471/1000 Iteration: 6600 Train loss: 0.311997 Train acc: 0.904000\n",
      "Epoch: 471/1000 Iteration: 6600 Validation loss: 0.316685 Validation acc: 0.897134\n",
      "Epoch: 474/1000 Iteration: 6650 Train loss: 0.251707 Train acc: 0.933628\n",
      "Epoch: 478/1000 Iteration: 6700 Train loss: 0.303869 Train acc: 0.900500\n",
      "Epoch: 478/1000 Iteration: 6700 Validation loss: 0.315771 Validation acc: 0.899570\n",
      "Epoch: 482/1000 Iteration: 6750 Train loss: 0.304560 Train acc: 0.899000\n",
      "Epoch: 485/1000 Iteration: 6800 Train loss: 0.332797 Train acc: 0.887500\n",
      "Epoch: 485/1000 Iteration: 6800 Validation loss: 0.316445 Validation acc: 0.899259\n",
      "Epoch: 489/1000 Iteration: 6850 Train loss: 0.303855 Train acc: 0.902500\n",
      "Epoch: 492/1000 Iteration: 6900 Train loss: 0.325434 Train acc: 0.895000\n",
      "Epoch: 492/1000 Iteration: 6900 Validation loss: 0.315089 Validation acc: 0.898134\n",
      "Epoch: 496/1000 Iteration: 6950 Train loss: 0.315925 Train acc: 0.897500\n",
      "Epoch: 499/1000 Iteration: 7000 Train loss: 0.231452 Train acc: 0.940265\n",
      "Epoch: 499/1000 Iteration: 7000 Validation loss: 0.314237 Validation acc: 0.900759\n",
      "Epoch: 503/1000 Iteration: 7050 Train loss: 0.302378 Train acc: 0.898000\n",
      "Epoch: 507/1000 Iteration: 7100 Train loss: 0.306812 Train acc: 0.891000\n",
      "Epoch: 507/1000 Iteration: 7100 Validation loss: 0.317035 Validation acc: 0.898856\n",
      "Epoch: 510/1000 Iteration: 7150 Train loss: 0.316791 Train acc: 0.891500\n",
      "Epoch: 514/1000 Iteration: 7200 Train loss: 0.300962 Train acc: 0.913000\n",
      "Epoch: 514/1000 Iteration: 7200 Validation loss: 0.313509 Validation acc: 0.900977\n",
      "Epoch: 517/1000 Iteration: 7250 Train loss: 0.318813 Train acc: 0.894500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 521/1000 Iteration: 7300 Train loss: 0.314865 Train acc: 0.905000\n",
      "Epoch: 521/1000 Iteration: 7300 Validation loss: 0.313159 Validation acc: 0.900292\n",
      "Epoch: 524/1000 Iteration: 7350 Train loss: 0.234476 Train acc: 0.944690\n",
      "Epoch: 528/1000 Iteration: 7400 Train loss: 0.299831 Train acc: 0.900500\n",
      "Epoch: 528/1000 Iteration: 7400 Validation loss: 0.312727 Validation acc: 0.901602\n",
      "Epoch: 532/1000 Iteration: 7450 Train loss: 0.299795 Train acc: 0.902000\n",
      "Epoch: 535/1000 Iteration: 7500 Train loss: 0.326564 Train acc: 0.886000\n",
      "Epoch: 535/1000 Iteration: 7500 Validation loss: 0.313198 Validation acc: 0.900884\n",
      "Epoch: 539/1000 Iteration: 7550 Train loss: 0.299254 Train acc: 0.911000\n",
      "Epoch: 542/1000 Iteration: 7600 Train loss: 0.321982 Train acc: 0.900500\n",
      "Epoch: 542/1000 Iteration: 7600 Validation loss: 0.312302 Validation acc: 0.900949\n",
      "Epoch: 546/1000 Iteration: 7650 Train loss: 0.309595 Train acc: 0.905500\n",
      "Epoch: 549/1000 Iteration: 7700 Train loss: 0.225893 Train acc: 0.942478\n",
      "Epoch: 549/1000 Iteration: 7700 Validation loss: 0.311165 Validation acc: 0.901417\n",
      "Epoch: 553/1000 Iteration: 7750 Train loss: 0.301071 Train acc: 0.906500\n",
      "Epoch: 557/1000 Iteration: 7800 Train loss: 0.300392 Train acc: 0.899500\n",
      "Epoch: 557/1000 Iteration: 7800 Validation loss: 0.313132 Validation acc: 0.901638\n",
      "Epoch: 560/1000 Iteration: 7850 Train loss: 0.318798 Train acc: 0.889000\n",
      "Epoch: 564/1000 Iteration: 7900 Train loss: 0.295222 Train acc: 0.908000\n",
      "Epoch: 564/1000 Iteration: 7900 Validation loss: 0.310211 Validation acc: 0.902667\n",
      "Epoch: 567/1000 Iteration: 7950 Train loss: 0.317218 Train acc: 0.898500\n",
      "Epoch: 571/1000 Iteration: 8000 Train loss: 0.308603 Train acc: 0.905000\n",
      "Epoch: 571/1000 Iteration: 8000 Validation loss: 0.309785 Validation acc: 0.902542\n",
      "Epoch: 574/1000 Iteration: 8050 Train loss: 0.235965 Train acc: 0.931416\n",
      "Epoch: 578/1000 Iteration: 8100 Train loss: 0.298537 Train acc: 0.904500\n",
      "Epoch: 578/1000 Iteration: 8100 Validation loss: 0.310081 Validation acc: 0.902824\n",
      "Epoch: 582/1000 Iteration: 8150 Train loss: 0.294066 Train acc: 0.902500\n",
      "Epoch: 585/1000 Iteration: 8200 Train loss: 0.312555 Train acc: 0.899000\n",
      "Epoch: 585/1000 Iteration: 8200 Validation loss: 0.309658 Validation acc: 0.903199\n",
      "Epoch: 589/1000 Iteration: 8250 Train loss: 0.295143 Train acc: 0.917000\n",
      "Epoch: 592/1000 Iteration: 8300 Train loss: 0.314053 Train acc: 0.899000\n",
      "Epoch: 592/1000 Iteration: 8300 Validation loss: 0.309727 Validation acc: 0.902199\n",
      "Epoch: 596/1000 Iteration: 8350 Train loss: 0.305801 Train acc: 0.900000\n",
      "Epoch: 599/1000 Iteration: 8400 Train loss: 0.230273 Train acc: 0.940265\n",
      "Epoch: 599/1000 Iteration: 8400 Validation loss: 0.308414 Validation acc: 0.903291\n",
      "Epoch: 603/1000 Iteration: 8450 Train loss: 0.297396 Train acc: 0.907500\n",
      "Epoch: 607/1000 Iteration: 8500 Train loss: 0.297495 Train acc: 0.903500\n",
      "Epoch: 607/1000 Iteration: 8500 Validation loss: 0.312229 Validation acc: 0.902795\n",
      "Epoch: 610/1000 Iteration: 8550 Train loss: 0.315473 Train acc: 0.896000\n",
      "Epoch: 614/1000 Iteration: 8600 Train loss: 0.298418 Train acc: 0.910000\n",
      "Epoch: 614/1000 Iteration: 8600 Validation loss: 0.307751 Validation acc: 0.903824\n",
      "Epoch: 617/1000 Iteration: 8650 Train loss: 0.316688 Train acc: 0.900500\n",
      "Epoch: 621/1000 Iteration: 8700 Train loss: 0.304776 Train acc: 0.899500\n",
      "Epoch: 621/1000 Iteration: 8700 Validation loss: 0.307497 Validation acc: 0.903699\n",
      "Epoch: 624/1000 Iteration: 8750 Train loss: 0.232594 Train acc: 0.935841\n",
      "Epoch: 628/1000 Iteration: 8800 Train loss: 0.298134 Train acc: 0.904000\n",
      "Epoch: 628/1000 Iteration: 8800 Validation loss: 0.307075 Validation acc: 0.905481\n",
      "Epoch: 632/1000 Iteration: 8850 Train loss: 0.291254 Train acc: 0.901500\n",
      "Epoch: 635/1000 Iteration: 8900 Train loss: 0.306254 Train acc: 0.896500\n",
      "Epoch: 635/1000 Iteration: 8900 Validation loss: 0.307941 Validation acc: 0.904485\n",
      "Epoch: 639/1000 Iteration: 8950 Train loss: 0.292925 Train acc: 0.906500\n",
      "Epoch: 642/1000 Iteration: 9000 Train loss: 0.310083 Train acc: 0.898500\n",
      "Epoch: 642/1000 Iteration: 9000 Validation loss: 0.306833 Validation acc: 0.903481\n",
      "Epoch: 646/1000 Iteration: 9050 Train loss: 0.301939 Train acc: 0.904000\n",
      "Epoch: 649/1000 Iteration: 9100 Train loss: 0.214865 Train acc: 0.962389\n",
      "Epoch: 649/1000 Iteration: 9100 Validation loss: 0.305696 Validation acc: 0.904856\n",
      "Epoch: 653/1000 Iteration: 9150 Train loss: 0.293868 Train acc: 0.908000\n",
      "Epoch: 657/1000 Iteration: 9200 Train loss: 0.294139 Train acc: 0.898000\n",
      "Epoch: 657/1000 Iteration: 9200 Validation loss: 0.307161 Validation acc: 0.905077\n",
      "Epoch: 660/1000 Iteration: 9250 Train loss: 0.310203 Train acc: 0.897500\n",
      "Epoch: 664/1000 Iteration: 9300 Train loss: 0.290882 Train acc: 0.911000\n",
      "Epoch: 664/1000 Iteration: 9300 Validation loss: 0.305156 Validation acc: 0.904981\n",
      "Epoch: 667/1000 Iteration: 9350 Train loss: 0.305608 Train acc: 0.906000\n",
      "Epoch: 671/1000 Iteration: 9400 Train loss: 0.299761 Train acc: 0.905500\n",
      "Epoch: 671/1000 Iteration: 9400 Validation loss: 0.305098 Validation acc: 0.903417\n",
      "Epoch: 674/1000 Iteration: 9450 Train loss: 0.220584 Train acc: 0.942478\n",
      "Epoch: 678/1000 Iteration: 9500 Train loss: 0.287869 Train acc: 0.914000\n",
      "Epoch: 678/1000 Iteration: 9500 Validation loss: 0.304606 Validation acc: 0.907295\n",
      "Epoch: 682/1000 Iteration: 9550 Train loss: 0.296808 Train acc: 0.900000\n",
      "Epoch: 685/1000 Iteration: 9600 Train loss: 0.301861 Train acc: 0.904000\n",
      "Epoch: 685/1000 Iteration: 9600 Validation loss: 0.305362 Validation acc: 0.907110\n",
      "Epoch: 689/1000 Iteration: 9650 Train loss: 0.283555 Train acc: 0.920500\n",
      "Epoch: 692/1000 Iteration: 9700 Train loss: 0.307669 Train acc: 0.900000\n",
      "Epoch: 692/1000 Iteration: 9700 Validation loss: 0.304656 Validation acc: 0.904763\n",
      "Epoch: 696/1000 Iteration: 9750 Train loss: 0.292267 Train acc: 0.911000\n",
      "Epoch: 699/1000 Iteration: 9800 Train loss: 0.215582 Train acc: 0.944690\n",
      "Epoch: 699/1000 Iteration: 9800 Validation loss: 0.303738 Validation acc: 0.906388\n",
      "Epoch: 703/1000 Iteration: 9850 Train loss: 0.293052 Train acc: 0.910000\n",
      "Epoch: 707/1000 Iteration: 9900 Train loss: 0.291773 Train acc: 0.907500\n",
      "Epoch: 707/1000 Iteration: 9900 Validation loss: 0.305213 Validation acc: 0.907174\n",
      "Epoch: 710/1000 Iteration: 9950 Train loss: 0.307890 Train acc: 0.899000\n",
      "Epoch: 714/1000 Iteration: 10000 Train loss: 0.288406 Train acc: 0.920000\n",
      "Epoch: 714/1000 Iteration: 10000 Validation loss: 0.303481 Validation acc: 0.904042\n",
      "Epoch: 717/1000 Iteration: 10050 Train loss: 0.298891 Train acc: 0.905500\n",
      "Epoch: 721/1000 Iteration: 10100 Train loss: 0.290603 Train acc: 0.910000\n",
      "Epoch: 721/1000 Iteration: 10100 Validation loss: 0.302692 Validation acc: 0.904042\n",
      "Epoch: 724/1000 Iteration: 10150 Train loss: 0.221782 Train acc: 0.955752\n",
      "Epoch: 728/1000 Iteration: 10200 Train loss: 0.293095 Train acc: 0.910000\n",
      "Epoch: 728/1000 Iteration: 10200 Validation loss: 0.303152 Validation acc: 0.908517\n",
      "Epoch: 732/1000 Iteration: 10250 Train loss: 0.287356 Train acc: 0.901500\n",
      "Epoch: 735/1000 Iteration: 10300 Train loss: 0.300120 Train acc: 0.900500\n",
      "Epoch: 735/1000 Iteration: 10300 Validation loss: 0.303644 Validation acc: 0.908424\n",
      "Epoch: 739/1000 Iteration: 10350 Train loss: 0.283754 Train acc: 0.921500\n",
      "Epoch: 742/1000 Iteration: 10400 Train loss: 0.306658 Train acc: 0.907000\n",
      "Epoch: 742/1000 Iteration: 10400 Validation loss: 0.302590 Validation acc: 0.905106\n",
      "Epoch: 746/1000 Iteration: 10450 Train loss: 0.302743 Train acc: 0.903500\n",
      "Epoch: 749/1000 Iteration: 10500 Train loss: 0.212863 Train acc: 0.960177\n",
      "Epoch: 749/1000 Iteration: 10500 Validation loss: 0.301635 Validation acc: 0.906638\n",
      "Epoch: 753/1000 Iteration: 10550 Train loss: 0.289474 Train acc: 0.911500\n",
      "Epoch: 757/1000 Iteration: 10600 Train loss: 0.286290 Train acc: 0.903000\n",
      "Epoch: 757/1000 Iteration: 10600 Validation loss: 0.305349 Validation acc: 0.907267\n",
      "Epoch: 760/1000 Iteration: 10650 Train loss: 0.301224 Train acc: 0.903000\n",
      "Epoch: 764/1000 Iteration: 10700 Train loss: 0.277051 Train acc: 0.918500\n",
      "Epoch: 764/1000 Iteration: 10700 Validation loss: 0.301310 Validation acc: 0.907513\n",
      "Epoch: 767/1000 Iteration: 10750 Train loss: 0.299612 Train acc: 0.907000\n",
      "Epoch: 771/1000 Iteration: 10800 Train loss: 0.290832 Train acc: 0.911500\n",
      "Epoch: 771/1000 Iteration: 10800 Validation loss: 0.301370 Validation acc: 0.905731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 774/1000 Iteration: 10850 Train loss: 0.217157 Train acc: 0.953540\n",
      "Epoch: 778/1000 Iteration: 10900 Train loss: 0.288444 Train acc: 0.916500\n",
      "Epoch: 778/1000 Iteration: 10900 Validation loss: 0.300794 Validation acc: 0.908952\n",
      "Epoch: 782/1000 Iteration: 10950 Train loss: 0.291947 Train acc: 0.901000\n",
      "Epoch: 785/1000 Iteration: 11000 Train loss: 0.299706 Train acc: 0.907000\n",
      "Epoch: 785/1000 Iteration: 11000 Validation loss: 0.303209 Validation acc: 0.908331\n",
      "Epoch: 789/1000 Iteration: 11050 Train loss: 0.286209 Train acc: 0.916500\n",
      "Epoch: 792/1000 Iteration: 11100 Train loss: 0.309434 Train acc: 0.905000\n",
      "Epoch: 792/1000 Iteration: 11100 Validation loss: 0.300657 Validation acc: 0.907420\n",
      "Epoch: 796/1000 Iteration: 11150 Train loss: 0.294554 Train acc: 0.907000\n",
      "Epoch: 799/1000 Iteration: 11200 Train loss: 0.208480 Train acc: 0.953540\n",
      "Epoch: 799/1000 Iteration: 11200 Validation loss: 0.300139 Validation acc: 0.907545\n",
      "Epoch: 803/1000 Iteration: 11250 Train loss: 0.286355 Train acc: 0.910500\n",
      "Epoch: 807/1000 Iteration: 11300 Train loss: 0.288596 Train acc: 0.915000\n",
      "Epoch: 807/1000 Iteration: 11300 Validation loss: 0.302944 Validation acc: 0.908206\n",
      "Epoch: 810/1000 Iteration: 11350 Train loss: 0.300068 Train acc: 0.905000\n",
      "Epoch: 814/1000 Iteration: 11400 Train loss: 0.278558 Train acc: 0.918000\n",
      "Epoch: 814/1000 Iteration: 11400 Validation loss: 0.299357 Validation acc: 0.907670\n",
      "Epoch: 817/1000 Iteration: 11450 Train loss: 0.299698 Train acc: 0.911500\n",
      "Epoch: 821/1000 Iteration: 11500 Train loss: 0.289373 Train acc: 0.912500\n",
      "Epoch: 821/1000 Iteration: 11500 Validation loss: 0.299524 Validation acc: 0.908920\n",
      "Epoch: 824/1000 Iteration: 11550 Train loss: 0.213448 Train acc: 0.960177\n",
      "Epoch: 828/1000 Iteration: 11600 Train loss: 0.287659 Train acc: 0.910500\n",
      "Epoch: 828/1000 Iteration: 11600 Validation loss: 0.299300 Validation acc: 0.911206\n",
      "Epoch: 832/1000 Iteration: 11650 Train loss: 0.284337 Train acc: 0.910000\n",
      "Epoch: 835/1000 Iteration: 11700 Train loss: 0.298616 Train acc: 0.902000\n",
      "Epoch: 835/1000 Iteration: 11700 Validation loss: 0.300569 Validation acc: 0.909988\n",
      "Epoch: 839/1000 Iteration: 11750 Train loss: 0.279495 Train acc: 0.920000\n",
      "Epoch: 842/1000 Iteration: 11800 Train loss: 0.298494 Train acc: 0.908500\n",
      "Epoch: 842/1000 Iteration: 11800 Validation loss: 0.299338 Validation acc: 0.908138\n",
      "Epoch: 846/1000 Iteration: 11850 Train loss: 0.293112 Train acc: 0.909000\n",
      "Epoch: 849/1000 Iteration: 11900 Train loss: 0.205228 Train acc: 0.964602\n",
      "Epoch: 849/1000 Iteration: 11900 Validation loss: 0.298835 Validation acc: 0.908827\n",
      "Epoch: 853/1000 Iteration: 11950 Train loss: 0.286607 Train acc: 0.913000\n",
      "Epoch: 857/1000 Iteration: 12000 Train loss: 0.289764 Train acc: 0.904000\n",
      "Epoch: 857/1000 Iteration: 12000 Validation loss: 0.301104 Validation acc: 0.908299\n",
      "Epoch: 860/1000 Iteration: 12050 Train loss: 0.295888 Train acc: 0.907000\n",
      "Epoch: 864/1000 Iteration: 12100 Train loss: 0.281606 Train acc: 0.919500\n",
      "Epoch: 864/1000 Iteration: 12100 Validation loss: 0.297775 Validation acc: 0.908920\n",
      "Epoch: 867/1000 Iteration: 12150 Train loss: 0.297267 Train acc: 0.909500\n",
      "Epoch: 871/1000 Iteration: 12200 Train loss: 0.284951 Train acc: 0.913500\n",
      "Epoch: 871/1000 Iteration: 12200 Validation loss: 0.297967 Validation acc: 0.908263\n",
      "Epoch: 874/1000 Iteration: 12250 Train loss: 0.205701 Train acc: 0.966814\n",
      "Epoch: 878/1000 Iteration: 12300 Train loss: 0.284035 Train acc: 0.912500\n",
      "Epoch: 878/1000 Iteration: 12300 Validation loss: 0.298240 Validation acc: 0.911520\n",
      "Epoch: 882/1000 Iteration: 12350 Train loss: 0.284451 Train acc: 0.912500\n",
      "Epoch: 885/1000 Iteration: 12400 Train loss: 0.294182 Train acc: 0.905000\n",
      "Epoch: 885/1000 Iteration: 12400 Validation loss: 0.298263 Validation acc: 0.911488\n",
      "Epoch: 889/1000 Iteration: 12450 Train loss: 0.278230 Train acc: 0.923500\n",
      "Epoch: 892/1000 Iteration: 12500 Train loss: 0.293923 Train acc: 0.911500\n",
      "Epoch: 892/1000 Iteration: 12500 Validation loss: 0.297185 Validation acc: 0.909952\n",
      "Epoch: 896/1000 Iteration: 12550 Train loss: 0.281329 Train acc: 0.919500\n",
      "Epoch: 899/1000 Iteration: 12600 Train loss: 0.203516 Train acc: 0.960177\n",
      "Epoch: 899/1000 Iteration: 12600 Validation loss: 0.297166 Validation acc: 0.908545\n",
      "Epoch: 903/1000 Iteration: 12650 Train loss: 0.280188 Train acc: 0.916500\n",
      "Epoch: 907/1000 Iteration: 12700 Train loss: 0.283292 Train acc: 0.912500\n",
      "Epoch: 907/1000 Iteration: 12700 Validation loss: 0.299164 Validation acc: 0.909299\n",
      "Epoch: 910/1000 Iteration: 12750 Train loss: 0.296110 Train acc: 0.904500\n",
      "Epoch: 914/1000 Iteration: 12800 Train loss: 0.277860 Train acc: 0.917000\n",
      "Epoch: 914/1000 Iteration: 12800 Validation loss: 0.296332 Validation acc: 0.910360\n",
      "Epoch: 917/1000 Iteration: 12850 Train loss: 0.304269 Train acc: 0.907000\n",
      "Epoch: 921/1000 Iteration: 12900 Train loss: 0.284316 Train acc: 0.912000\n",
      "Epoch: 921/1000 Iteration: 12900 Validation loss: 0.296447 Validation acc: 0.909670\n",
      "Epoch: 924/1000 Iteration: 12950 Train loss: 0.209639 Train acc: 0.960177\n",
      "Epoch: 928/1000 Iteration: 13000 Train loss: 0.284013 Train acc: 0.914500\n",
      "Epoch: 928/1000 Iteration: 13000 Validation loss: 0.295954 Validation acc: 0.911799\n",
      "Epoch: 932/1000 Iteration: 13050 Train loss: 0.281728 Train acc: 0.907000\n",
      "Epoch: 935/1000 Iteration: 13100 Train loss: 0.299535 Train acc: 0.906000\n",
      "Epoch: 935/1000 Iteration: 13100 Validation loss: 0.297014 Validation acc: 0.911988\n",
      "Epoch: 939/1000 Iteration: 13150 Train loss: 0.274742 Train acc: 0.921500\n",
      "Epoch: 942/1000 Iteration: 13200 Train loss: 0.295182 Train acc: 0.914500\n",
      "Epoch: 942/1000 Iteration: 13200 Validation loss: 0.295787 Validation acc: 0.909545\n",
      "Epoch: 946/1000 Iteration: 13250 Train loss: 0.288641 Train acc: 0.915500\n",
      "Epoch: 949/1000 Iteration: 13300 Train loss: 0.205474 Train acc: 0.953540\n",
      "Epoch: 949/1000 Iteration: 13300 Validation loss: 0.295399 Validation acc: 0.911017\n",
      "Epoch: 953/1000 Iteration: 13350 Train loss: 0.279960 Train acc: 0.920500\n",
      "Epoch: 957/1000 Iteration: 13400 Train loss: 0.278318 Train acc: 0.916000\n",
      "Epoch: 957/1000 Iteration: 13400 Validation loss: 0.298538 Validation acc: 0.911113\n",
      "Epoch: 960/1000 Iteration: 13450 Train loss: 0.289819 Train acc: 0.911000\n",
      "Epoch: 964/1000 Iteration: 13500 Train loss: 0.278014 Train acc: 0.921000\n",
      "Epoch: 964/1000 Iteration: 13500 Validation loss: 0.295346 Validation acc: 0.910860\n",
      "Epoch: 967/1000 Iteration: 13550 Train loss: 0.297869 Train acc: 0.909000\n",
      "Epoch: 971/1000 Iteration: 13600 Train loss: 0.281062 Train acc: 0.918000\n",
      "Epoch: 971/1000 Iteration: 13600 Validation loss: 0.295336 Validation acc: 0.910452\n",
      "Epoch: 974/1000 Iteration: 13650 Train loss: 0.208363 Train acc: 0.949115\n",
      "Epoch: 978/1000 Iteration: 13700 Train loss: 0.282963 Train acc: 0.915000\n",
      "Epoch: 978/1000 Iteration: 13700 Validation loss: 0.294850 Validation acc: 0.912863\n",
      "Epoch: 982/1000 Iteration: 13750 Train loss: 0.281290 Train acc: 0.913000\n",
      "Epoch: 985/1000 Iteration: 13800 Train loss: 0.292534 Train acc: 0.910500\n",
      "Epoch: 985/1000 Iteration: 13800 Validation loss: 0.295119 Validation acc: 0.911956\n",
      "Epoch: 989/1000 Iteration: 13850 Train loss: 0.272184 Train acc: 0.921000\n",
      "Epoch: 992/1000 Iteration: 13900 Train loss: 0.293192 Train acc: 0.915000\n",
      "Epoch: 992/1000 Iteration: 13900 Validation loss: 0.295436 Validation acc: 0.910735\n",
      "Epoch: 996/1000 Iteration: 13950 Train loss: 0.286335 Train acc: 0.918000\n",
      "Epoch: 999/1000 Iteration: 14000 Train loss: 0.197353 Train acc: 0.966814\n",
      "Epoch: 999/1000 Iteration: 14000 Validation loss: 0.294146 Validation acc: 0.912424\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_train, y_train, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 50 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%100 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v in get_batches(X_validation, y_validation, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess, cnn_model_path + \"checkpoints-cnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 100 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 100 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "testStrings = '''4092,3677,1\n",
    "4556,4555,1\n",
    "4408,4242,1\n",
    "62210,4133,1\n",
    "4459,84509,1\n",
    "6750,2896,1\n",
    "3942,7158,1\n",
    "3754,65157,1\n",
    "3084,65157,1\n",
    "6985,65157,1\n",
    "3061,65157,1\n",
    "27939,65157,1\n",
    "4139,2915,1\n",
    "3058,2937,1\n",
    "4047,2937,1\n",
    "7335,3010,1\n",
    "3375,9343,1\n",
    "4150,45921,1'''\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_test_reverse = []\n",
    "\n",
    "for line in testStrings.splitlines():\n",
    "    word = line.replace(\"\\r\\n\", \"\").split(\",\")\n",
    "    X_test.append([word[0], word[1]])\n",
    "    X_test_reverse.append([word[1], word[0]])\n",
    "    y_test.append(int(word[2]))\n",
    "#     print(word)\n",
    "#     print(vector_model.docvecs[word[0]])\n",
    "#     print(vector_model.docvecs[word[1]])\n",
    "\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['4092', '3677'], ['4556', '4555'], ['4408', '4242'], ['62210', '4133'], ['4459', '84509'], ['6750', '2896'], ['3942', '7158'], ['3754', '65157'], ['3084', '65157'], ['6985', '65157'], ['3061', '65157'], ['27939', '65157'], ['4139', '2915'], ['3058', '2937'], ['4047', '2937'], ['7335', '3010'], ['3375', '9343'], ['4150', '45921']]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7335', '3010']  yes\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for pair in X_test:\n",
    "    if pair in X_train or pair in X_validation:\n",
    "        print(pair, ' yes')\n",
    "        X_test.remove(pair)\n",
    "\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/MLOntology/NCIt/cnnModel/area/checkpoints-cnn/har.ckpt\n",
      "Test accuracy: 0.294118\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "batch_size = len(X_test)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint( cnn_model_path + 'checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/MLOntology/NCIt/cnnModel/area/checkpoints-cnn/har.ckpt\n",
      "['4092', '3677'] : 1 \n",
      "benign epithelial neoplasm -> benign neoplasm \n",
      "['4556', '4555'] : 1 \n",
      "iris nevus -> benign iris neoplasm \n",
      "['4408', '4242'] : 1 \n",
      "benign posterior tongue neoplasm -> benign soft tissue neoplasm \n",
      "['62210', '4133'] : 1 \n",
      "breast tubular adenoma -> tubular adenoma \n",
      "['4459', '84509'] : 1 \n",
      "clear cell squamous cell skin carcinoma -> primary malignant neoplasm \n",
      "['6750', '2896'] : 1 \n",
      "cutaneous glomangioma -> benign skin neoplasm \n",
      "['3942', '7158'] : 1 \n",
      "fibrous hamartoma of infancy -> benign dermal neoplasm \n",
      "['3754', '65157'] : 1 \n",
      "gonadoblastoma -> neoplasm, uncertain whether benign or malignant \n",
      "['3084', '65157'] : 1 \n",
      "hemangioendothelioma -> neoplasm, uncertain whether benign or malignant \n",
      "['6985', '65157'] : 1 \n",
      "invasive hydatidiform mole -> neoplasm, uncertain whether benign or malignant \n",
      "['3061', '65157'] : 1 \n",
      "jugulotympanic paraganglioma -> neoplasm, uncertain whether benign or malignant \n",
      "['27939', '65157'] : 1 \n",
      "lobular neoplasia -> neoplasm, uncertain whether benign or malignant \n",
      "['4139', '2915'] : 1 \n",
      "combined carcinoid and adenocarcinoma -> carcinoid tumor \n",
      "['3058', '2937'] : 1 \n",
      "glioblastoma -> intraventricular brain neoplasm \n",
      "['4047', '2937'] : 1 \n",
      "pilocytic astrocytoma -> intraventricular brain neoplasm \n",
      "['3375', '9343'] : 1 \n",
      "skull neoplasm -> bone neoplasm \n",
      "['4150', '45921'] : 1 \n",
      "basophilic adenocarcinoma -> anterior pituitary gland neoplasm \n",
      "Test accuracy: [False False False False False False  True False  True False False  True\n",
      "  True False  True False False]\n",
      "[array([False, False, False, False, False, False,  True, False,  True,\n",
      "       False, False,  True,  True, False,  True, False, False])]\n"
     ]
    }
   ],
   "source": [
    "n_classes=2 \n",
    "\n",
    "def get_batches_withName(x_samples, y_samples, batch_size=64):\n",
    "    samples = list(zip(x_samples, y_samples))\n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    shuffle(samples)\n",
    "    for offset in range(0, num_samples, batch_size):\n",
    "        batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "        X_samples = []\n",
    "        Y_samples= []\n",
    "        for batch_sample in batch_samples:\n",
    "            print(\"{} : {} \".format(batch_sample[0], batch_sample[1]))\n",
    "            print(\"{} -> {} \".format(conceptLabelDict[batch_sample[0][0]], conceptLabelDict[batch_sample[0][1]]))\n",
    "            pair_list = batch_sample[0]\n",
    "#             data_vector= getVector(pair_list, conceptLabelDict, vector_model)\n",
    "            pvdm_vector = getVector(pair_list, conceptLabelDict, vector_model)\n",
    "            pvdbow_vector = getVector(pair_list, conceptLabelDict, vector_model_0)\n",
    "            data_vector = stackVector(pvdm_vector, pvdbow_vector)\n",
    "#             print(data_vector.shape)\n",
    "            X_samples.append(data_vector)\n",
    "            class_label = batch_sample[1] \n",
    "            Y_samples.append(class_label)\n",
    "\n",
    "        X_samples = np.array(X_samples).astype('float32')\n",
    "        Y_samples = np.eye(n_classes)[Y_samples]\n",
    "#             print('one batch ready')\n",
    "        yield shuffle(X_samples, Y_samples)\n",
    "\n",
    "\n",
    "test_pred = []\n",
    "batch_size = len(X_test)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(cnn_model_path + 'checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches_withName(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_pred = sess.run(correct_pred, feed_dict=feed)\n",
    "        print(\"Test accuracy: {}\".format(batch_pred))\n",
    "        test_pred.append(batch_pred)\n",
    "        \n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['8784', '86026', 0], ['8784', '7917', 0], ['8784', '86034', 0], ['8784', '86033', 0], ['8784', '86053', 0]]\n",
      "732906\n"
     ]
    }
   ],
   "source": [
    "testingPairList=[]\n",
    "\n",
    "def read_test_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==2:\n",
    "                childID = get_trailing_number(splitted[0])\n",
    "                notparentID = get_trailing_number(splitted[1].replace(\"\\r\\n\", \"\"))\n",
    "                assert childID in vector_model.docvecs, \"%s not in vector model\"%(childID)\n",
    "                assert notparentID in vector_model.docvecs, \"%s not in vector model\"%(notparentID)\n",
    "                testingPairList.append([childID, notparentID, 0])\n",
    "#                 conceptNotPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "testingPair_file = data_path + \"testing_owl_ncit.txt\"\n",
    "read_test_pair(testingPair_file)\n",
    "\n",
    "\n",
    "first2pairs =testingPairList[10:15]\n",
    "print(first2pairs)\n",
    "print(len(testingPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove samples from training samples \n",
    "\n",
    "train_pair_list = []\n",
    "for pair in conceptPairList:\n",
    "    pair = tuple(pair)\n",
    "    train_pair_list.append(pair)\n",
    "\n",
    "train_pair_set = set(train_pair_list)\n",
    "\n",
    "train_notpair_list = []\n",
    "for pair in conceptNotPairList:\n",
    "    pair = tuple(pair)\n",
    "    train_notpair_list.append(pair)\n",
    "\n",
    "train_notpair_set = set(train_notpair_list)\n",
    "\n",
    "testing_pair_list = []\n",
    "for pair in testingPairList:\n",
    "    pair = tuple(pair)\n",
    "    testing_pair_list.append(pair)\n",
    "\n",
    "testing_pair_set = set(testing_pair_list)\n",
    "\n",
    "\n",
    "\n",
    "rest_pair_Set = testing_pair_set - train_pair_set - train_notpair_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['90500', '115121', 0], ['90499', '140080', 0], ['133445', '8237', 0], ['87777', '135207', 0], ['7431', '4765', 0]]\n",
      "723084\n"
     ]
    }
   ],
   "source": [
    "type(rest_pair_Set)\n",
    "\n",
    "rest_pair_list=list(rest_pair_Set)\n",
    "\n",
    "rest_testingPairList =[]\n",
    "for t in rest_pair_list:\n",
    "    rest_testingPairList.append(list(t))\n",
    "\n",
    "\n",
    "print(rest_testingPairList[:5])\n",
    "print(len(rest_testingPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "idpairs_list, label_list= readFromPairList([], rest_testingPairList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/MLOntology/NCIt/cnnModel/area/checkpoints-cnn/har.ckpt\n",
      "Test accuracy: 0.933896\n"
     ]
    }
   ],
   "source": [
    "test_rest_acc = []\n",
    "batch_size = 5000\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(cnn_model_path + 'checkpoints-cnn'))\n",
    "    test_iteration = 1\n",
    "    \n",
    "    for x_t, y_t in get_batches(idpairs_list, label_list, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_rest_acc.append(batch_acc)\n",
    "        \n",
    "        test_iteration += 1\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_rest_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training and test loss\n",
    "t = np.arange(test_iteration-1)\n",
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(test_rest_acc), 'g-')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.ylim(0.4, 1)\n",
    "plt.legend(['test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
