{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hao/anaconda3/envs/MLOntology/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import multiprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variabls\n",
    "\n",
    "directory_path =  \"/home/hao/AnacondaProjects/MLOntology/NCIt/\"\n",
    "data_path = directory_path + \"data/\"\n",
    "vector_model_path = directory_path +\"vectorModel/\"\n",
    "cnn_model_path = directory_path +\"cnnModel/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_trailing_number(s):\n",
    "    m = re.search(r'\\d+$', s)\n",
    "    return m.group() if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prostate carcinoma\n",
      "stage ia esophageal cancer ajcc v7\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#read class label file\n",
    "#create mapping from id to labels  \n",
    "#iso-8859-1 , encoding=\"iso-8859-1\"\n",
    "conceptLabelDict={}\n",
    "errors=[]\n",
    "\n",
    "def read_label(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                conceptID = get_trailing_number(splitted[1])\n",
    "                conceptLabelDict[conceptID] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "label_file = data_path + \"ontClassLabels_owl_ncit.txt\"\n",
    "read_label(label_file)\n",
    "print(conceptLabelDict[\"4863\"])\n",
    "print(conceptLabelDict[\"115117\"])\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['4861', '7318', 1], ['87152', '87150', 1], ['87153', '140032', 1], ['87154', '87153', 1], ['87155', '87153', 1]]\n",
      "16533\n"
     ]
    }
   ],
   "source": [
    "conceptPairDict={}\n",
    "errors=[]\n",
    "conceptPairList=[]\n",
    "\n",
    "def read_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                childID = get_trailing_number(splitted[1])\n",
    "                parentID = get_trailing_number(splitted[2].replace(\"\\r\\n\", \"\"))\n",
    "                conceptPairList.append([childID, parentID , 1])\n",
    "#                 conceptPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "pair_file = data_path + \"ontHierarchy_owl_ncit.txt\"\n",
    "read_pair(pair_file)\n",
    "\n",
    "checkpairs = conceptPairList[10:15]\n",
    "print(checkpairs)\n",
    "print(len(conceptPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['7918', '9151', 0], ['7918', '48612', 0], ['7918', '48613', 0], ['7918', '91231', 0], ['7918', '66753', 0]]\n",
      "37147\n"
     ]
    }
   ],
   "source": [
    "conceptNotPairDict={}\n",
    "conceptNotPairList=[]\n",
    "\n",
    "def read_not_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==2:\n",
    "                childID = get_trailing_number(splitted[0])\n",
    "                notparentID = get_trailing_number(splitted[1].replace(\"\\r\\n\", \"\"))\n",
    "                conceptNotPairList.append([childID, notparentID, 0])\n",
    "#                 conceptNotPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "notPair_file = data_path + \"taxNotPairs_owl_ncit.txt\"\n",
    "read_not_pair(notPair_file)\n",
    "\n",
    "\n",
    "first2pairs =conceptNotPairList[10:15]\n",
    "print(first2pairs)\n",
    "print(len(conceptNotPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34927\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cleanlist = []\n",
    "[cleanlist.append(x) for x in conceptNotPairList if x not in cleanlist]\n",
    "print(len(cleanlist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptNotPairList = cleanlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['8176', '8174', 1], ['6681', '5647', 1], ['54294', '54293', 1], ['7532', '7530', 1], ['4295', '7201', 1], ['3757', '4699', 1], ['140007', '140005', 1], ['95546', '4374', 1]]\n",
      "2000\n",
      "[['9061', '4092', 0], ['6106', '4110', 0], ['27822', '5091', 0], ['122717', '3182', 0], ['128112', '3443', 0], ['4572', '2877', 0], ['4647', '5212', 0], ['4381', '4858', 0]]\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "new_list = random.sample(conceptPairList, 2000)\n",
    "print(new_list[2:10])\n",
    "print(len(new_list))\n",
    "\n",
    "new_list_2 = random.sample(conceptNotPairList, 2000)\n",
    "print(new_list_2[2:10])\n",
    "print(len(new_list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14533\n",
      "32927\n"
     ]
    }
   ],
   "source": [
    "testing_list = [x for x in conceptPairList if x not in new_list]\n",
    "testing_list_2 = [y for y in conceptNotPairList if y not in new_list_2]\n",
    "\n",
    "print(len(testing_list))\n",
    "print(len(testing_list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = new_list + new_list_2\n",
    "\n",
    "filepath = directory_path + \"output.txt\"\n",
    "with open(filepath, 'w') as file_handler:\n",
    "    for item in test_list:\n",
    "        file_handler.write(\"{}\\t{}\\t{}\\n\".format(item[0], item[1], item[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "[['3642', '5541', '1'], ['7546', '7545', '1'], ['8176', '8174', '1'], ['6681', '5647', '1'], ['54294', '54293', '1']]\n"
     ]
    }
   ],
   "source": [
    "with open(filepath) as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "content = [x.strip() for x in content] \n",
    "\n",
    "pair_lists=[]\n",
    "for item in content:\n",
    "    itemlist=item.split('\\t')\n",
    "    pair_lists.append(itemlist)\n",
    "\n",
    "print(len(pair_lists))\n",
    "print(pair_lists[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
