{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import multiprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['37225000', '52860004', 1], ['159386001', '159385002', 1], ['233836002', '233835003', 1], ['233836002', '304914007', 1], ['224923003', '224717003', 1]]\n",
      "502206\n"
     ]
    }
   ],
   "source": [
    "conceptPairDict={}\n",
    "errors=[]\n",
    "conceptPairList=[]\n",
    "\n",
    "def read_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                conceptPairList.append([splitted[1], splitted[2].replace(\"\\r\\n\", \"\"), 1])\n",
    "#                 conceptPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "pair_file = \"/home/hao/AnacondaProjects/MLOntology/ontHierarchy.txt\"\n",
    "read_pair(pair_file)\n",
    "\n",
    "first2pairs = conceptPairList[10:15]\n",
    "print(first2pairs)\n",
    "print(len(conceptPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['273187009', '272765000', 0], ['272877001', '272765000', 0], ['273216002', '272765000', 0], ['273125004', '272765000', 0], ['272973003', '272765000', 0]]\n",
      "6166563\n"
     ]
    }
   ],
   "source": [
    "conceptNotPairDict={}\n",
    "conceptNotPairList=[]\n",
    "\n",
    "def read_not_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==2:\n",
    "                conceptNotPairList.append([splitted[0], splitted[1].replace(\"\\r\\n\", \"\"), 0])\n",
    "#                 conceptNotPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "notPair_file = \"/home/hao/AnacondaProjects/MLOntology/taxNotPairs.txt\"\n",
    "read_not_pair(notPair_file)\n",
    "\n",
    "# first2pairs = {k: conceptNotPairDict[k] for k in list(conceptNotPairDict)[10:15]}\n",
    "first2pairs =conceptNotPairList[10:15]\n",
    "print(first2pairs)\n",
    "print(len(conceptNotPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('237267007', 0.627997100353241),\n",
      " ('722912007', 0.6036189794540405),\n",
      " ('446466006', 0.5924400687217712),\n",
      " ('722913002', 0.5906124711036682),\n",
      " ('67798003', 0.5715452432632446),\n",
      " ('253745002', 0.5685455203056335),\n",
      " ('10759661000119108', 0.5673998594284058),\n",
      " ('277485007', 0.5658801794052124),\n",
      " ('177130000', 0.5645993947982788),\n",
      " ('312974005', 0.5601198077201843)]\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/hao/AnacondaProjects/MLOntology/model0\"\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(model.docvecs.most_similar([inferred_vector], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/MLOntology/model1\"\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(model.docvecs.most_similar([inferred_vector], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60005, 60049, 60050, 60053, 60055, 60014, 60094, 60007, 60041, 60009]\n",
      "[60180, 60126, 60103, 60132, 60194, 60170, 60136, 60163, 60114, 60147]\n",
      "[60264, 60206, 60212, 60211, 60243, 60219, 60221, 60287, 60204, 60255]\n",
      "[60338, 60365, 60341, 60370, 60351, 60374, 60342, 60384, 60310, 60322]\n",
      "[60481, 60402, 60451, 60429, 60462, 60475, 60459, 60461, 60473, 60408]\n",
      "[60504, 60579, 60578, 60517, 60566, 60581, 60520, 60585, 60513, 60539]\n",
      "[60626, 60615, 60699, 60631, 60642, 60687, 60683, 60616, 60604, 60694]\n",
      "[60759, 60760, 60732, 60799, 60706, 60777, 60720, 60738, 60716, 60704]\n",
      "[60858, 60828, 60817, 60897, 60849, 60807, 60872, 60829, 60802, 60861]\n",
      "[60931, 60914, 60993, 60938, 60956, 60926, 60907, 60981, 60929, 60955]\n",
      "[61076, 61057, 61019, 61084, 61060, 61083, 61016, 61006, 61068, 61078]\n",
      "[61198, 61191, 61101, 61107, 61102, 61118, 61146, 61113, 61148, 61150]\n",
      "[61283, 61208, 61281, 61299, 61243, 61228, 61245, 61229, 61232, 61211]\n",
      "[61382, 61355, 61386, 61347, 61330, 61377, 61357, 61363, 61313, 61383]\n",
      "[61464, 61487, 61497, 61446, 61432, 61494, 61408, 61461, 61492, 61450]\n",
      "[61576, 61544, 61592, 61556, 61555, 61539, 61565, 61590, 61570, 61512]\n",
      "[61643, 61682, 61654, 61696, 61632, 61691, 61666, 61626, 61628, 61677]\n",
      "[61706, 61722, 61742, 61768, 61717, 61791, 61733, 61716, 61753, 61719]\n",
      "[61842, 61852, 61817, 61815, 61863, 61803, 61882, 61877, 61839, 61828]\n",
      "[61907, 61965, 61900, 61903, 61970, 61921, 61975, 61987, 61972, 61913]\n",
      "[62099, 62054, 62032, 62096, 62086, 62011, 62070, 62000, 62018, 62012]\n",
      "[62140, 62178, 62166, 62192, 62142, 62197, 62188, 62195, 62183, 62132]\n",
      "[62243, 62271, 62244, 62238, 62247, 62232, 62214, 62240, 62237, 62286]\n",
      "[62304, 62333, 62366, 62389, 62367, 62321, 62318, 62364, 62362, 62347]\n",
      "[62474, 62481, 62403, 62412, 62423, 62446, 62400, 62489, 62410, 62454]\n",
      "[62580, 62551, 62557, 62546, 62504, 62584, 62538, 62562, 62585, 62555]\n",
      "[62686, 62659, 62671, 62604, 62689, 62655, 62662, 62658, 62625, 62600]\n",
      "[62753, 62711, 62776, 62754, 62775, 62768, 62750, 62737, 62701, 62777]\n",
      "[62862, 62805, 62875, 62809, 62804, 62887, 62823, 62889, 62826, 62852]\n",
      "[62950, 62928, 62978, 62987, 62936, 62920, 62901, 62908, 62995, 62910]\n",
      "[63098, 63009, 63086, 63077, 63036, 63081, 63012, 63047, 63030, 63092]\n",
      "[63126, 63178, 63147, 63143, 63120, 63192, 63160, 63195, 63177, 63185]\n",
      "[63260, 63281, 63222, 63290, 63233, 63253, 63225, 63296, 63206, 63295]\n",
      "[63300, 63322, 63397, 63395, 63325, 63328, 63333, 63368, 63336, 63396]\n",
      "[63475, 63488, 63440, 63410, 63428, 63498, 63437, 63425, 63496, 63466]\n",
      "[63507, 63504, 63571, 63511, 63532, 63582, 63529, 63555, 63531, 63510]\n",
      "[63688, 63696, 63619, 63693, 63697, 63618, 63652, 63647, 63625, 63658]\n",
      "[63758, 63725, 63741, 63783, 63722, 63768, 63769, 63718, 63733, 63728]\n",
      "[63892, 63882, 63852, 63871, 63877, 63846, 63804, 63845, 63844, 63815]\n",
      "[63964, 63909, 63907, 63910, 63948, 63920, 63904, 63938, 63947, 63952]\n",
      "[64014, 64002, 64097, 64032, 64060, 64069, 64095, 64034, 64054, 64042]\n",
      "[64133, 64186, 64139, 64174, 64134, 64198, 64115, 64150, 64166, 64146]\n",
      "[64299, 64276, 64275, 64271, 64224, 64284, 64227, 64266, 64288, 64245]\n",
      "[64374, 64326, 64319, 64322, 64372, 64305, 64398, 64363, 64336, 64309]\n",
      "[64433, 64442, 64428, 64472, 64451, 64449, 64402, 64476, 64461, 64475]\n",
      "[64545, 64546, 64549, 64543, 64544, 64540, 64584, 64539, 64594, 64559]\n",
      "[64628, 64661, 64635, 64683, 64600, 64650, 64665, 64642, 64671, 64613]\n",
      "[64710, 64743, 64742, 64707, 64737, 64701, 64760, 64725, 64727, 64786]\n",
      "[64885, 64824, 64858, 64877, 64822, 64837, 64859, 64876, 64851, 64825]\n",
      "[64937, 64963, 64999, 64958, 64989, 64908, 64918, 64967, 64931, 64940]\n",
      "[65083, 65099, 65027, 65021, 65076, 65061, 65093, 65003, 65087, 65042]\n",
      "[65114, 65156, 65182, 65155, 65198, 65197, 65113, 65177, 65165, 65170]\n",
      "[65288, 65274, 65266, 65207, 65236, 65264, 65209, 65217, 65253, 65251]\n",
      "[65333, 65341, 65336, 65314, 65328, 65338, 65364, 65362, 65384, 65317]\n",
      "[65473, 65411, 65449, 65421, 65471, 65434, 65446, 65413, 65458, 65403]\n",
      "[65563, 65590, 65554, 65533, 65503, 65552, 65506, 65544, 65598, 65537]\n",
      "[65638, 65693, 65688, 65658, 65628, 65639, 65669, 65609, 65604, 65695]\n",
      "[65742, 65738, 65721, 65758, 65726, 65705, 65776, 65772, 65737, 65771]\n",
      "[65828, 65851, 65887, 65818, 65803, 65861, 65859, 65871, 65831, 65892]\n",
      "[65956, 65970, 65940, 65987, 65992, 65993, 65985, 65951, 65931, 65968]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "feature_number = 1024\n",
    "\n",
    "train_list_before=[]\n",
    "train_label_list=[]\n",
    "test_list_before=[]\n",
    "test_label_list =[]\n",
    "\n",
    "offset = 6000*10\n",
    "\n",
    "for i in range(60):\n",
    "    index = np.arange(100)     #generate numbers from 0 to 100\n",
    "    np.random.shuffle(index)        #shuffle the 100 values\n",
    "    index = [int(100*i+j + offset) for j in index]\n",
    "    print(index[10:20])\n",
    "    train_list_before.extend([conceptPairList[b] for b in index[0:40]]) \n",
    "    train_label_list.extend([1]*40)\n",
    "    train_list_before.extend([conceptNotPairList[b] for b in index[40:80]])\n",
    "    train_label_list.extend([0]*40)\n",
    "    test_list_before.extend([conceptPairList[b] for b in index[80:90]])\n",
    "    test_label_list.extend([1]*10)\n",
    "    test_list_before.extend([conceptNotPairList[b] for b in index[90:100]])\n",
    "    test_label_list.extend([0]*10)\n",
    "\n",
    "\n",
    "    \n",
    "train_list =[]\n",
    "test_list = []\n",
    "\n",
    "for line in train_list_before:\n",
    "    if line[0] in model.docvecs and line[1] in model.docvecs:\n",
    "        a= model.docvecs[line[0]]\n",
    "        b= model.docvecs[line[1]]\n",
    "        c = np.array((a, b))\n",
    "#         train_list.append(np.reshape(c, feature_number)) \n",
    "        train_list.append(np.reshape(c, feature_number, order='F'))\n",
    "\n",
    "\n",
    "test_list_ids={}\n",
    "for i, line in enumerate(test_list_before):\n",
    "    if line[0] in model.docvecs and line[1] in model.docvecs:\n",
    "        a= model.docvecs[line[0]]\n",
    "        b= model.docvecs[line[1]]\n",
    "        c = np.array((a, b))\n",
    "        test_list_ids[i] = (line[0], line[1])\n",
    "#         test_list.append(np.reshape(c, feature_number))\n",
    "        test_list.append(np.reshape(c, feature_number, order='F'))\n",
    "\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.10509553, -0.04225969, -0.11002547, ..., -0.00568312,\n",
      "        0.0049549 ,  0.00325755], dtype=float32), array([ 0.01995175, -0.09641007, -0.02109857, ..., -0.06566277,\n",
      "        0.01167493, -0.05647767], dtype=float32), array([-0.01588383, -0.1900169 , -0.05535665, ...,  0.04538804,\n",
      "       -0.03217676, -0.09448548], dtype=float32), array([ 0.06889442,  0.24594533,  0.09414224, ...,  0.25871456,\n",
      "        0.06104438,  0.08569817], dtype=float32), array([ 0.12309054,  0.3103413 ,  0.08827072, ...,  0.14672555,\n",
      "        0.01643647,  0.29918829], dtype=float32), array([ 0.17484045,  0.18587458,  0.06456479, ...,  0.23945893,\n",
      "        0.06898703,  0.0747689 ], dtype=float32), array([-0.00803294, -0.00444531, -0.0216737 , ...,  0.04504101,\n",
      "       -0.13326477, -0.16463144], dtype=float32), array([ 0.00400854, -0.04614465, -0.09716806, ...,  0.23006232,\n",
      "       -0.18869072, -0.15321375], dtype=float32), array([ 0.12309054,  0.23308435,  0.08827072, ...,  0.20277965,\n",
      "        0.01643647, -0.11098397], dtype=float32), array([ 0.22611549,  0.18202686,  0.14330469, ...,  0.35060194,\n",
      "       -0.06900405, -0.20526238], dtype=float32), array([ 0.18920621,  0.06059236,  0.28318018, ...,  0.20576748,\n",
      "        0.01875023,  0.01669537], dtype=float32), array([ 0.13402866,  0.06059236,  0.22169015, ...,  0.20576748,\n",
      "        0.03341931,  0.01669537], dtype=float32), array([ 0.19524099,  0.06059236,  0.2633203 , ...,  0.20576748,\n",
      "       -0.04633778,  0.01669537], dtype=float32), array([ 0.13515013,  0.06059236,  0.23894496, ...,  0.20576748,\n",
      "       -0.02431965,  0.01669537], dtype=float32), array([ 0.14681309,  0.06059236,  0.18861981, ...,  0.20576748,\n",
      "        0.00693331,  0.01669537], dtype=float32), array([ 0.14072427,  0.10519884, -0.11740884, ...,  0.11745843,\n",
      "       -0.0561699 ,  0.01731068], dtype=float32), array([ 0.3325797 ,  0.06059236,  0.35025004, ...,  0.20576748,\n",
      "        0.20466055,  0.01669537], dtype=float32), array([ 0.01810739,  0.06059236,  0.26105917, ...,  0.20576748,\n",
      "       -0.17762071,  0.01669537], dtype=float32), array([ 0.0795463 ,  0.10519884, -0.17913727, ...,  0.11745843,\n",
      "        0.03762052,  0.01731068], dtype=float32), array([ 0.21071161,  0.10519884, -0.06116898, ...,  0.11745843,\n",
      "       -0.07887554,  0.01731068], dtype=float32)]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "4800\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "print(train_list[30:50])\n",
    "print(train_label_list[30:50])\n",
    "print(len(train_list))\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "[0.93291666666666662]\n"
     ]
    }
   ],
   "source": [
    "#SVM \n",
    "\n",
    "\n",
    "print(len(train_list))\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(train_list, train_label_list)\n",
    "\n",
    "train_errors=[]\n",
    "train_errors.append(clf.score(train_list, train_label_list))\n",
    "print(train_errors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptLabelDict={}\n",
    "errors=[]\n",
    "\n",
    "def read_label(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                conceptLabelDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "label_file = \"/home/hao/AnacondaProjects/MLOntology/ontClassLabels.txt\"\n",
    "read_label(label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 6 predicted label [0], but true label is 1\n",
      "('362341004', '128330006') Concept Pairs: (entire brodmann areas 17 (striate cortex), 18 (parastriate cortex) and 19 (peristriate cortex) of occipital lobe --- structure of brodmann areas 17 (striate cortex), 18 (parastriate cortex) and 19 (peristriate cortex) of the occipital lobe)\n",
      "index 32 predicted label [1], but true label is 0\n",
      "('182238002', '360794000') Concept Pairs: (entire articular capsule --- capsule of interphalangeal joint of toe)\n",
      "index 53 predicted label [1], but true label is 0\n",
      "('730043004', '23090001') Concept Pairs: (entire joint capsule of upper limb --- structure of capsule of carpometacarpal joint)\n",
      "index 60 predicted label [0], but true label is 1\n",
      "('86048008', '2305000') Concept Pairs: (structure of spinous process of fourth cervical vertebra --- structure of spinous process of cervical vertebra)\n",
      "index 67 predicted label [0], but true label is 1\n",
      "('313060009', '123859001') Concept Pairs: (ligament of sternum --- structure of ligament of joint)\n",
      "index 122 predicted label [0], but true label is 1\n",
      "('369160002', '75551009') Concept Pairs: (entire anterior tubercle of thalamus --- structure of anterior tubercle of thalamus)\n",
      "index 123 predicted label [0], but true label is 1\n",
      "('7404008', '81468006') Concept Pairs: (structure of anterior semicircular duct --- semicircular duct structure)\n",
      "index 126 predicted label [0], but true label is 1\n",
      "('303623000', '80769008') Concept Pairs: (structure of posterior tibial lymph node --- structure of tibial lymph node)\n",
      "index 127 predicted label [0], but true label is 1\n",
      "('278981008', '33594008') Concept Pairs: (entire terminal bronchiole --- structure of terminal bronchiole)\n",
      "index 165 predicted label [0], but true label is 1\n",
      "('180941005', '80622005') Concept Pairs: (entire abducens nerve --- abducens nerve structure)\n",
      "index 171 predicted label [1], but true label is 0\n",
      "('311411003', '297223007') Concept Pairs: (jejunostomy - stoma --- divided colostomy stoma)\n",
      "index 174 predicted label [1], but true label is 0\n",
      "('310873008', '297223007') Concept Pairs: (duodenostomy - stoma --- divided colostomy stoma)\n",
      "index 184 predicted label [0], but true label is 1\n",
      "('53017002', '24486003') Concept Pairs: (structure of transplanted embryo --- transplant)\n",
      "index 185 predicted label [0], but true label is 1\n",
      "('363393007', '448868009') Concept Pairs: (malignant tumor of tonsil --- malignant neoplasm of lateral wall of oropharynx)\n",
      "index 228 predicted label [0], but true label is 1\n",
      "('23657002', '72276004') Concept Pairs: (structure of carotid sheath --- structure of fascia of head, orbit and/or neck)\n",
      "index 243 predicted label [0], but true label is 1\n",
      "('64551004', '78653002') Concept Pairs: (lamina muscularis of gastric mucosa --- gastric mucous membrane structure)\n",
      "index 248 predicted label [0], but true label is 1\n",
      "('245954004', '182376006') Concept Pairs: (t4/t5 part of supraspinous ligament --- thoracic part of supraspinous ligament)\n",
      "index 263 predicted label [0], but true label is 1\n",
      "('729338001', '280326001') Concept Pairs: (entire ascending superficial branch of cervical plexus --- ascending superficial branch of cervical plexus)\n",
      "index 270 predicted label [1], but true label is 0\n",
      "('125258001', '125261000') Concept Pairs: (complete protrusion --- incomplete hernia)\n",
      "index 277 predicted label [1], but true label is 0\n",
      "('5974001', '125261000') Concept Pairs: (pressure cone --- incomplete hernia)\n",
      "index 288 predicted label [0], but true label is 1\n",
      "('727767008', '182375005') Concept Pairs: (entire thoracic interspinous ligament --- thoracic interspinous ligament)\n",
      "index 290 predicted label [1], but true label is 0\n",
      "('384709000', '1791001') Concept Pairs: (sprain --- radiation injury with fibrosis)\n",
      "index 293 predicted label [1], but true label is 0\n",
      "('43265003', '1791001') Concept Pairs: (constriction injury --- radiation injury with fibrosis)\n",
      "index 300 predicted label [0], but true label is 1\n",
      "('589001', '21814001') Concept Pairs: (interventricular septum structure --- cardiac ventricular structure)\n",
      "index 312 predicted label [1], but true label is 0\n",
      "('21444008', '1791001') Concept Pairs: (microglial nodules --- radiation injury with fibrosis)\n",
      "index 321 predicted label [0], but true label is 1\n",
      "('699979002', '279508004') Concept Pairs: (structure of ligament of thyroid cartilage --- laryngeal ligament)\n",
      "index 341 predicted label [0], but true label is 1\n",
      "('245429006', '49832006') Concept Pairs: (entire rectosigmoid junction --- structure of rectosigmoid junction)\n",
      "index 366 predicted label [0], but true label is 1\n",
      "('14221007', '51722002') Concept Pairs: (structure of rete testis --- seminiferous tubule structure)\n",
      "index 368 predicted label [0], but true label is 1\n",
      "('711514000', '47990007') Concept Pairs: (structure of wall of artery of head, neck and/or brain --- structure of artery of head, neck and/or brain)\n",
      "index 381 predicted label [0], but true label is 1\n",
      "('241234000', '303827001') Concept Pairs: (abdominal angiography --- trunk angiography)\n",
      "index 447 predicted label [0], but true label is 1\n",
      "('36765005', '118633002') Concept Pairs: (structure of subclavian artery --- artery of thorax)\n",
      "index 481 predicted label [0], but true label is 1\n",
      "('2687004', '68288006') Concept Pairs: (structure of bowman's space --- glomerulus structure)\n",
      "index 494 predicted label [1], but true label is 0\n",
      "('60115006', '11884006') Concept Pairs: (congenital malposition --- congenital hyperrotation)\n",
      "index 501 predicted label [0], but true label is 1\n",
      "('362354006', '88442005') Concept Pairs: (entire corpus callosum --- corpus callosum structure)\n",
      "index 502 predicted label [0], but true label is 1\n",
      "('33096000', '106233006') Concept Pairs: (vertical --- topographical modifier)\n",
      "index 509 predicted label [0], but true label is 1\n",
      "('281088000', '609617007') Concept Pairs: (anorectal structure --- structure of pelvic region of trunk)\n",
      "index 546 predicted label [0], but true label is 1\n",
      "('46728006', '362923004') Concept Pairs: (structure of masseter fascia --- masseter muscle part)\n",
      "index 548 predicted label [0], but true label is 1\n",
      "('181472009', '36141000') Concept Pairs: (entire skin of cheek --- skin structure of cheek)\n",
      "index 550 predicted label [1], but true label is 0\n",
      "('46675001', '13129009') Concept Pairs: (osteoporotic fracture --- fracture, open, incomplete)\n",
      "index 559 predicted label [1], but true label is 0\n",
      "('370608000', '13129009') Concept Pairs: (slab fracture --- fracture, open, incomplete)\n",
      "index 561 predicted label [0], but true label is 1\n",
      "('239144007', '399940000') Concept Pairs: (congenital erector pili hamartoma --- hamartoma of muscle)\n",
      "index 569 predicted label [0], but true label is 1\n",
      "('272700008', '276149009') Concept Pairs: (entire base of phalanx of thumb --- entire base of phalanx of hand)\n",
      "index 582 predicted label [0], but true label is 1\n",
      "('254873002', '92260003') Concept Pairs: (benign germ cell tumor of ovary --- benign neoplasm of ovary)\n",
      "index 589 predicted label [0], but true label is 1\n",
      "('368646007', '66000000') Concept Pairs: (entire isthmus of osseous portion of auditory canal --- structure of isthmus of osseous portion of auditory canal)\n",
      "index 602 predicted label [0], but true label is 1\n",
      "('297866007', '20797009') Concept Pairs: (entire embryonic mantle layer --- structure of embryonic mantle layer)\n",
      "index 620 predicted label [0], but true label is 1\n",
      "('57213007', '360464007') Concept Pairs: (structure of intermediate olfactory striae --- olfactory striae)\n",
      "index 625 predicted label [0], but true label is 1\n",
      "('700001005', '699957007') Concept Pairs: (gastrocnemius muscle and/or tendon structure --- triceps surae muscle and/or tendon structure)\n",
      "index 628 predicted label [0], but true label is 1\n",
      "('13698008', '67185001') Concept Pairs: (intranuclear inclusion --- subcellular structure)\n",
      "index 631 predicted label [1], but true label is 0\n",
      "('79654002', '89347008') Concept Pairs: (edema --- chronic passive congestion)\n",
      "index 639 predicted label [1], but true label is 0\n",
      "('41699000', '89347008') Concept Pairs: (effusion --- chronic passive congestion)\n",
      "index 648 predicted label [0], but true label is 1\n",
      "('734079001', '20462008') Concept Pairs: (multicystic ameloblastoma --- ameloblastoma)\n",
      "index 658 predicted label [1], but true label is 0\n",
      "('445925008', '128799007') Concept Pairs: (lymphomatous infiltration --- hodgkin lymphoma, lymphocyte-rich)\n",
      "index 704 predicted label [0], but true label is 1\n",
      "('362353000', '89359007') Concept Pairs: (entire parietal operculum --- parietal operculum structure)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 721 predicted label [0], but true label is 1\n",
      "('273225008', '273216002') Concept Pairs: (nogier auricular pancreas --- nogier auricular points)\n",
      "index 745 predicted label [0], but true label is 1\n",
      "('46729003', '367916008') Concept Pairs: (entire crest of head of twelfth rib --- structure of crest of head of twelfth rib)\n",
      "index 765 predicted label [0], but true label is 1\n",
      "('272701007', '276150009') Concept Pairs: (entire shaft of phalanx of thumb --- entire shaft of phalanx of hand)\n",
      "index 767 predicted label [0], but true label is 1\n",
      "('731459002', '609615004') Concept Pairs: (entire wall of abdominal segment of trunk --- structure of wall of abdominal segment of trunk)\n",
      "index 769 predicted label [0], but true label is 1\n",
      "('361305002', '361104005') Concept Pairs: (entire tubercle of fifth rib --- entire tubercle of rib)\n",
      "index 801 predicted label [0], but true label is 1\n",
      "('361829002', '33883002') Concept Pairs: (entire joint of head --- joint structure of head)\n",
      "index 825 predicted label [0], but true label is 1\n",
      "('420028002', '128803008') Concept Pairs: (primary cutaneous marginal zone b-cell lymphoma --- marginal zone b-cell lymphoma)\n",
      "index 846 predicted label [0], but true label is 1\n",
      "('64554007', '65352000') Concept Pairs: (structure of shaft of fourth metacarpal bone --- bone structure of fourth metacarpal)\n",
      "index 848 predicted label [0], but true label is 1\n",
      "('730410006', '361439004') Concept Pairs: (entire tail fold --- tail fold)\n",
      "index 849 predicted label [0], but true label is 1\n",
      "('734080003', '400078005') Concept Pairs: (solitary fibrous tumor and hemangiopericytoma grade 1 --- benign fibromatous neoplasm - category)\n",
      "index 861 predicted label [0], but true label is 1\n",
      "('369172008', '279147005') Concept Pairs: (entire ventral posteromedial nucleus of thalamus --- entire ventral posterior nucleus of thalamus)\n",
      "index 862 predicted label [0], but true label is 1\n",
      "('64556009', '245353004') Concept Pairs: (structure of intermediate common iliac lymph node --- common iliac node)\n",
      "index 885 predicted label [0], but true label is 1\n",
      "('25758003', '721025003') Concept Pairs: (left nasolacrimal duct structure --- external structure of left eye region)\n",
      "index 908 predicted label [0], but true label is 1\n",
      "('424743000', '714295000') Concept Pairs: (entire muscle of modiolar muscle group --- entire craniofacial muscle)\n",
      "index 957 predicted label [1], but true label is 0\n",
      "('372147008', '40459000') Concept Pairs: (kaposi's sarcoma - category --- malignant mixed tumor, carcinomatous type)\n",
      "index 963 predicted label [0], but true label is 1\n",
      "('244385005', '277699000') Concept Pairs: (entire left ventricle --- entire cardiac ventricle)\n",
      "index 981 predicted label [0], but true label is 1\n",
      "('60361003', '69778002') Concept Pairs: (structure of mucous membrane of renal pelvis --- structure of soft tissues of abdomen)\n",
      "index 986 predicted label [0], but true label is 1\n",
      "('68751009', '84765007') Concept Pairs: (structure of pterygoid process of sphenoid bone --- pterygoid region structure)\n",
      "index 989 predicted label [0], but true label is 1\n",
      "('93917007', '363422006') Concept Pairs: (primary malignant neoplasm of nasal cavity --- malignant tumor of nasal cavity)\n",
      "index 1006 predicted label [0], but true label is 1\n",
      "('361308000', '361104005') Concept Pairs: (entire tubercle of eighth rib --- entire tubercle of rib)\n",
      "index 1023 predicted label [0], but true label is 1\n",
      "('94441008', '363489000') Concept Pairs: (secondary malignant neoplasm of neck --- malignant tumor of neck)\n",
      "index 1036 predicted label [1], but true label is 0\n",
      "('69183002', '12540003') Concept Pairs: (change in cytochemical muscle architecture --- muscle fiber atrophy, type ii)\n",
      "index 1061 predicted label [0], but true label is 1\n",
      "('280567005', '280563009') Concept Pairs: (pretarsal space of upper eyelid --- eyelid layer)\n",
      "index 1067 predicted label [0], but true label is 1\n",
      "('39915008', '282004003') Concept Pairs: (fifth toe structure --- lesser toe structure)\n",
      "index 1105 predicted label [0], but true label is 1\n",
      "('360782009', '181788008') Concept Pairs: (retinaculum of peroneal muscles --- fascia of foot)\n",
      "index 1106 predicted label [0], but true label is 1\n",
      "('35721009', '47471008') Concept Pairs: (structure of deep popliteal lymph node --- popliteal lymph node structure)\n",
      "index 1133 predicted label [1], but true label is 0\n",
      "('125272005', '123625002') Concept Pairs: (expanding aneurysm --- thrombosed atherosclerotic aneurysm)\n",
      "index 1184 predicted label [0], but true label is 1\n",
      "('254870004', '254869000') Concept Pairs: (choriocarcinoma of ovary --- malignant germ cell tumor of ovary)\n",
      "index 1191 predicted label [1], but true label is 0\n",
      "('73728008', '55794002') Concept Pairs: (maturation acceleration --- hypocalcification)\n"
     ]
    }
   ],
   "source": [
    "for i, (item, label) in enumerate(zip(test_list, test_label_list)):\n",
    "    result = clf.predict([item])\n",
    "    if result != label:\n",
    "        print(\"index %d predicted label %s, but true label is %s\" % (i, result, label))\n",
    "        idpair = test_list_ids[i] \n",
    "        concept1 = conceptLabelDict[idpair[0]]\n",
    "        concept2 = conceptLabelDict[idpair[1]]\n",
    "        print(\"%s Concept Pairs: (%s --- %s)\" % (idpair, concept1, concept2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "1200\n",
      "[1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# m3 = np.array((a,d))\n",
    "# m3 = np.reshape(m3, 400, order='F')\n",
    "print(len(test_list))\n",
    "result = clf.predict(test_list)\n",
    "\n",
    "print(result.size)\n",
    "\n",
    "\n",
    "print(result[:29])\n",
    "print(np.array(test_label_list[:29]))\n",
    "\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   6   32   53   60   67  122  123  126  127  165  171  174  184  185  228\n",
      "  243  248  263  270  277  288  290  293  300  312  321  341  366  368  381\n",
      "  447  481  494  501  502  509  546  548  550  559  561  569  582  589  602\n",
      "  620  625  628  631  639  648  658  704  721  745  765  767  769  801  825\n",
      "  846  848  849  861  862  885  908  957  963  981  986  989 1006 1023 1036\n",
      " 1061 1067 1105 1106 1133 1184 1191]\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "err_ids=np.flatnonzero(result != test_label_list)\n",
    "\n",
    "print(err_ids)\n",
    "print(err_ids.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931666666667\n",
      "0.880248800959\n",
      "0.931574672615\n",
      "0.931666666667\n",
      "0.931758660718\n",
      "[ 0.9340836   0.92906574]\n",
      "[ 0.96833333  0.895     ]\n",
      "[ 0.90217391  0.96582734]\n",
      "0.934000625586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "print(accuracy_score(result, test_label_list))\n",
    "print(average_precision_score(result, test_label_list))\n",
    "\n",
    "print(f1_score(result, test_label_list, average='macro') ) \n",
    "\n",
    "print(f1_score(result, test_label_list, average='micro')  )\n",
    "\n",
    "print(f1_score(result, test_label_list, average='weighted') )\n",
    "\n",
    "print(f1_score(result, test_label_list, average=None))\n",
    "\n",
    "print(precision_score(result, test_label_list, average=None))\n",
    "print(recall_score(result, test_label_list, average=None))\n",
    "\n",
    "print(roc_auc_score(result, test_label_list, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label_list_m = np.eye(2)[train_label_list]\n",
    "# test_label_list_m = np.eye(2)[test_label_list]\n",
    "# print(test_label_list_m[10:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 100\n",
      "Train Loss: 0.687326 Acc: [0.47999999]\n",
      "None 200\n",
      "Train Loss: 0.666688 Acc: [0.5]\n",
      "None 300\n",
      "Train Loss: 0.653269 Acc: [0.5]\n",
      "None 400\n",
      "Train Loss: 0.547272 Acc: [0.87]\n",
      "None 500\n",
      "Train Loss: 0.415417 Acc: [0.89999998]\n",
      "None 600\n",
      "Train Loss: 0.320903 Acc: [0.89999998]\n",
      "None 700\n",
      "Train Loss: 0.237224 Acc: [0.94999999]\n",
      "None 800\n",
      "Train Loss: 0.230004 Acc: [0.93000001]\n",
      "None 900\n",
      "Train Loss: 0.173643 Acc: [0.94]\n",
      "None 1000\n",
      "Train Loss: 0.1187 Acc: [0.98000002]\n",
      "None 1100\n",
      "Train Loss: 0.128572 Acc: [0.95999998]\n",
      "None 1200\n",
      "Train Loss: 0.157483 Acc: [0.94]\n",
      "None 1300\n",
      "Train Loss: 0.102974 Acc: [0.97000003]\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "import numpy as np\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "'''\n",
    "In the data, there are 2 classes and every class has 3000 samples and every sample has 512 features\n",
    "The first 3000 samples are from class 0, second 3000 are from class 1\n",
    "'''\n",
    "# DATA_DIR = ''\n",
    "CLASS_NUM = 2       #there are 2 classes\n",
    "SPLIT_PERCENT = 0.8     #split the data into 80% for training and 20% for testing\n",
    "FEATURE_NUM = 1024   \n",
    "TRAIN_ITER = 1500    #the number of iterations for training\n",
    "display_step = 100        #how many iterations to display the results\n",
    "\n",
    "\n",
    "train_num = int(3000*SPLIT_PERCENT)     #the number of samples for training\n",
    "\n",
    "train_feature = train_list      #training features (list of list)\n",
    "train_y = train_label_list        #training lables    (list)\n",
    "test_feature = test_list       #test features  (list of list)\n",
    "test_y = test_label_list         #test labels    (list)\n",
    "\n",
    "\n",
    "y_m = np.eye(2)[train_y]\n",
    "test_y_m = np.eye(2)[test_y]\n",
    "\n",
    "'''\n",
    "y = wx+b        (vectors)\n",
    "'''\n",
    "#function to get variables 'w'\n",
    "def weight_variable(shape, num):\n",
    "    initial = tf.truncated_normal(shape, stddev=1/num)\n",
    "    return tf.Variable(initial, name='weight')\n",
    "\n",
    "#the bias 'b' in the equations\n",
    "def bias_variable(shape, num):\n",
    "    initial = tf.constant(0.0001, shape=shape)\n",
    "    return tf.Variable(initial, name='bias')\n",
    "\n",
    "#convolutional process\n",
    "def conv1d(x, W):\n",
    "    return tf.nn.conv1d(x, W, stride=1, padding='SAME')     #x: variable, w: weight, stride and padding (padding can be ignored currently) \n",
    "\n",
    "#pooling process\n",
    "def max_pool_1x1(x, shape):\n",
    "    x=tf.reshape(x,shape)       #it is transfered into four dimensions, but the other three are 1\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, 4, 1],\n",
    "                        strides=[1, 1, 2, 1], padding='SAME')\n",
    "\n",
    "'''\n",
    "The feature is 3 dimensional data.  [batch, length, channel] \n",
    "batch is usually ignored (for example there are 100 samples in a batch, so samples should not be modified mutually), length and channel are shown in the paper.\n",
    "At first, the length is 512, and channel is 1.\n",
    "Because our data are time series data, so length is enough, but for images, it may be [batch, length, width, channel]\n",
    "'''\n",
    "# the convolutional layer\n",
    "def layer(features, f, input_n, channel, hidden_units, layer_index):\n",
    "    \"\"\"Construct a convolutional layer\n",
    "    Args:\n",
    "    features: Features placeholder, from the previous layer.\n",
    "    f: the length\n",
    "    input_n: Size of the features used in the convention.\n",
    "    hidden_units: Size of the current hidden layer.\n",
    "    layer_index: the index of layer\n",
    "    Returns:\n",
    "    hidden units: The unit output for the next layer.\n",
    "    weights: the weights in the current hidden layer\n",
    "    \"\"\"\n",
    "    # Hidden 1\n",
    "    with tf.name_scope('hidden'+str(layer_index)) as scope:     # name scope may be ignored first\n",
    "        with tf.name_scope(\"weight\"):\n",
    "            weights = weight_variable([input_n, channel, hidden_units], math.sqrt(f))\n",
    "\n",
    "        with tf.name_scope(\"bias\"):\n",
    "            biases = bias_variable([hidden_units], math.sqrt(f))\n",
    "    hidden = relu(conv1d(features, weights) + biases, 0.01)\n",
    "    shape = [-1,1,f,hidden_units]\n",
    "    h_pool1 = max_pool_1x1(hidden,shape)\n",
    "    return h_pool1, weights\n",
    "\n",
    "# fully connected layer, here the data are two dimension, [batch, length]\n",
    "def densely_connect(features, input_n, hidden_units):\n",
    "    \"\"\"Construct a fully (densely) connected layer.\n",
    "    Args:\n",
    "    features: Features placeholder, from the previous layer.\n",
    "    input_n: Size of units in the previous layer.\n",
    "    hidden_units: Size of the current hidden layer.\n",
    "    Returns:\n",
    "    logits: The estimated output in last layer.\n",
    "    weights: the weights in the hidden layer\n",
    "    \"\"\"\n",
    "    with tf.name_scope('softmax_linear') as dense:\n",
    "        with tf.name_scope(\"weight\"):\n",
    "            weights = weight_variable([input_n, hidden_units], math.sqrt(input_n))\n",
    "        with tf.name_scope(\"bias\"):\n",
    "            biases = bias_variable([hidden_units], math.sqrt(input_n))\n",
    "    logits = relu(tf.matmul(features, weights) + biases, 0.01)      # the matrix product operation\n",
    "    return logits, weights\n",
    "\n",
    "# dropout layer (it is not necessary)\n",
    "# randomly set (1-keep_prob) percentage of units to be zero\n",
    "def dropout(features, input_n, hidden_units, keep_prob):\n",
    "    with tf.name_scope('dropout'):\n",
    "        with tf.name_scope(\"weight\"):\n",
    "            weights = weight_variable([input_n, hidden_units], math.sqrt(input_n))\n",
    "        with tf.name_scope(\"bias\"):\n",
    "            biases = bias_variable([hidden_units], math.sqrt(input_n))\n",
    "    h_fc1_drop = tf.nn.dropout(features, keep_prob)\n",
    "    drop_out = relu(tf.matmul(features, weights) + biases, 0.01)\n",
    "    return drop_out\n",
    "\n",
    "# calculate the loss in the neural network\n",
    "def loss(logits, labels):\n",
    "    \"\"\"Calculates the loss from the logits and the labels.\n",
    "    Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int32 - [batch_size, NUM_CLASSES].\n",
    "    Returns:\n",
    "    loss: Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"Loss\"):\n",
    "        labels = tf.to_int64(labels)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=labels, logits=logits, name='xentropy')\n",
    "    # tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "    return tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "\n",
    "def next_batch(data, label, num):\n",
    "    \"\"\"Generate the next batch randomly\n",
    "    Args:\n",
    "    data: training data.\n",
    "    label: training label.\n",
    "    num: the size in a batch\n",
    "    Returns:\n",
    "    next batch's training features and labels.\n",
    "    \"\"\"\n",
    "    index = np.arange(len(data))\n",
    "    np.random.shuffle(index)\n",
    "#     train_feature = data[np.array(index)[0:num]]\n",
    "#     train_label = label[np.array(index)[0:num]]\n",
    "    train_feature_batch = [data[b] for b in index[0:num]]\n",
    "    train_feature_batch = np.asarray(train_feature_batch)\n",
    "    train_label_batch = [label[b] for b in index[0:num]]\n",
    "    train_label_batch = np.asarray(train_label_batch)\n",
    "    return train_feature_batch, train_label_batch\n",
    "\n",
    "def relu(x, alpha=0., max_value=None):\n",
    "    '''ReLU.\n",
    "    alpha: slope of negative section.\n",
    "    '''\n",
    "    negative_part = tf.nn.relu(-x)\n",
    "    x = tf.nn.relu(x)\n",
    "    if max_value is not None:\n",
    "        x = tf.clip_by_value(x, tf.cast(0., dtype=tf.float32),\n",
    "                             tf.cast(max_value, dtype=tf.float32))\n",
    "    x -= tf.constant(alpha, dtype=tf.float32) * negative_part\n",
    "    return x\n",
    "\n",
    "#define a session to run the model\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#place holders for training features and label\n",
    "#None means the value is variable\n",
    "x = tf.placeholder(tf.float32, shape=[None, FEATURE_NUM])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, CLASS_NUM])\n",
    "\n",
    "# decide whether it is training or testing, it is not used in our model, but it may be used\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "#from [-1, 512, 1] -> [-1, 256, 32] -> [-1, 128, 64] -> [-1, 64, 64] -> [-1, 32, 64] -> [-1, 16, 64] -> [-1, 8, 64] -> [-1, 200]\n",
    "\n",
    "#6 hidden layers\n",
    "x_1 = tf.reshape(x, [-1,FEATURE_NUM,1])\n",
    "h_pool0, w0 = layer(x_1, FEATURE_NUM, 15, 1, 32, 0)\n",
    "h_pool0 = tf.reshape(h_pool0, [-1,512,32])\n",
    "h_pool1, w1 = layer(h_pool0, 512, 10, 32, 64, 1)\n",
    "\n",
    "h_pool1 = tf.reshape(h_pool1, [-1,256,64])\n",
    "h_pool2, w2 = layer(h_pool1, 256, 10, 64, 64, 2)\n",
    "h_pool2 = tf.reshape(h_pool2, [-1,128,64])\n",
    "h_pool3, w3 = layer(h_pool2, 128, 10, 64, 64, 3)\n",
    "h_pool3 = tf.reshape(h_pool3, [-1,64,64])\n",
    "h_pool4, w4 = layer(h_pool3, 64, 5, 64, 64, 4)\n",
    "h_pool4 = tf.reshape(h_pool4, [-1,32,64])\n",
    "h_pool5, w5 = layer(h_pool4, 32, 5, 64, 64, 5)\n",
    "h_pool5 = tf.reshape(h_pool5, [-1,16,64])\n",
    "h_pool6, w6 = layer(h_pool5, 16, 5, 64, 64, 6)\n",
    "h_pool6 = tf.reshape(h_pool6, [-1,8,64])\n",
    "\n",
    "#densely connected: 200 units\n",
    "h_pool_flat = tf.reshape(h_pool6, [-1, 8*64])\n",
    "h_dc, w_d = densely_connect(h_pool_flat, 8*64, 200)\n",
    "\n",
    "#dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "y_conv=dropout(h_dc, (int)(h_dc.get_shape()[1]), CLASS_NUM, keep_prob)\n",
    "\n",
    "\n",
    "beta = 0.001\n",
    "cross_entropy = loss(y_conv, y_)\n",
    "loss = cross_entropy +beta*(tf.nn.l2_loss(w0) + tf.nn.l2_loss(w1)+tf.nn.l2_loss(w2)+tf.nn.l2_loss(w3)+tf.nn.l2_loss(w4)+tf.nn.l2_loss(w5)+tf.nn.l2_loss(w6)+tf.nn.l2_loss(w_d))  #L2 regularization\n",
    "epsilon = 1e-5      # learning rate\n",
    "train_step = tf.train.AdamOptimizer(epsilon).minimize(loss)     #optimization function, our goal is to minimize the loss\n",
    "\n",
    "predict = tf.argmax(y_conv,1)   #the predicted class\n",
    "\n",
    "# calculate the accuray, the corrected classified divided by the total size\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "#saver to save the training check point\n",
    "# variables can be restored in a new model by 'saver.restore(sess, save_path)'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())  #initialize the variables\n",
    "\n",
    "\n",
    "for i in range(1,TRAIN_ITER):       #training iterations\n",
    "    d, l = next_batch(train_feature, y_m, 100)      # get 100 samples in one batch\n",
    "#     print(\"d size is %s, l size is %s \"% (len(d), len(l)))\n",
    "#     print(\"d size is %s, l size is %s \"% (len(d[0]), len(l[0])))\n",
    "    _, ls=sess.run([train_step,cross_entropy], feed_dict={x: d, y_: l, keep_prob: 1, is_training:True})     #run the train step (optimization function), the second one is just to show the loss in this iteration.   THE FEED dictionary is to feed the place holders which are needed in the optimization function.\n",
    "    \n",
    "    if i%display_step==0:\n",
    "        print(_, i)\n",
    "        acc = sess.run([accuracy], feed_dict={x: d, y_: l, keep_prob: 1, is_training:False})\n",
    "        print(\"Train Loss:\", ls, \"Acc:\", acc)\n",
    "\n",
    "# sess.run  or tensor.eval are two ways\n",
    "# get the accuracy in the testing data\n",
    "print(accuracy.eval(session=sess, feed_dict={x:test_feature, y_:test_y_m, keep_prob: 1, is_training:False}))\n",
    "\n",
    "\n",
    "# save the model results\n",
    "save_path = saver.save(sess, \"./model-noleaky.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = sess.run(predict, feed_dict={x:test_feature, keep_prob:1, is_training:False})\n",
    "print(y_pred[:20])\n",
    "print(test_y[:20])\n",
    "\n",
    "\n",
    "err_ids=np.flatnonzero(y_pred != test_y)\n",
    "\n",
    "print(err_ids)\n",
    "print(err_ids.size)\n",
    "for err_id in err_ids:\n",
    "    print(\"index %d predicted label %s, but true label is %s\" % (err_id, y_pred[err_id], test_y[err_id]))\n",
    "    idpair = test_list_ids[err_id] \n",
    "    concept1 = conceptLabelDict[idpair[0]]\n",
    "    concept2 = conceptLabelDict[idpair[1]]\n",
    "    print(\"%s Concept Pairs: (%s --- %s)\" % (idpair, concept1, concept2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = y_pred\n",
    "test_label_list = test_y\n",
    "\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "print(accuracy_score(result, test_label_list))\n",
    "print(average_precision_score(result, test_label_list))\n",
    "\n",
    "print(f1_score(result, test_label_list, average='macro') ) \n",
    "\n",
    "print(f1_score(result, test_label_list, average='micro')  )\n",
    "\n",
    "print(f1_score(result, test_label_list, average='weighted') )\n",
    "\n",
    "print(f1_score(result, test_label_list, average=None))\n",
    "\n",
    "print(precision_score(result, test_label_list, average=None))\n",
    "print(recall_score(result, test_label_list, average=None))\n",
    "\n",
    "print(roc_auc_score(result, test_label_list, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "err_ids=np.flatnonzero(result != test_label_list)\n",
    "\n",
    "print(err_ids)\n",
    "print(err_ids.size)\n",
    "for err_id in err_ids:\n",
    "    idpair = test_list_ids[err_id] \n",
    "    print(idpair)\n",
    "    concept1 = conceptLabelDict[idpair[0]]\n",
    "    concept2 = conceptLabelDict[idpair[1]]\n",
    "    print(\"(Concept 1 %s ---- Concept 2 %s)\" % (concept1, concept2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plist = [[1,2,3], [3,4,5], [3,4,5], [5,6,7],[2,3,7]]\n",
    "\n",
    "plist.extend([1]*4)\n",
    "print(plist)\n",
    "\n",
    "index = np.arange(5)\n",
    "\n",
    "c = [plist[b] for b in index[:2]]\n",
    "print(c)\n",
    "c.extend([plist[b] for b in index[2:]])\n",
    "print(c)\n",
    "\n",
    "for i in range(3):      # i is the class index, for example, i==0 for class 0, i==1 for class 1 ...\n",
    "    index = np.arange(30)     #generate numbers from 0 to 2999\n",
    "    np.random.shuffle(index)        #shuffle the 3000 values\n",
    "    index = [int(300*i+j) for j in index]\n",
    "    print(index)\n",
    "    print(np.array(index)[0:5])\n",
    "    print(np.array(index)[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([1,2,3])\n",
    "y=np.append(y, [1]*4)\n",
    "y= np.append(y, [0])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/MLOntology/model1\"\n",
    "\n",
    "print(path)\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(inferred_vector)\n",
    "print(inferred_vector.size)\n",
    "# pprint(model.docvecs.most_similar([inferred_vector], topn=20))\n",
    "\n",
    "\n",
    "path = \"D:/MLOntology/model0\"\n",
    "\n",
    "print(path)\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(inferred_vector)\n",
    "print(inferred_vector.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.docvecs['SENT_5690']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "print(X)\n",
    "print(y)\n",
    "train_errors=[]\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y)  \n",
    "\n",
    "train_errors.append(clf.score(X, y))\n",
    "print(train_errors)\n",
    "X_test=[[2,2]]\n",
    "y_test = [1]\n",
    "test_errors=[]\n",
    "clf.predict(X_test)\n",
    "\n",
    "test_errors.append(clf.score(X_test, y_test))\n",
    "print(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "a= model.docvecs[0]\n",
    "b= model.docvecs[1]\n",
    "m1 = np.array((a, b))\n",
    "\n",
    "# print(np.reshape(m1, 1024))\n",
    "# print(np.reshape(m1, 400, order='F')) # two ways of reshape\n",
    "\n",
    "c= model.docvecs[2]\n",
    "d= model.docvecs[3]\n",
    "print(c.shape)\n",
    "print(d.shape)\n",
    "print(c.shape[0]+d.shape[0])\n",
    "m2 = np.array((c, d))\n",
    "\n",
    "m1 = np.reshape(m1, 1024)\n",
    "m2 = np.reshape(m2, 1024)\n",
    "# m1 = np.reshape(m1, 1024, order='F')\n",
    "# m2 = np.reshape(m2, 1024, order='F')\n",
    "\n",
    "print(m1)\n",
    "\n",
    "X = [m1, m2]\n",
    "print(X)\n",
    "\n",
    "XX = np.append(m1, m2)\n",
    "print(XX)\n",
    "\n",
    "y = [0, 1]\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X, y)\n",
    "\n",
    "m3 = np.array((a,d))\n",
    "m3 = np.reshape(m3, 1024, order='F')\n",
    "\n",
    "result = clf.predict([m3])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a=  np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "m1 = np.array((a, b))\n",
    "print(m1)\n",
    "\n",
    "m2 = np.vstack((a, b)).T\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDict={}\n",
    "testDict[0] = (\"a\", \"b\")\n",
    "print(testDict[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,1,0,1,0,1,0])\n",
    "b = np.array([0,1,0,1,0,1,1])\n",
    "\n",
    "np.flatnonzero(a!=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
