{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import multiprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['37225000', '52860004', 1], ['159386001', '159385002', 1], ['233836002', '233835003', 1], ['233836002', '304914007', 1], ['224923003', '224717003', 1]]\n",
      "502206\n"
     ]
    }
   ],
   "source": [
    "conceptPairDict={}\n",
    "errors=[]\n",
    "conceptPairList=[]\n",
    "\n",
    "def read_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                conceptPairList.append([splitted[1], splitted[2].replace(\"\\r\\n\", \"\"), 1])\n",
    "#                 conceptPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "pair_file = \"D:/workspace/MLDataProcessing/output/ontHierarchy.txt\"\n",
    "read_pair(pair_file)\n",
    "\n",
    "first2pairs = conceptPairList[10:15]\n",
    "print(first2pairs)\n",
    "print(len(conceptPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['273187009', '272765000', 0], ['272877001', '272765000', 0], ['273216002', '272765000', 0], ['273125004', '272765000', 0], ['272973003', '272765000', 0]]\n",
      "6166563\n"
     ]
    }
   ],
   "source": [
    "conceptNotPairDict={}\n",
    "conceptNotPairList=[]\n",
    "\n",
    "def read_not_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==2:\n",
    "                conceptNotPairList.append([splitted[0], splitted[1].replace(\"\\r\\n\", \"\"), 0])\n",
    "#                 conceptNotPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "notPair_file = \"D:/workspace/MLDataProcessing/output/taxNotPairs.txt\"\n",
    "read_not_pair(notPair_file)\n",
    "\n",
    "# first2pairs = {k: conceptNotPairDict[k] for k in list(conceptNotPairDict)[10:15]}\n",
    "first2pairs =conceptNotPairList[10:15]\n",
    "print(first2pairs)\n",
    "print(len(conceptNotPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('237267007', 0.5860327482223511),\n",
      " ('722912007', 0.5498074889183044),\n",
      " ('722913002', 0.5403775572776794),\n",
      " ('446466006', 0.5249851942062378),\n",
      " ('10759711000119103', 0.5154984593391418),\n",
      " ('267262008', 0.5110116600990295),\n",
      " ('10759661000119108', 0.506843626499176),\n",
      " ('177130000', 0.5065948963165283),\n",
      " ('12729009', 0.5010930895805359),\n",
      " ('10759611000119105', 0.5007020235061646)]\n"
     ]
    }
   ],
   "source": [
    "path = \"D:/MLOntology/model0\"\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(model.docvecs.most_similar([inferred_vector], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"D:/MLOntology/model1\"\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(model.docvecs.most_similar([inferred_vector], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6019, 6070, 6086, 6031, 6062, 6097, 6032, 6017, 6041, 6016]\n",
      "[6155, 6172, 6153, 6191, 6188, 6182, 6148, 6104, 6114, 6145]\n",
      "[6293, 6246, 6289, 6278, 6227, 6237, 6223, 6282, 6204, 6284]\n",
      "[6364, 6358, 6381, 6377, 6362, 6393, 6395, 6302, 6387, 6388]\n",
      "[6463, 6407, 6456, 6430, 6417, 6484, 6448, 6473, 6491, 6427]\n",
      "[6501, 6584, 6566, 6512, 6570, 6553, 6569, 6529, 6500, 6590]\n",
      "[6607, 6695, 6686, 6651, 6664, 6613, 6653, 6608, 6637, 6672]\n",
      "[6728, 6745, 6797, 6763, 6738, 6780, 6766, 6775, 6744, 6769]\n",
      "[6820, 6868, 6809, 6860, 6834, 6890, 6889, 6803, 6895, 6870]\n",
      "[6909, 6934, 6938, 6995, 6922, 6940, 6972, 6929, 6964, 6984]\n",
      "[7016, 7003, 7033, 7042, 7018, 7089, 7027, 7000, 7061, 7043]\n",
      "[7192, 7130, 7118, 7178, 7128, 7187, 7191, 7171, 7103, 7195]\n",
      "[7255, 7288, 7249, 7278, 7228, 7202, 7240, 7262, 7201, 7233]\n",
      "[7336, 7385, 7323, 7370, 7327, 7331, 7306, 7372, 7377, 7313]\n",
      "[7468, 7402, 7404, 7400, 7450, 7459, 7429, 7451, 7406, 7444]\n",
      "[7524, 7598, 7500, 7566, 7504, 7556, 7579, 7587, 7552, 7505]\n",
      "[7661, 7623, 7638, 7696, 7689, 7668, 7686, 7698, 7671, 7616]\n",
      "[7756, 7763, 7795, 7788, 7741, 7717, 7799, 7753, 7747, 7752]\n",
      "[7813, 7804, 7831, 7858, 7815, 7845, 7887, 7850, 7816, 7890]\n",
      "[7998, 7964, 7951, 7906, 7997, 7974, 7942, 7908, 7956, 7920]\n",
      "[8066, 8092, 8069, 8082, 8085, 8001, 8061, 8057, 8032, 8046]\n",
      "[8181, 8169, 8111, 8188, 8137, 8102, 8107, 8180, 8121, 8165]\n",
      "[8280, 8276, 8201, 8240, 8203, 8257, 8254, 8221, 8291, 8229]\n",
      "[8385, 8360, 8327, 8364, 8353, 8308, 8333, 8379, 8318, 8355]\n",
      "[8476, 8415, 8423, 8447, 8450, 8494, 8431, 8449, 8457, 8496]\n",
      "[8547, 8525, 8519, 8514, 8544, 8542, 8524, 8527, 8513, 8565]\n",
      "[8623, 8648, 8657, 8696, 8621, 8674, 8698, 8690, 8635, 8619]\n",
      "[8715, 8772, 8775, 8737, 8769, 8793, 8757, 8705, 8712, 8740]\n",
      "[8857, 8832, 8833, 8875, 8893, 8866, 8883, 8881, 8872, 8870]\n",
      "[8935, 8999, 8959, 8932, 8976, 8901, 8960, 8931, 8983, 8913]\n",
      "[9045, 9004, 9005, 9096, 9097, 9038, 9086, 9095, 9052, 9042]\n",
      "[9150, 9109, 9152, 9104, 9144, 9197, 9129, 9147, 9108, 9187]\n",
      "[9246, 9274, 9285, 9299, 9281, 9290, 9264, 9280, 9293, 9228]\n",
      "[9396, 9348, 9387, 9388, 9301, 9310, 9302, 9316, 9322, 9392]\n",
      "[9443, 9475, 9421, 9405, 9484, 9454, 9449, 9440, 9418, 9486]\n",
      "[9563, 9587, 9527, 9579, 9506, 9595, 9583, 9541, 9510, 9550]\n",
      "[9694, 9638, 9665, 9614, 9650, 9658, 9633, 9649, 9662, 9669]\n",
      "[9713, 9788, 9702, 9725, 9771, 9701, 9776, 9768, 9795, 9786]\n",
      "[9894, 9889, 9850, 9812, 9874, 9890, 9806, 9826, 9807, 9885]\n",
      "[9913, 9966, 9929, 9984, 9982, 9907, 9909, 9902, 9979, 9912]\n",
      "[10065, 10072, 10021, 10061, 10079, 10081, 10056, 10037, 10080, 10055]\n",
      "[10121, 10156, 10168, 10186, 10114, 10181, 10166, 10124, 10117, 10169]\n",
      "[10241, 10292, 10255, 10256, 10285, 10200, 10247, 10257, 10228, 10269]\n",
      "[10381, 10305, 10374, 10346, 10308, 10338, 10387, 10378, 10322, 10324]\n",
      "[10458, 10400, 10409, 10406, 10435, 10401, 10464, 10439, 10415, 10479]\n",
      "[10501, 10505, 10586, 10547, 10502, 10504, 10571, 10592, 10557, 10590]\n",
      "[10670, 10671, 10610, 10630, 10636, 10663, 10687, 10664, 10614, 10640]\n",
      "[10742, 10703, 10755, 10727, 10777, 10717, 10726, 10758, 10724, 10769]\n",
      "[10884, 10802, 10814, 10877, 10899, 10888, 10868, 10809, 10867, 10841]\n",
      "[10929, 10944, 10968, 10978, 10981, 10989, 10912, 10919, 10990, 10926]\n",
      "[11082, 11040, 11012, 11027, 11022, 11004, 11044, 11091, 11021, 11045]\n",
      "[11160, 11174, 11163, 11118, 11172, 11101, 11142, 11138, 11167, 11133]\n",
      "[11277, 11285, 11284, 11254, 11292, 11253, 11229, 11281, 11212, 11238]\n",
      "[11314, 11345, 11383, 11322, 11355, 11349, 11311, 11344, 11387, 11360]\n",
      "[11498, 11499, 11480, 11467, 11439, 11444, 11426, 11406, 11433, 11423]\n",
      "[11532, 11535, 11599, 11571, 11526, 11557, 11596, 11545, 11581, 11523]\n",
      "[11659, 11664, 11645, 11644, 11691, 11619, 11610, 11674, 11678, 11630]\n",
      "[11711, 11787, 11767, 11741, 11726, 11791, 11715, 11747, 11719, 11786]\n",
      "[11852, 11868, 11869, 11839, 11849, 11865, 11857, 11842, 11835, 11802]\n",
      "[11982, 11940, 11931, 11949, 11980, 11991, 11927, 11902, 11976, 11928]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "feature_number = 1024\n",
    "\n",
    "train_list_before=[]\n",
    "train_label_list=[]\n",
    "test_list_before=[]\n",
    "test_label_list =[]\n",
    "\n",
    "offset = 6000\n",
    "\n",
    "for i in range(60):\n",
    "    index = np.arange(100)     #generate numbers from 0 to 100\n",
    "    np.random.shuffle(index)        #shuffle the 100 values\n",
    "    index = [int(100*i+j + offset) for j in index]\n",
    "    print(index[10:20])\n",
    "    train_list_before.extend([conceptPairList[b] for b in index[0:40]]) \n",
    "    train_label_list.extend([1]*40)\n",
    "    train_list_before.extend([conceptNotPairList[b] for b in index[40:80]])\n",
    "    train_label_list.extend([0]*40)\n",
    "    test_list_before.extend([conceptPairList[b] for b in index[80:90]])\n",
    "    test_label_list.extend([1]*10)\n",
    "    test_list_before.extend([conceptNotPairList[b] for b in index[90:100]])\n",
    "    test_label_list.extend([0]*10)\n",
    "\n",
    "\n",
    "    \n",
    "train_list =[]\n",
    "test_list = []\n",
    "\n",
    "for line in train_list_before:\n",
    "    if line[0] in model.docvecs and line[1] in model.docvecs:\n",
    "        a= model.docvecs[line[0]]\n",
    "        b= model.docvecs[line[1]]\n",
    "        c = np.array((a, b))\n",
    "#         train_list.append(np.reshape(c, feature_number)) \n",
    "        train_list.append(np.reshape(c, feature_number, order='F'))\n",
    "\n",
    "\n",
    "test_list_ids={}\n",
    "for i, line in enumerate(test_list_before):\n",
    "    if line[0] in model.docvecs and line[1] in model.docvecs:\n",
    "        a= model.docvecs[line[0]]\n",
    "        b= model.docvecs[line[1]]\n",
    "        c = np.array((a, b))\n",
    "        test_list_ids[i] = (line[0], line[1])\n",
    "#         test_list.append(np.reshape(c, feature_number))\n",
    "        test_list.append(np.reshape(c, feature_number, order='F'))\n",
    "\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.2835132 , -0.07740058,  0.08801333, ...,  0.05238185,\n",
      "        0.13701488, -0.20197156], dtype=float32), array([-0.04869056, -0.19915049,  0.21782987, ..., -0.0946416 ,\n",
      "       -0.01996695, -0.17629008], dtype=float32), array([-0.08139496,  0.15654613, -0.11598934, ..., -0.19314079,\n",
      "        0.00167724,  0.02864841], dtype=float32), array([-0.0604803 ,  0.04651431, -0.13535379, ..., -0.09133615,\n",
      "       -0.21332239, -0.25945604], dtype=float32), array([-0.33551827, -0.27371043,  0.09206092, ..., -0.24618427,\n",
      "        0.03852985, -0.10815102], dtype=float32), array([-0.15090123, -0.2541906 ,  0.09829646, ..., -0.01854175,\n",
      "        0.05277655,  0.31554946], dtype=float32), array([ 0.02635466,  0.44302973, -0.06935468, ..., -0.42810643,\n",
      "        0.03341359,  0.34629533], dtype=float32), array([ 0.04004204,  0.12201235,  0.07779548, ..., -0.10708943,\n",
      "        0.02779918,  0.07826661], dtype=float32), array([-0.1477978 , -0.28235456,  0.15462002, ...,  0.29724404,\n",
      "        0.03261452,  0.07695621], dtype=float32), array([-0.29879805, -0.18907975,  0.11616605, ...,  0.14525217,\n",
      "       -0.1051048 , -0.2126566 ], dtype=float32), array([-0.01155692, -0.1186982 ,  0.05759298, ...,  0.00065869,\n",
      "       -0.02719358, -0.2544986 ], dtype=float32), array([-0.20628403, -0.08935568,  0.05817127, ...,  0.07683762,\n",
      "       -0.16638456, -0.00326769], dtype=float32), array([-0.0015352 ,  0.01991208,  0.18618706, ..., -0.1777938 ,\n",
      "       -0.08381955, -0.00419947], dtype=float32), array([ 0.13026743, -0.1186982 ,  0.00553446, ...,  0.00065869,\n",
      "        0.05302546, -0.2544986 ], dtype=float32), array([-0.2860409 , -0.32249025, -0.0929949 , ...,  0.0257692 ,\n",
      "        0.10162888, -0.09794278], dtype=float32), array([-0.11789267, -0.14705443, -0.19699053, ..., -0.097828  ,\n",
      "       -0.3032363 , -0.28904557], dtype=float32), array([-0.09243413, -0.32249025,  0.07942373, ...,  0.0257692 ,\n",
      "       -0.09819644, -0.09794278], dtype=float32), array([-0.16259892, -0.17606755,  0.06058369, ..., -0.13135785,\n",
      "        0.03453309, -0.20109323], dtype=float32), array([ 0.1389022 , -0.1186982 ,  0.03609056, ...,  0.00065869,\n",
      "       -0.02428965, -0.2544986 ], dtype=float32), array([-0.25887808, -0.08935568,  0.00737827, ...,  0.07683762,\n",
      "       -0.03257823, -0.00326769], dtype=float32)]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "4800\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "print(train_list[30:50])\n",
    "print(train_label_list[30:50])\n",
    "print(len(train_list))\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "[0.9383333333333334]\n"
     ]
    }
   ],
   "source": [
    "#SVM \n",
    "\n",
    "\n",
    "print(len(train_list))\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(train_list, train_label_list)\n",
    "\n",
    "train_errors=[]\n",
    "train_errors.append(clf.score(train_list, train_label_list))\n",
    "print(train_errors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conceptLabelDict={}\n",
    "errors=[]\n",
    "\n",
    "def read_label(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                conceptLabelDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "label_file = \"D:/MLOntology/ontClassLabels.txt\"\n",
    "read_label(label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 25 predicted label [0], but true label is 1\n",
      "('279448009', '6413002') Concept Pairs: (entire presymphysial lymph node --- structure of presymphysial lymph node)\n",
      "index 28 predicted label [0], but true label is 1\n",
      "('420479003', '422374002') Concept Pairs: (entire permanent second molar tooth --- entire second molar tooth)\n",
      "index 46 predicted label [0], but true label is 1\n",
      "('62397004', '45272004') Concept Pairs: (sacral plexus structure --- lumbosacral plexus structure)\n",
      "index 48 predicted label [0], but true label is 1\n",
      "('416285004', '51398009') Concept Pairs: (astrocytic hamartoma --- hamartoma)\n",
      "index 60 predicted label [0], but true label is 1\n",
      "('362287008', '24314005') Concept Pairs: (entire pyramidal system --- pyramidal system structure)\n",
      "index 85 predicted label [0], but true label is 1\n",
      "('57154007', '59650007') Concept Pairs: (structure of pontine portion of corticospinal tract --- structure of pars basalis of pons)\n",
      "index 105 predicted label [0], but true label is 1\n",
      "('110632006', '116007004') Concept Pairs: (vagina and perineum (combined site) --- combined site)\n",
      "index 120 predicted label [0], but true label is 1\n",
      "('81797008', '192747009') Concept Pairs: (structure of cusp of aortic valve --- structure of cardiac valve cusp)\n",
      "index 163 predicted label [0], but true label is 1\n",
      "('368577001', '181171005') Concept Pairs: (entire retina of right eye --- entire retina)\n",
      "index 202 predicted label [0], but true label is 1\n",
      "('153622002', '360637000') Concept Pairs: (structure of nasofrontal vein --- structure of tributary of facial vein)\n",
      "index 207 predicted label [0], but true label is 1\n",
      "('153622002', '360663005') Concept Pairs: (structure of nasofrontal vein --- structure of tributary of superior ophthalmic vein)\n",
      "index 233 predicted label [1], but true label is 0\n",
      "('30285000', '63638007') Concept Pairs: (verruca --- eosinophilic granulomatous polyp)\n",
      "index 241 predicted label [0], but true label is 1\n",
      "('71834002', '10056005') Concept Pairs: (long ciliary nerves --- structure of ophthalmic nerve)\n",
      "index 247 predicted label [0], but true label is 1\n",
      "('431491007', '304582006') Concept Pairs: (structure of upper urinary tract proper --- kidney and/or ureter structures)\n",
      "index 276 predicted label [1], but true label is 0\n",
      "('2734008', '5901005') Concept Pairs: (major injury --- multiple internal injuries)\n",
      "index 300 predicted label [0], but true label is 1\n",
      "('244847002', '244846006') Concept Pairs: (suboccipital muscle --- posterior vertebral muscle of neck)\n",
      "index 303 predicted label [0], but true label is 1\n",
      "('164108006', '11465001') Concept Pairs: (entire superior articular process of fourth cervical vertebra --- structure of superior articular process of fourth cervical vertebra)\n",
      "index 304 predicted label [0], but true label is 1\n",
      "('368053002', '29514006') Concept Pairs: (entire subclavius muscle --- structure of subclavius muscle)\n",
      "index 347 predicted label [0], but true label is 1\n",
      "('1581009', '42258001') Concept Pairs: (structure of ileal artery --- superior mesenteric artery structure)\n",
      "index 353 predicted label [1], but true label is 0\n",
      "('25751009', '125308006') Concept Pairs: (loss of fluid --- non-pitting edema)\n",
      "index 380 predicted label [0], but true label is 1\n",
      "('76031008', '23215003') Concept Pairs: (structure of spinous process of twelfth thoracic vertebra --- bone structure of t12)\n",
      "index 382 predicted label [0], but true label is 1\n",
      "('728239002', '245225002') Concept Pairs: (entire tendon of first dorsal interosseus of foot --- tendon of first dorsal interosseus of foot)\n",
      "index 421 predicted label [0], but true label is 1\n",
      "('195046004', '63467002') Concept Pairs: (left main stem bundle branch block --- left bundle branch block)\n",
      "index 534 predicted label [1], but true label is 0\n",
      "('2784001', '55118007') Concept Pairs: (traction injury --- deep cold injury)\n",
      "index 537 predicted label [1], but true label is 0\n",
      "('5770003', '55118007') Concept Pairs: (decompression injury --- deep cold injury)\n",
      "index 561 predicted label [0], but true label is 1\n",
      "('731910006', '417584008') Concept Pairs: (entire skin and subcutaneous tissue of pelvis --- skin and subcutaneous tissue structure of pelvis)\n",
      "index 584 predicted label [0], but true label is 1\n",
      "('71836000', '405952001') Concept Pairs: (nasopharyngeal structure --- parameningeal structure in the context of malignancy)\n",
      "index 628 predicted label [0], but true label is 1\n",
      "('61471000119100', '402818009') Concept Pairs: (basal cell carcinoma of naris --- basal cell carcinoma of nose)\n",
      "index 703 predicted label [0], but true label is 1\n",
      "('119546009', '53394001') Concept Pairs: (bone structure of shaft of metatarsal --- structure of diaphysis)\n",
      "index 727 predicted label [0], but true label is 1\n",
      "('368066002', '65758004') Concept Pairs: (entire subcutaneous tissue of umbilicus --- subcutaneous tissue structure of umbilicus)\n",
      "index 728 predicted label [0], but true label is 1\n",
      "('3156006', '314326001') Concept Pairs: (structure of obturator artery --- branch of anterior division of internal iliac artery)\n",
      "index 783 predicted label [0], but true label is 1\n",
      "('118501004', '15434002') Concept Pairs: (synovial tissue of tendon sheath --- tendon sheath structure)\n",
      "index 843 predicted label [0], but true label is 1\n",
      "('280509006', '110696007') Concept Pairs: (entire internal carotid plexus --- structure of internal carotid plexus)\n",
      "index 861 predicted label [0], but true label is 1\n",
      "('39332000', '3898006') Concept Pairs: (intraepidermal epithelioma of jadassohn --- neoplasm, benign)\n",
      "index 865 predicted label [0], but true label is 1\n",
      "('14167003', '36486006') Concept Pairs: (fibrous sheath of sperm tail --- specialized subunit or derivative of cilium or flagellum, not bacterial)\n",
      "index 867 predicted label [0], but true label is 1\n",
      "('336609007', '182358004') Concept Pairs: (entire ligament of trunk --- entire ligament)\n",
      "index 868 predicted label [0], but true label is 1\n",
      "('91238003', '304592003') Concept Pairs: (bone structure of distal ulna --- bone structure of distal end of radius and/or ulna)\n",
      "index 887 predicted label [0], but true label is 1\n",
      "('1584001', '58442004') Concept Pairs: (entire symphysis --- entire cartilaginous joint)\n",
      "index 900 predicted label [0], but true label is 1\n",
      "('65022003', '75899004') Concept Pairs: (structure of amniotic cavity --- chorionic cavity structure)\n",
      "index 905 predicted label [0], but true label is 1\n",
      "('302529003', '717798006') Concept Pairs: (entire fibula --- entire bone of tibia and/or fibula)\n",
      "index 908 predicted label [0], but true label is 1\n",
      "('368065003', '38927002') Concept Pairs: (entire umbilical ring --- structure of umbilical ring)\n",
      "index 943 predicted label [0], but true label is 1\n",
      "('81275005', '314287005') Concept Pairs: (structure of muscular branches of occipital artery --- branch of occipital artery)\n",
      "index 947 predicted label [0], but true label is 1\n",
      "('125316002', '56208002') Concept Pairs: (diffuse ulceration --- ulcer)\n",
      "index 961 predicted label [0], but true label is 1\n",
      "('255337007', '107644003') Concept Pairs: (dendritic --- shape finding)\n",
      "index 986 predicted label [0], but true label is 1\n",
      "('308822005', '42278009') Concept Pairs: (entire thyroglossal duct --- structure of thyroglossal duct)\n",
      "index 1030 predicted label [1], but true label is 0\n",
      "('272379006', '87100004') Concept Pairs: (event --- topography unknown)\n",
      "index 1034 predicted label [1], but true label is 0\n",
      "('419891008', '87100004') Concept Pairs: (record artifact --- topography unknown)\n",
      "index 1036 predicted label [1], but true label is 0\n",
      "('370115009', '87100004') Concept Pairs: (special concept --- topography unknown)\n",
      "index 1062 predicted label [0], but true label is 1\n",
      "('76033006', '73829009') Concept Pairs: (structure of intercaval sinus --- right atrial structure)\n",
      "index 1122 predicted label [0], but true label is 1\n",
      "('82851002', '362837007') Concept Pairs: (lipoblast --- entire cell)\n",
      "index 1127 predicted label [0], but true label is 1\n",
      "('302523002', '332709000') Concept Pairs: (entire rib --- entire long bone)\n",
      "index 1160 predicted label [0], but true label is 1\n",
      "('65549009', '711190000') Concept Pairs: (structure of distal epiphyseal growth plate --- structure of epiphyseal plate)\n",
      "index 1162 predicted label [0], but true label is 1\n",
      "('68171009', '281777001') Concept Pairs: (axillary lymph node structure --- structure of lymphatic system of axilla)\n",
      "index 1164 predicted label [0], but true label is 1\n",
      "('224935004', '230259002') Concept Pairs: (entire subcutaneous tissue of fourth toe --- entire subcutaneous tissue of toe)\n",
      "index 1167 predicted label [0], but true label is 1\n",
      "('147864007', '363605000') Concept Pairs: (entire masseteric artery --- entire artery of head)\n"
     ]
    }
   ],
   "source": [
    "for i, (item, label) in enumerate(zip(test_list, test_label_list)):\n",
    "    result = clf.predict([item])\n",
    "    if result != label:\n",
    "        print(\"index %d predicted label %s, but true label is %s\" % (i, result, label))\n",
    "        idpair = test_list_ids[i] \n",
    "        concept1 = conceptLabelDict[idpair[0]]\n",
    "        concept2 = conceptLabelDict[idpair[1]]\n",
    "        print(\"%s Concept Pairs: (%s --- %s)\" % (idpair, concept1, concept2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "1200\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# m3 = np.array((a,d))\n",
    "# m3 = np.reshape(m3, 400, order='F')\n",
    "print(len(test_list))\n",
    "result = clf.predict(test_list)\n",
    "\n",
    "print(result.size)\n",
    "\n",
    "\n",
    "print(result[:29])\n",
    "print(np.array(test_label_list[:29]))\n",
    "\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  25   28   46   48   60   85  105  120  163  202  207  233  241  247\n",
      "  276  300  303  304  347  353  380  382  421  534  537  561  584  628\n",
      "  703  727  728  783  843  861  865  867  868  887  900  905  908  943\n",
      "  947  961  986 1030 1034 1036 1062 1122 1127 1160 1162 1164 1167]\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "\n",
    "err_ids=np.flatnonzero(result != test_label_list)\n",
    "\n",
    "print(err_ids)\n",
    "print(err_ids.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9541666666666667\n",
      "0.9151901366607249\n",
      "0.9541182040196625\n",
      "0.9541666666666666\n",
      "0.9542151293136709\n",
      "[0.95560936 0.95262705]\n",
      "[0.98666667 0.92166667]\n",
      "[0.92644757 0.98573975]\n",
      "0.9560936623902656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "print(accuracy_score(result, test_label_list))\n",
    "print(average_precision_score(result, test_label_list))\n",
    "\n",
    "print(f1_score(result, test_label_list, average='macro') ) \n",
    "\n",
    "print(f1_score(result, test_label_list, average='micro')  )\n",
    "\n",
    "print(f1_score(result, test_label_list, average='weighted') )\n",
    "\n",
    "print(f1_score(result, test_label_list, average=None))\n",
    "\n",
    "print(precision_score(result, test_label_list, average=None))\n",
    "print(recall_score(result, test_label_list, average=None))\n",
    "\n",
    "print(roc_auc_score(result, test_label_list, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_label_list_m = np.eye(2)[train_label_list]\n",
    "# test_label_list_m = np.eye(2)[test_label_list]\n",
    "# print(test_label_list_m[10:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 100\n",
      "Train Loss: 0.69142306 Acc: [0.49]\n",
      "None 200\n",
      "Train Loss: 0.66437715 Acc: [0.71]\n",
      "None 300\n",
      "Train Loss: 0.63580245 Acc: [0.72]\n",
      "None 400\n",
      "Train Loss: 0.57054174 Acc: [0.86]\n",
      "None 500\n",
      "Train Loss: 0.5039642 Acc: [0.86]\n",
      "None 600\n",
      "Train Loss: 0.31338054 Acc: [0.93]\n",
      "None 700\n",
      "Train Loss: 0.2417683 Acc: [0.95]\n",
      "None 800\n",
      "Train Loss: 0.21721977 Acc: [0.96]\n",
      "None 900\n",
      "Train Loss: 0.17651536 Acc: [0.96]\n",
      "None 1000\n",
      "Train Loss: 0.19576985 Acc: [0.94]\n",
      "None 1100\n",
      "Train Loss: 0.14295651 Acc: [0.96]\n",
      "None 1200\n",
      "Train Loss: 0.1796587 Acc: [0.93]\n",
      "None 1300\n",
      "Train Loss: 0.12233908 Acc: [0.94]\n",
      "None 1400\n",
      "Train Loss: 0.09104396 Acc: [0.99]\n",
      "0.96\n",
      "Model saved in file: ./model-noleaky.ckpt\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "import numpy as np\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "'''\n",
    "In the data, there are 2 classes and every class has 3000 samples and every sample has 512 features\n",
    "The first 3000 samples are from class 0, second 3000 are from class 1\n",
    "'''\n",
    "# DATA_DIR = ''\n",
    "CLASS_NUM = 2       #there are 2 classes\n",
    "SPLIT_PERCENT = 0.8     #split the data into 80% for training and 20% for testing\n",
    "FEATURE_NUM = 1024   \n",
    "TRAIN_ITER = 1500    #the number of iterations for training\n",
    "display_step = 100        #how many iterations to display the results\n",
    "\n",
    "\n",
    "train_num = int(3000*SPLIT_PERCENT)     #the number of samples for training\n",
    "\n",
    "train_feature = train_list      #training features (list of list)\n",
    "train_y = train_label_list        #training lables    (list)\n",
    "test_feature = test_list       #test features  (list of list)\n",
    "test_y = test_label_list         #test labels    (list)\n",
    "\n",
    "\n",
    "y_m = np.eye(2)[train_y]\n",
    "test_y_m = np.eye(2)[test_y]\n",
    "\n",
    "'''\n",
    "y = wx+b        (vectors)\n",
    "'''\n",
    "#function to get variables 'w'\n",
    "def weight_variable(shape, num):\n",
    "    initial = tf.truncated_normal(shape, stddev=1/num)\n",
    "    return tf.Variable(initial, name='weight')\n",
    "\n",
    "#the bias 'b' in the equations\n",
    "def bias_variable(shape, num):\n",
    "    initial = tf.constant(0.0001, shape=shape)\n",
    "    return tf.Variable(initial, name='bias')\n",
    "\n",
    "#convolutional process\n",
    "def conv1d(x, W):\n",
    "    return tf.nn.conv1d(x, W, stride=1, padding='SAME')     #x: variable, w: weight, stride and padding (padding can be ignored currently) \n",
    "\n",
    "#pooling process\n",
    "def max_pool_1x1(x, shape):\n",
    "    x=tf.reshape(x,shape)       #it is transfered into four dimensions, but the other three are 1\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, 4, 1],\n",
    "                        strides=[1, 1, 2, 1], padding='SAME')\n",
    "\n",
    "'''\n",
    "The feature is 3 dimensional data.  [batch, length, channel] \n",
    "batch is usually ignored (for example there are 100 samples in a batch, so samples should not be modified mutually), length and channel are shown in the paper.\n",
    "At first, the length is 512, and channel is 1.\n",
    "Because our data are time series data, so length is enough, but for images, it may be [batch, length, width, channel]\n",
    "'''\n",
    "# the convolutional layer\n",
    "def layer(features, f, input_n, channel, hidden_units, layer_index):\n",
    "    \"\"\"Construct a convolutional layer\n",
    "    Args:\n",
    "    features: Features placeholder, from the previous layer.\n",
    "    f: the length\n",
    "    input_n: Size of the features used in the convention.\n",
    "    hidden_units: Size of the current hidden layer.\n",
    "    layer_index: the index of layer\n",
    "    Returns:\n",
    "    hidden units: The unit output for the next layer.\n",
    "    weights: the weights in the current hidden layer\n",
    "    \"\"\"\n",
    "    # Hidden 1\n",
    "    with tf.name_scope('hidden'+str(layer_index)) as scope:     # name scope may be ignored first\n",
    "        with tf.name_scope(\"weight\"):\n",
    "            weights = weight_variable([input_n, channel, hidden_units], math.sqrt(f))\n",
    "\n",
    "        with tf.name_scope(\"bias\"):\n",
    "            biases = bias_variable([hidden_units], math.sqrt(f))\n",
    "    hidden = relu(conv1d(features, weights) + biases, 0.01)\n",
    "    shape = [-1,1,f,hidden_units]\n",
    "    h_pool1 = max_pool_1x1(hidden,shape)\n",
    "    return h_pool1, weights\n",
    "\n",
    "# fully connected layer, here the data are two dimension, [batch, length]\n",
    "def densely_connect(features, input_n, hidden_units):\n",
    "    \"\"\"Construct a fully (densely) connected layer.\n",
    "    Args:\n",
    "    features: Features placeholder, from the previous layer.\n",
    "    input_n: Size of units in the previous layer.\n",
    "    hidden_units: Size of the current hidden layer.\n",
    "    Returns:\n",
    "    logits: The estimated output in last layer.\n",
    "    weights: the weights in the hidden layer\n",
    "    \"\"\"\n",
    "    with tf.name_scope('softmax_linear') as dense:\n",
    "        with tf.name_scope(\"weight\"):\n",
    "            weights = weight_variable([input_n, hidden_units], math.sqrt(input_n))\n",
    "        with tf.name_scope(\"bias\"):\n",
    "            biases = bias_variable([hidden_units], math.sqrt(input_n))\n",
    "    logits = relu(tf.matmul(features, weights) + biases, 0.01)      # the matrix product operation\n",
    "    return logits, weights\n",
    "\n",
    "# dropout layer (it is not necessary)\n",
    "# randomly set (1-keep_prob) percentage of units to be zero\n",
    "def dropout(features, input_n, hidden_units, keep_prob):\n",
    "    with tf.name_scope('dropout'):\n",
    "        with tf.name_scope(\"weight\"):\n",
    "            weights = weight_variable([input_n, hidden_units], math.sqrt(input_n))\n",
    "        with tf.name_scope(\"bias\"):\n",
    "            biases = bias_variable([hidden_units], math.sqrt(input_n))\n",
    "    h_fc1_drop = tf.nn.dropout(features, keep_prob)\n",
    "    drop_out = relu(tf.matmul(features, weights) + biases, 0.01)\n",
    "    return drop_out\n",
    "\n",
    "# calculate the loss in the neural network\n",
    "def loss(logits, labels):\n",
    "    \"\"\"Calculates the loss from the logits and the labels.\n",
    "    Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int32 - [batch_size, NUM_CLASSES].\n",
    "    Returns:\n",
    "    loss: Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"Loss\"):\n",
    "        labels = tf.to_int64(labels)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=labels, logits=logits, name='xentropy')\n",
    "    # tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "    return tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "\n",
    "def next_batch(data, label, num):\n",
    "    \"\"\"Generate the next batch randomly\n",
    "    Args:\n",
    "    data: training data.\n",
    "    label: training label.\n",
    "    num: the size in a batch\n",
    "    Returns:\n",
    "    next batch's training features and labels.\n",
    "    \"\"\"\n",
    "    index = np.arange(len(data))\n",
    "    np.random.shuffle(index)\n",
    "#     train_feature = data[np.array(index)[0:num]]\n",
    "#     train_label = label[np.array(index)[0:num]]\n",
    "    train_feature_batch = [data[b] for b in index[0:num]]\n",
    "    train_feature_batch = np.asarray(train_feature_batch)\n",
    "    train_label_batch = [label[b] for b in index[0:num]]\n",
    "    train_label_batch = np.asarray(train_label_batch)\n",
    "    return train_feature_batch, train_label_batch\n",
    "\n",
    "def relu(x, alpha=0., max_value=None):\n",
    "    '''ReLU.\n",
    "    alpha: slope of negative section.\n",
    "    '''\n",
    "    negative_part = tf.nn.relu(-x)\n",
    "    x = tf.nn.relu(x)\n",
    "    if max_value is not None:\n",
    "        x = tf.clip_by_value(x, tf.cast(0., dtype=tf.float32),\n",
    "                             tf.cast(max_value, dtype=tf.float32))\n",
    "    x -= tf.constant(alpha, dtype=tf.float32) * negative_part\n",
    "    return x\n",
    "\n",
    "#define a session to run the model\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#place holders for training features and label\n",
    "#None means the value is variable\n",
    "x = tf.placeholder(tf.float32, shape=[None, FEATURE_NUM])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, CLASS_NUM])\n",
    "\n",
    "# decide whether it is training or testing, it is not used in our model, but it may be used\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "#from [-1, 512, 1] -> [-1, 256, 32] -> [-1, 128, 64] -> [-1, 64, 64] -> [-1, 32, 64] -> [-1, 16, 64] -> [-1, 8, 64] -> [-1, 200]\n",
    "\n",
    "#6 hidden layers\n",
    "x_1 = tf.reshape(x, [-1,FEATURE_NUM,1])\n",
    "h_pool0, w0 = layer(x_1, FEATURE_NUM, 15, 1, 32, 0)\n",
    "h_pool0 = tf.reshape(h_pool0, [-1,512,32])\n",
    "h_pool1, w1 = layer(h_pool0, 512, 10, 32, 64, 1)\n",
    "\n",
    "h_pool1 = tf.reshape(h_pool1, [-1,256,64])\n",
    "h_pool2, w2 = layer(h_pool1, 256, 10, 64, 64, 2)\n",
    "h_pool2 = tf.reshape(h_pool2, [-1,128,64])\n",
    "h_pool3, w3 = layer(h_pool2, 128, 10, 64, 64, 3)\n",
    "h_pool3 = tf.reshape(h_pool3, [-1,64,64])\n",
    "h_pool4, w4 = layer(h_pool3, 64, 5, 64, 64, 4)\n",
    "h_pool4 = tf.reshape(h_pool4, [-1,32,64])\n",
    "h_pool5, w5 = layer(h_pool4, 32, 5, 64, 64, 5)\n",
    "h_pool5 = tf.reshape(h_pool5, [-1,16,64])\n",
    "h_pool6, w6 = layer(h_pool5, 16, 5, 64, 64, 6)\n",
    "h_pool6 = tf.reshape(h_pool6, [-1,8,64])\n",
    "\n",
    "#densely connected: 200 units\n",
    "h_pool_flat = tf.reshape(h_pool6, [-1, 8*64])\n",
    "h_dc, w_d = densely_connect(h_pool_flat, 8*64, 200)\n",
    "\n",
    "#dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "y_conv=dropout(h_dc, (int)(h_dc.get_shape()[1]), CLASS_NUM, keep_prob)\n",
    "\n",
    "\n",
    "beta = 0.001\n",
    "cross_entropy = loss(y_conv, y_)\n",
    "loss = cross_entropy +beta*(tf.nn.l2_loss(w0) + tf.nn.l2_loss(w1)+tf.nn.l2_loss(w2)+tf.nn.l2_loss(w3)+tf.nn.l2_loss(w4)+tf.nn.l2_loss(w5)+tf.nn.l2_loss(w6)+tf.nn.l2_loss(w_d))  #L2 regularization\n",
    "epsilon = 1e-5      # learning rate\n",
    "train_step = tf.train.AdamOptimizer(epsilon).minimize(loss)     #optimization function, our goal is to minimize the loss\n",
    "\n",
    "predict = tf.argmax(y_conv,1)   #the predicted class\n",
    "\n",
    "# calculate the accuray, the corrected classified divided by the total size\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "#saver to save the training check point\n",
    "# variables can be restored in a new model by 'saver.restore(sess, save_path)'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())  #initialize the variables\n",
    "\n",
    "\n",
    "for i in range(1,TRAIN_ITER):       #training iterations\n",
    "    d, l = next_batch(train_feature, y_m, 100)      # get 100 samples in one batch\n",
    "#     print(\"d size is %s, l size is %s \"% (len(d), len(l)))\n",
    "#     print(\"d size is %s, l size is %s \"% (len(d[0]), len(l[0])))\n",
    "    _, ls=sess.run([train_step,cross_entropy], feed_dict={x: d, y_: l, keep_prob: 1, is_training:True})     #run the train step (optimization function), the second one is just to show the loss in this iteration.   THE FEED dictionary is to feed the place holders which are needed in the optimization function.\n",
    "    \n",
    "    if i%display_step==0:\n",
    "        print(_, i)\n",
    "        acc = sess.run([accuracy], feed_dict={x: d, y_: l, keep_prob: 1, is_training:False})\n",
    "        print(\"Train Loss:\", ls, \"Acc:\", acc)\n",
    "\n",
    "# sess.run  or tensor.eval are two ways\n",
    "# get the accuracy in the testing data\n",
    "print(accuracy.eval(session=sess, feed_dict={x:test_feature, y_:test_y_m, keep_prob: 1, is_training:False}))\n",
    "\n",
    "\n",
    "# save the model results\n",
    "save_path = saver.save(sess, \"./model-noleaky.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[  29   45   60  182  200  208  216  220  236  239  264  300  303  353\n",
      "  365  369  423  431  451  452  456  460  489  508  513  552  623  628\n",
      "  649  717  727  822  854  864  867  875  887  899  907  908  924  926\n",
      "  980  986 1136 1155 1162 1169]\n",
      "48\n",
      "index 29 predicted label 0, but true label is 1\n",
      "('124264000', '124237001') Concept Pairs: (deficiency of glycerol-3-phosphate acyltransferase --- deficiency of transferase)\n",
      "index 45 predicted label 0, but true label is 1\n",
      "('122167004', '68793005') Concept Pairs: (measurement of borrelia burgdorferi 66 kilodalton antibody --- serologic test)\n",
      "index 60 predicted label 0, but true label is 1\n",
      "('362287008', '24314005') Concept Pairs: (entire pyramidal system --- pyramidal system structure)\n",
      "index 182 predicted label 0, but true label is 1\n",
      "('446695008', '363691001') Concept Pairs: (measurement of blood pressure at anterior tibial pulse using doppler --- procedure categorized by device involved)\n",
      "index 200 predicted label 0, but true label is 1\n",
      "('171448007', '445942002') Concept Pairs: (excision of lesion of temporal lobe of brain --- excision of temporal lobe)\n",
      "index 208 predicted label 0, but true label is 1\n",
      "('124263006', '124237001') Concept Pairs: (deficiency of glutamine phenylacetyltransferase --- deficiency of transferase)\n",
      "index 216 predicted label 1, but true label is 0\n",
      "('279689003', '399384005') Concept Pairs: (prostatic gland structure --- structure of transition zone of prostate)\n",
      "index 220 predicted label 0, but true label is 1\n",
      "('243799002', '129125009') Concept Pairs: (examination categorized by action status --- procedure with explicit context)\n",
      "index 236 predicted label 1, but true label is 0\n",
      "('245152001', '728179002') Concept Pairs: (tendon of fourth lumbrical muscle of hand --- entire tendon of second lumbrical muscle of hand)\n",
      "index 239 predicted label 1, but true label is 0\n",
      "('91715002', '119410002') Concept Pairs: (spinal cord, roots and ganglia structure --- nerve part)\n",
      "index 264 predicted label 0, but true label is 1\n",
      "('700463002', '238060000') Concept Pairs: (alpha-methylacyl-coa racemase deficiency disorder --- general loss of peroxisomal function)\n",
      "index 300 predicted label 0, but true label is 1\n",
      "('244847002', '244846006') Concept Pairs: (suboccipital muscle --- posterior vertebral muscle of neck)\n",
      "index 303 predicted label 0, but true label is 1\n",
      "('164108006', '11465001') Concept Pairs: (entire superior articular process of fourth cervical vertebra --- structure of superior articular process of fourth cervical vertebra)\n",
      "index 353 predicted label 1, but true label is 0\n",
      "('25751009', '125308006') Concept Pairs: (loss of fluid --- non-pitting edema)\n",
      "index 365 predicted label 0, but true label is 1\n",
      "('120072002', '4365001') Concept Pairs: (obstetrics repair --- surgical repair)\n",
      "index 369 predicted label 0, but true label is 1\n",
      "('712510007', '87763006') Concept Pairs: (intestinal hemorrhage --- lower gastrointestinal hemorrhage)\n",
      "index 423 predicted label 0, but true label is 1\n",
      "('62399001', '120055009') Concept Pairs: (autotransplantation of ovary --- ovary implantation)\n",
      "index 431 predicted label 1, but true label is 0\n",
      "('118287003', '399908004') Concept Pairs: (transitional cell neoplasm --- benign adenomatous neoplasm - category)\n",
      "index 451 predicted label 1, but true label is 0\n",
      "('62344005', '400039006') Concept Pairs: (congenital septation --- high-flow congenital vascular malformation)\n",
      "index 452 predicted label 1, but true label is 0\n",
      "('371023001', '400039006') Concept Pairs: (congenital abnormal communication --- high-flow congenital vascular malformation)\n",
      "index 456 predicted label 1, but true label is 0\n",
      "('81409000', '400039006') Concept Pairs: (coarctation --- high-flow congenital vascular malformation)\n",
      "index 460 predicted label 0, but true label is 1\n",
      "('721947001', '58443009') Concept Pairs: (structure of macula lutea of left eye --- structure of retina of left eye)\n",
      "index 489 predicted label 0, but true label is 1\n",
      "('168307001', '129125009') Concept Pairs: (skin ulcer swab taken --- procedure with explicit context)\n",
      "index 508 predicted label 0, but true label is 1\n",
      "('439368006', '449404007') Concept Pairs: (laparoscopic cryoablation of neoplasm of liver --- cryosurgery of lesion of liver)\n",
      "index 513 predicted label 1, but true label is 0\n",
      "('730069005', '369303007') Concept Pairs: (entire branch of middle cerebral artery --- entire cortical branch of middle cerebral artery)\n",
      "index 552 predicted label 1, but true label is 0\n",
      "('37176007', '1707008') Concept Pairs: (structure of massa intermedia --- structure of ventral nuclear group of thalamus)\n",
      "index 623 predicted label 0, but true label is 1\n",
      "('43526002', '110406006') Concept Pairs: (operative site --- effect of surgery)\n",
      "index 628 predicted label 0, but true label is 1\n",
      "('61471000119100', '402818009') Concept Pairs: (basal cell carcinoma of naris --- basal cell carcinoma of nose)\n",
      "index 649 predicted label 0, but true label is 1\n",
      "('28846007', '430925007') Concept Pairs: (histamine measurement --- measurement of substance)\n",
      "index 717 predicted label 1, but true label is 0\n",
      "('182422005', '304947003') Concept Pairs: (collateral ligament of metacarpophalangeal joint of little finger --- radial collateral ligament of metacarpophalangeal joint of middle finger)\n",
      "index 727 predicted label 0, but true label is 1\n",
      "('368066002', '65758004') Concept Pairs: (entire subcutaneous tissue of umbilicus --- subcutaneous tissue structure of umbilicus)\n",
      "index 822 predicted label 0, but true label is 1\n",
      "('37759000', '57134006') Concept Pairs: (surgical instrument, device --- instrument, device)\n",
      "index 854 predicted label 1, but true label is 0\n",
      "('125177007', '61542006') Concept Pairs: (spontaneous dislocation --- closed dislocation, complete)\n",
      "index 864 predicted label 0, but true label is 1\n",
      "('66595008', '128599005') Concept Pairs: (drug-related myocardial necrosis syndrome --- structural disorder of heart)\n",
      "index 867 predicted label 0, but true label is 1\n",
      "('336609007', '182358004') Concept Pairs: (entire ligament of trunk --- entire ligament)\n",
      "index 875 predicted label 1, but true label is 0\n",
      "('279963001', '790007') Concept Pairs: (border of liver --- structure of visceral aspect of liver)\n",
      "index 887 predicted label 0, but true label is 1\n",
      "('1584001', '58442004') Concept Pairs: (entire symphysis --- entire cartilaginous joint)\n",
      "index 899 predicted label 1, but true label is 0\n",
      "('727450000', '40832004') Concept Pairs: (entire vagus nerve branch --- structure of vagus nerve hepatic branch)\n",
      "index 907 predicted label 0, but true label is 1\n",
      "('414201007', '426658004') Concept Pairs: (family coriobacteriaceae --- suborder coriobacterineae)\n",
      "index 908 predicted label 0, but true label is 1\n",
      "('368065003', '38927002') Concept Pairs: (entire umbilical ring --- structure of umbilical ring)\n",
      "index 924 predicted label 0, but true label is 1\n",
      "('400047006', '49601007') Concept Pairs: (peripheral vascular disease --- disorder of cardiovascular system)\n",
      "index 926 predicted label 0, but true label is 1\n",
      "('27799005', '89031001') Concept Pairs: (postinflammatory hypopigmentation --- hypopigmentation)\n",
      "index 980 predicted label 0, but true label is 1\n",
      "('372784001', '395994000') Concept Pairs: (papaverine --- opium alkaloid)\n",
      "index 986 predicted label 0, but true label is 1\n",
      "('308822005', '42278009') Concept Pairs: (entire thyroglossal duct --- structure of thyroglossal duct)\n",
      "index 1136 predicted label 1, but true label is 0\n",
      "('181534001', '181536004') Concept Pairs: (entire skin of elbow --- skin of posterior surface of elbow)\n",
      "index 1155 predicted label 1, but true label is 0\n",
      "('361420009', '361498005') Concept Pairs: (hypobranchial eminence --- fourth branchial cleft)\n",
      "index 1162 predicted label 0, but true label is 1\n",
      "('68171009', '281777001') Concept Pairs: (axillary lymph node structure --- structure of lymphatic system of axilla)\n",
      "index 1169 predicted label 0, but true label is 1\n",
      "('440413003', '363691001') Concept Pairs: (aspiration of urinary bladder using needle --- procedure categorized by device involved)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = sess.run(predict, feed_dict={x:test_feature, keep_prob:1, is_training:False})\n",
    "print(y_pred[:20])\n",
    "print(test_y[:20])\n",
    "\n",
    "\n",
    "err_ids=np.flatnonzero(y_pred != test_y)\n",
    "\n",
    "print(err_ids)\n",
    "print(err_ids.size)\n",
    "for err_id in err_ids:\n",
    "    print(\"index %d predicted label %s, but true label is %s\" % (err_id, y_pred[err_id], test_y[err_id]))\n",
    "    idpair = test_list_ids[err_id] \n",
    "    concept1 = conceptLabelDict[idpair[0]]\n",
    "    concept2 = conceptLabelDict[idpair[1]]\n",
    "    print(\"%s Concept Pairs: (%s --- %s)\" % (idpair, concept1, concept2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "err_ids=np.flatnonzero(result != test_label_list)\n",
    "\n",
    "print(err_ids)\n",
    "print(err_ids.size)\n",
    "for err_id in err_ids:\n",
    "    idpair = test_list_ids[err_id] \n",
    "    print(idpair)\n",
    "    concept1 = conceptLabelDict[idpair[0]]\n",
    "    concept2 = conceptLabelDict[idpair[1]]\n",
    "    print(\"(Concept 1 %s ---- Concept 2 %s)\" % (concept1, concept2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plist = [[1,2,3], [3,4,5], [3,4,5], [5,6,7],[2,3,7]]\n",
    "\n",
    "plist.extend([1]*4)\n",
    "print(plist)\n",
    "\n",
    "index = np.arange(5)\n",
    "\n",
    "c = [plist[b] for b in index[:2]]\n",
    "print(c)\n",
    "c.extend([plist[b] for b in index[2:]])\n",
    "print(c)\n",
    "\n",
    "for i in range(3):      # i is the class index, for example, i==0 for class 0, i==1 for class 1 ...\n",
    "    index = np.arange(30)     #generate numbers from 0 to 2999\n",
    "    np.random.shuffle(index)        #shuffle the 3000 values\n",
    "    index = [int(300*i+j) for j in index]\n",
    "    print(index)\n",
    "    print(np.array(index)[0:5])\n",
    "    print(np.array(index)[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=np.array([1,2,3])\n",
    "y=np.append(y, [1]*4)\n",
    "y= np.append(y, [0])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"D:/MLOntology/model1\"\n",
    "\n",
    "print(path)\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(inferred_vector)\n",
    "print(inferred_vector.size)\n",
    "# pprint(model.docvecs.most_similar([inferred_vector], topn=20))\n",
    "\n",
    "\n",
    "path = \"D:/MLOntology/model0\"\n",
    "\n",
    "print(path)\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(inferred_vector)\n",
    "print(inferred_vector.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.docvecs['SENT_5690']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "print(X)\n",
    "print(y)\n",
    "train_errors=[]\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y)  \n",
    "\n",
    "train_errors.append(clf.score(X, y))\n",
    "print(train_errors)\n",
    "X_test=[[2,2]]\n",
    "y_test = [1]\n",
    "test_errors=[]\n",
    "clf.predict(X_test)\n",
    "\n",
    "test_errors.append(clf.score(X_test, y_test))\n",
    "print(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "a= model.docvecs[0]\n",
    "b= model.docvecs[1]\n",
    "m1 = np.array((a, b))\n",
    "\n",
    "# print(np.reshape(m1, 1024))\n",
    "# print(np.reshape(m1, 400, order='F')) # two ways of reshape\n",
    "\n",
    "c= model.docvecs[2]\n",
    "d= model.docvecs[3]\n",
    "print(c.shape)\n",
    "print(d.shape)\n",
    "print(c.shape[0]+d.shape[0])\n",
    "m2 = np.array((c, d))\n",
    "\n",
    "m1 = np.reshape(m1, 1024)\n",
    "m2 = np.reshape(m2, 1024)\n",
    "# m1 = np.reshape(m1, 1024, order='F')\n",
    "# m2 = np.reshape(m2, 1024, order='F')\n",
    "\n",
    "print(m1)\n",
    "\n",
    "X = [m1, m2]\n",
    "print(X)\n",
    "\n",
    "XX = np.append(m1, m2)\n",
    "print(XX)\n",
    "\n",
    "y = [0, 1]\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X, y)\n",
    "\n",
    "m3 = np.array((a,d))\n",
    "m3 = np.reshape(m3, 1024, order='F')\n",
    "\n",
    "result = clf.predict([m3])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a=  np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "m1 = np.array((a, b))\n",
    "print(m1)\n",
    "\n",
    "m2 = np.vstack((a, b)).T\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDict={}\n",
    "testDict[0] = (\"a\", \"b\")\n",
    "print(testDict[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1,1,0,1,0,1,0])\n",
    "b = np.array([0,1,0,1,0,1,1])\n",
    "\n",
    "np.flatnonzero(a!=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
