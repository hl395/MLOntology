{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hao/anaconda3/envs/MLOntology/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import multiprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variabls\n",
    "\n",
    "directory_path =  \"/home/hao/AnacondaProjects/MLOntology/NCIt/\"\n",
    "data_path = directory_path + \"data/\"\n",
    "vector_model_path = directory_path +\"vectorModel/\"\n",
    "cnn_model_path = directory_path +\"cnnModel/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_trailing_number(s):\n",
    "    m = re.search(r'\\d+$', s)\n",
    "    return m.group() if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prostate carcinoma\n",
      "stage ia esophageal cancer ajcc v7\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#read class label file\n",
    "#create mapping from id to labels  \n",
    "#iso-8859-1 , encoding=\"iso-8859-1\"\n",
    "conceptLabelDict={}\n",
    "errors=[]\n",
    "\n",
    "def read_label(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                conceptID = get_trailing_number(splitted[1])\n",
    "                conceptLabelDict[conceptID] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "label_file = data_path + \"ontClassLabels_owl_ncit.txt\"\n",
    "read_label(label_file)\n",
    "print(conceptLabelDict[\"4863\"])\n",
    "print(conceptLabelDict[\"115117\"])\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['4861', '7318', 1], ['87152', '87150', 1], ['87153', '140032', 1], ['87154', '87153', 1], ['87155', '87153', 1]]\n",
      "16533\n"
     ]
    }
   ],
   "source": [
    "conceptPairDict={}\n",
    "errors=[]\n",
    "conceptPairList=[]\n",
    "\n",
    "def read_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                childID = get_trailing_number(splitted[1])\n",
    "                parentID = get_trailing_number(splitted[2].replace(\"\\r\\n\", \"\"))\n",
    "                conceptPairList.append([childID, parentID , 1])\n",
    "#                 conceptPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "pair_file = data_path + \"ontHierarchy_owl_ncit.txt\"\n",
    "read_pair(pair_file)\n",
    "\n",
    "checkpairs = conceptPairList[10:15]\n",
    "print(checkpairs)\n",
    "print(len(conceptPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['7918', '9151', 0], ['7918', '48612', 0], ['7918', '48613', 0], ['7918', '91231', 0], ['7918', '66753', 0]]\n",
      "37147\n"
     ]
    }
   ],
   "source": [
    "conceptNotPairDict={}\n",
    "conceptNotPairList=[]\n",
    "\n",
    "def read_not_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==2:\n",
    "                childID = get_trailing_number(splitted[0])\n",
    "                notparentID = get_trailing_number(splitted[1].replace(\"\\r\\n\", \"\"))\n",
    "                conceptNotPairList.append([childID, notparentID, 0])\n",
    "#                 conceptNotPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "notPair_file = data_path + \"taxNotPairs_owl_ncit.txt\"\n",
    "read_not_pair(notPair_file)\n",
    "\n",
    "\n",
    "first2pairs =conceptNotPairList[10:15]\n",
    "print(first2pairs)\n",
    "print(len(conceptNotPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(len(conceptPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(conceptPairList) < len(conceptNotPairList):\n",
    "    # In-place shuffle\n",
    "    random.shuffle(conceptNotPairList)\n",
    "    leftPairList = conceptNotPairList[len(conceptPairList):]\n",
    "    conceptNotPairList = conceptNotPairList[:len(conceptPairList)]\n",
    "else:\n",
    "    # In-place shuffle\n",
    "    random.shuffle(conceptPairList)\n",
    "    leftPairList = conceptPairList[len(conceptNotPairList):]\n",
    "    conceptPairList = conceptPairList[:len(conceptNotPairList)]\n",
    "\n",
    "assert len(conceptPairList) == len(conceptNotPairList), \"Mistmatch in POS&NEG samples!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20614\n"
     ]
    }
   ],
   "source": [
    "print(len(leftPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('7576', 0.7686420679092407),\n",
      " ('82862', 0.7540969848632812),\n",
      " ('4495', 0.7524679899215698),\n",
      " ('4229', 0.7506747245788574),\n",
      " ('3804', 0.7484248876571655),\n",
      " ('4486', 0.7465652227401733),\n",
      " ('3033', 0.7464011311531067),\n",
      " ('4234', 0.745087742805481),\n",
      " ('3803', 0.7450522184371948),\n",
      " ('3694', 0.7374510765075684)]\n"
     ]
    }
   ],
   "source": [
    "#  PV-DBOW\n",
    "vector_model_file = vector_model_path + \"model0\"\n",
    "\n",
    "vector_model = gensim.models.Doc2Vec.load(vector_model_file)\n",
    "\n",
    "inferred_vector = vector_model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(vector_model.docvecs.most_similar([inferred_vector], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('8965', 0.49586647748947144),\n",
      " ('3694', 0.49576500058174133),\n",
      " ('4562', 0.49446868896484375),\n",
      " ('7158', 0.4795208275318146),\n",
      " ('4557', 0.47393715381622314),\n",
      " ('5665', 0.4628344178199768),\n",
      " ('7045', 0.4492914378643036),\n",
      " ('114940', 0.44915124773979187),\n",
      " ('3810', 0.44833317399024963),\n",
      " ('5365', 0.44617414474487305)]\n"
     ]
    }
   ],
   "source": [
    "# PV-DM seems better??\n",
    "vector_model_file = vector_model_path + \"model1\"\n",
    "\n",
    "vector_model = gensim.models.Doc2Vec.load(vector_model_file)\n",
    "\n",
    "inferred_vector = vector_model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(vector_model.docvecs.most_similar([inferred_vector], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_model.docvecs['7918']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def readFromPairList(id_pair_list, id_notPair_list):\n",
    "    pair_list = id_pair_list + id_notPair_list\n",
    "    random.shuffle(pair_list)\n",
    "    idpairs_list =[]\n",
    "    label_list =[]\n",
    "    for i, line in enumerate(pair_list):      \n",
    "        idpairs_list.append([line[0], line[1]])\n",
    "        label_list.append(line[2])\n",
    "    return idpairs_list, label_list\n",
    "\n",
    "idpairs_list, label_list= readFromPairList(conceptPairList, conceptNotPairList)\n",
    "\n",
    "print(label_list[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['96948', '96810'], ['3574', '3061'], ['7355', '7716'], ['134615', '7711'], ['89476', '2917'], ['6682', '88888'], ['115225', '3851'], ['27721', '3406'], ['148065', '7055'], ['27267', '7340'], ['43535', '7724'], ['4723', '5305'], ['133564', '35180'], ['39644', '68838'], ['7469', '7489'], ['6148', '4122'], ['3127', '3156'], ['7194', '8968'], ['5860', '5029'], ['27392', '43329']]\n",
      "[['8791', '54663'], ['115432', '6283'], ['9360', '3211'], ['7152', '8923'], ['27889', '91201'], ['7082', '7081'], ['4670', '40406'], ['115370', '9045'], ['5488', '27439'], ['133005', '133003'], ['9347', '3646'], ['134614', '7121'], ['8068', '27809'], ['4862', '36255'], ['6002', '8771'], ['27293', '7653'], ['133592', '4937'], ['2857', '7364'], ['7404', '7398'], ['27859', '4342']]\n",
      "[1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0]\n",
      "[0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(idpairs_list, label_list, test_size = 0.2, shuffle= True)\n",
    "print(X_train[:20])\n",
    "print(X_validation[:20])\n",
    "print(y_train[:20])\n",
    "print(y_validation[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 256 # 128 + 128\n",
    "\n",
    "def getVectorFromModel(concept_id, conceptLabelDict, model):\n",
    "    if concept_id in model.docvecs:\n",
    "        concept_vector= model.docvecs[concept_id]\n",
    "    else:\n",
    "        print(\"%s not found, get inferred vector \"%(concept_id))\n",
    "        concept_label = conceptLabelDict[concept_id]\n",
    "        concept_vector= model.infer_vector(concept_label.split())\n",
    "    return concept_vector\n",
    "\n",
    "def getVector(line, conceptLabelDict, model):        \n",
    "    a = getVectorFromModel(line[0], conceptLabelDict, model)\n",
    "    b = getVectorFromModel(line[1], conceptLabelDict, model)\n",
    "    c = np.array((a, b))\n",
    "    c = np.reshape(c, (256,1), order='F')\n",
    "#     c = c.T \n",
    "#     c = np.expand_dims(c, axis=2)\n",
    "#     print(c.shape)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackVector(vector):\n",
    "    from numpy import dstack\n",
    "    return dstack((vector, vector, vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=2 \n",
    "\n",
    "def get_batches(x_samples, y_samples, batch_size=64):\n",
    "    samples = list(zip(x_samples, y_samples))\n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    shuffle(samples)\n",
    "    for offset in range(0, num_samples, batch_size):\n",
    "        batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "        X_samples = []\n",
    "        Y_samples= []\n",
    "        for batch_sample in batch_samples:\n",
    "            pair_list = batch_sample[0]\n",
    "            data_vector = getVector(pair_list, conceptLabelDict, vector_model)\n",
    "#                 data_vector = stackVector(data_vector)\n",
    "#             print(data_vector.shape)\n",
    "            X_samples.append(data_vector)\n",
    "            class_label = batch_sample[1] \n",
    "            Y_samples.append(class_label)\n",
    "\n",
    "        X_samples = np.array(X_samples).astype('float32')\n",
    "        Y_samples = np.eye(n_classes)[Y_samples]\n",
    "#             print('one batch ready')\n",
    "        yield shuffle(X_samples, Y_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_batches(X, y, batch_size = 100):\n",
    "    \"\"\" Return a generator for batches \"\"\"\n",
    "    n_batches = len(X) // batch_size\n",
    "    X, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over batches and yield\n",
    "    for b in range(0, len(X), batch_size):\n",
    "        yield X[b:b+batch_size], y[b:b+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "# build the model??\n",
    "batch_size = 1000       # Batch size\n",
    "seq_len = 256          # Number of steps\n",
    "learning_rate = 0.0001\n",
    "epochs = 1000\n",
    "\n",
    "n_classes = 2\n",
    "n_channels = 1\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')\n",
    "\n",
    "    \n",
    "with graph.as_default():\n",
    "    # (batch, 256, 1) --> (batch, 128, 9)\n",
    "    conv0 = tf.layers.conv1d(inputs=inputs_, filters=9, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_0 = tf.layers.max_pooling1d(inputs=conv0, pool_size=2, strides=2, padding='same')\n",
    "    # (batch, 128, 9) --> (batch, 64, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=max_pool_0, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 64, 18) --> (batch, 32, 36)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=36, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 32, 36) --> (batch, 16, 72)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=72, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 16, 72) --> (batch, 8, 144)\n",
    "    conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=144, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=2, strides=2, padding='same')\n",
    "\n",
    "\n",
    "with graph.as_default():\n",
    "    # Flatten and add dropout\n",
    "    flat = tf.reshape(max_pool_4, (-1, 8*144))\n",
    "    flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat, n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-cnn') == False):\n",
    "    !mkdir checkpoints-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/500 Iteration: 50 Train loss: 0.685435 Train acc: 0.540000\n",
      "Epoch: 1/500 Iteration: 100 Train loss: 0.677512 Train acc: 0.617500\n",
      "Epoch: 1/500 Iteration: 100 Validation loss: 0.674008 Validation acc: 0.683048\n",
      "Epoch: 2/500 Iteration: 150 Train loss: 0.652459 Train acc: 0.680000\n",
      "Epoch: 2/500 Iteration: 200 Train loss: 0.607811 Train acc: 0.677500\n",
      "Epoch: 2/500 Iteration: 200 Validation loss: 0.584217 Validation acc: 0.741615\n",
      "Epoch: 3/500 Iteration: 250 Train loss: 0.592736 Train acc: 0.710000\n",
      "Epoch: 4/500 Iteration: 300 Train loss: 0.502282 Train acc: 0.770000\n",
      "Epoch: 4/500 Iteration: 300 Validation loss: 0.504274 Validation acc: 0.757637\n",
      "Epoch: 5/500 Iteration: 350 Train loss: 0.478823 Train acc: 0.770000\n",
      "Epoch: 5/500 Iteration: 400 Train loss: 0.472114 Train acc: 0.787500\n",
      "Epoch: 5/500 Iteration: 400 Validation loss: 0.464137 Validation acc: 0.783187\n",
      "Epoch: 6/500 Iteration: 450 Train loss: 0.421783 Train acc: 0.825000\n",
      "Epoch: 7/500 Iteration: 500 Train loss: 0.433389 Train acc: 0.795000\n",
      "Epoch: 7/500 Iteration: 500 Validation loss: 0.438427 Validation acc: 0.802042\n",
      "Epoch: 8/500 Iteration: 550 Train loss: 0.450362 Train acc: 0.795000\n",
      "Epoch: 8/500 Iteration: 600 Train loss: 0.405301 Train acc: 0.822500\n",
      "Epoch: 8/500 Iteration: 600 Validation loss: 0.426051 Validation acc: 0.805041\n",
      "Epoch: 9/500 Iteration: 650 Train loss: 0.409115 Train acc: 0.827500\n",
      "Epoch: 10/500 Iteration: 700 Train loss: 0.387340 Train acc: 0.817500\n",
      "Epoch: 10/500 Iteration: 700 Validation loss: 0.422507 Validation acc: 0.801198\n",
      "Epoch: 11/500 Iteration: 750 Train loss: 0.455368 Train acc: 0.775000\n",
      "Epoch: 11/500 Iteration: 800 Train loss: 0.470080 Train acc: 0.757500\n",
      "Epoch: 11/500 Iteration: 800 Validation loss: 0.408375 Validation acc: 0.815143\n",
      "Epoch: 12/500 Iteration: 850 Train loss: 0.385079 Train acc: 0.835000\n",
      "Epoch: 13/500 Iteration: 900 Train loss: 0.436658 Train acc: 0.795000\n",
      "Epoch: 13/500 Iteration: 900 Validation loss: 0.410136 Validation acc: 0.811652\n",
      "Epoch: 14/500 Iteration: 950 Train loss: 0.412664 Train acc: 0.792500\n",
      "Epoch: 14/500 Iteration: 1000 Train loss: 0.464360 Train acc: 0.805000\n",
      "Epoch: 14/500 Iteration: 1000 Validation loss: 0.398522 Validation acc: 0.820104\n",
      "Epoch: 15/500 Iteration: 1050 Train loss: 0.414483 Train acc: 0.815000\n",
      "Epoch: 16/500 Iteration: 1100 Train loss: 0.420698 Train acc: 0.815000\n",
      "Epoch: 16/500 Iteration: 1100 Validation loss: 0.397155 Validation acc: 0.819938\n",
      "Epoch: 17/500 Iteration: 1150 Train loss: 0.383954 Train acc: 0.825000\n",
      "Epoch: 17/500 Iteration: 1200 Train loss: 0.383221 Train acc: 0.837500\n",
      "Epoch: 17/500 Iteration: 1200 Validation loss: 0.393513 Validation acc: 0.822438\n",
      "Epoch: 18/500 Iteration: 1250 Train loss: 0.384847 Train acc: 0.815000\n",
      "Epoch: 19/500 Iteration: 1300 Train loss: 0.401932 Train acc: 0.817500\n",
      "Epoch: 19/500 Iteration: 1300 Validation loss: 0.390286 Validation acc: 0.824164\n",
      "Epoch: 20/500 Iteration: 1350 Train loss: 0.407039 Train acc: 0.825000\n",
      "Epoch: 20/500 Iteration: 1400 Train loss: 0.447237 Train acc: 0.787500\n",
      "Epoch: 20/500 Iteration: 1400 Validation loss: 0.388728 Validation acc: 0.826556\n",
      "Epoch: 21/500 Iteration: 1450 Train loss: 0.378929 Train acc: 0.835000\n",
      "Epoch: 22/500 Iteration: 1500 Train loss: 0.397511 Train acc: 0.802500\n",
      "Epoch: 22/500 Iteration: 1500 Validation loss: 0.387005 Validation acc: 0.826869\n",
      "Epoch: 23/500 Iteration: 1550 Train loss: 0.415065 Train acc: 0.830000\n",
      "Epoch: 23/500 Iteration: 1600 Train loss: 0.433463 Train acc: 0.780000\n",
      "Epoch: 23/500 Iteration: 1600 Validation loss: 0.383960 Validation acc: 0.827380\n",
      "Epoch: 24/500 Iteration: 1650 Train loss: 0.431856 Train acc: 0.770000\n",
      "Epoch: 25/500 Iteration: 1700 Train loss: 0.445919 Train acc: 0.792500\n",
      "Epoch: 25/500 Iteration: 1700 Validation loss: 0.384708 Validation acc: 0.825584\n",
      "Epoch: 26/500 Iteration: 1750 Train loss: 0.415390 Train acc: 0.812500\n",
      "Epoch: 26/500 Iteration: 1800 Train loss: 0.358483 Train acc: 0.820000\n",
      "Epoch: 26/500 Iteration: 1800 Validation loss: 0.379762 Validation acc: 0.830008\n",
      "Epoch: 27/500 Iteration: 1850 Train loss: 0.412818 Train acc: 0.810000\n",
      "Epoch: 28/500 Iteration: 1900 Train loss: 0.395850 Train acc: 0.812500\n",
      "Epoch: 28/500 Iteration: 1900 Validation loss: 0.381357 Validation acc: 0.827771\n",
      "Epoch: 29/500 Iteration: 1950 Train loss: 0.392242 Train acc: 0.832500\n",
      "Epoch: 29/500 Iteration: 2000 Train loss: 0.468332 Train acc: 0.792500\n",
      "Epoch: 29/500 Iteration: 2000 Validation loss: 0.377450 Validation acc: 0.827841\n",
      "Epoch: 30/500 Iteration: 2050 Train loss: 0.396359 Train acc: 0.795000\n",
      "Epoch: 31/500 Iteration: 2100 Train loss: 0.376446 Train acc: 0.817500\n",
      "Epoch: 31/500 Iteration: 2100 Validation loss: 0.376677 Validation acc: 0.829222\n",
      "Epoch: 32/500 Iteration: 2150 Train loss: 0.369786 Train acc: 0.832500\n",
      "Epoch: 32/500 Iteration: 2200 Train loss: 0.376437 Train acc: 0.825000\n",
      "Epoch: 32/500 Iteration: 2200 Validation loss: 0.375875 Validation acc: 0.828007\n",
      "Epoch: 33/500 Iteration: 2250 Train loss: 0.398135 Train acc: 0.830000\n",
      "Epoch: 34/500 Iteration: 2300 Train loss: 0.368683 Train acc: 0.827500\n",
      "Epoch: 34/500 Iteration: 2300 Validation loss: 0.371854 Validation acc: 0.833135\n",
      "Epoch: 35/500 Iteration: 2350 Train loss: 0.384410 Train acc: 0.840000\n",
      "Epoch: 35/500 Iteration: 2400 Train loss: 0.436185 Train acc: 0.785000\n",
      "Epoch: 35/500 Iteration: 2400 Validation loss: 0.372808 Validation acc: 0.826684\n",
      "Epoch: 36/500 Iteration: 2450 Train loss: 0.411358 Train acc: 0.817500\n",
      "Epoch: 37/500 Iteration: 2500 Train loss: 0.343371 Train acc: 0.850000\n",
      "Epoch: 37/500 Iteration: 2500 Validation loss: 0.368685 Validation acc: 0.835175\n",
      "Epoch: 38/500 Iteration: 2550 Train loss: 0.411735 Train acc: 0.805000\n",
      "Epoch: 38/500 Iteration: 2600 Train loss: 0.378598 Train acc: 0.840000\n",
      "Epoch: 38/500 Iteration: 2600 Validation loss: 0.370322 Validation acc: 0.830450\n",
      "Epoch: 39/500 Iteration: 2650 Train loss: 0.375793 Train acc: 0.817500\n",
      "Epoch: 40/500 Iteration: 2700 Train loss: 0.382345 Train acc: 0.830000\n",
      "Epoch: 40/500 Iteration: 2700 Validation loss: 0.366371 Validation acc: 0.833832\n",
      "Epoch: 41/500 Iteration: 2750 Train loss: 0.373833 Train acc: 0.832500\n",
      "Epoch: 41/500 Iteration: 2800 Train loss: 0.362053 Train acc: 0.830000\n",
      "Epoch: 41/500 Iteration: 2800 Validation loss: 0.364831 Validation acc: 0.833263\n",
      "Epoch: 42/500 Iteration: 2850 Train loss: 0.401970 Train acc: 0.812500\n",
      "Epoch: 43/500 Iteration: 2900 Train loss: 0.375885 Train acc: 0.810000\n",
      "Epoch: 43/500 Iteration: 2900 Validation loss: 0.363698 Validation acc: 0.834567\n",
      "Epoch: 44/500 Iteration: 2950 Train loss: 0.355466 Train acc: 0.845000\n",
      "Epoch: 44/500 Iteration: 3000 Train loss: 0.378741 Train acc: 0.810000\n",
      "Epoch: 44/500 Iteration: 3000 Validation loss: 0.362034 Validation acc: 0.835891\n",
      "Epoch: 45/500 Iteration: 3050 Train loss: 0.356760 Train acc: 0.830000\n",
      "Epoch: 46/500 Iteration: 3100 Train loss: 0.399596 Train acc: 0.812500\n",
      "Epoch: 46/500 Iteration: 3100 Validation loss: 0.361675 Validation acc: 0.835008\n",
      "Epoch: 47/500 Iteration: 3150 Train loss: 0.351119 Train acc: 0.835000\n",
      "Epoch: 47/500 Iteration: 3200 Train loss: 0.357117 Train acc: 0.840000\n",
      "Epoch: 47/500 Iteration: 3200 Validation loss: 0.361252 Validation acc: 0.836095\n",
      "Epoch: 48/500 Iteration: 3250 Train loss: 0.409821 Train acc: 0.815000\n",
      "Epoch: 49/500 Iteration: 3300 Train loss: 0.414091 Train acc: 0.797500\n",
      "Epoch: 49/500 Iteration: 3300 Validation loss: 0.359122 Validation acc: 0.836754\n",
      "Epoch: 49/500 Iteration: 3350 Train loss: 0.457190 Train acc: 0.788462\n",
      "Epoch: 50/500 Iteration: 3400 Train loss: 0.375655 Train acc: 0.820000\n",
      "Epoch: 50/500 Iteration: 3400 Validation loss: 0.360514 Validation acc: 0.836684\n",
      "Epoch: 51/500 Iteration: 3450 Train loss: 0.369250 Train acc: 0.817500\n",
      "Epoch: 52/500 Iteration: 3500 Train loss: 0.339375 Train acc: 0.845000\n",
      "Epoch: 52/500 Iteration: 3500 Validation loss: 0.357361 Validation acc: 0.837214\n",
      "Epoch: 52/500 Iteration: 3550 Train loss: 0.405252 Train acc: 0.817500\n",
      "Epoch: 53/500 Iteration: 3600 Train loss: 0.426732 Train acc: 0.797500\n",
      "Epoch: 53/500 Iteration: 3600 Validation loss: 0.360520 Validation acc: 0.834516\n",
      "Epoch: 54/500 Iteration: 3650 Train loss: 0.366090 Train acc: 0.825000\n",
      "Epoch: 55/500 Iteration: 3700 Train loss: 0.340772 Train acc: 0.850000\n",
      "Epoch: 55/500 Iteration: 3700 Validation loss: 0.355549 Validation acc: 0.836204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/500 Iteration: 3750 Train loss: 0.363845 Train acc: 0.825000\n",
      "Epoch: 56/500 Iteration: 3800 Train loss: 0.310034 Train acc: 0.880000\n",
      "Epoch: 56/500 Iteration: 3800 Validation loss: 0.358346 Validation acc: 0.835124\n",
      "Epoch: 57/500 Iteration: 3850 Train loss: 0.352487 Train acc: 0.827500\n",
      "Epoch: 58/500 Iteration: 3900 Train loss: 0.372352 Train acc: 0.835000\n",
      "Epoch: 58/500 Iteration: 3900 Validation loss: 0.353219 Validation acc: 0.837528\n",
      "Epoch: 58/500 Iteration: 3950 Train loss: 0.334994 Train acc: 0.832500\n",
      "Epoch: 59/500 Iteration: 4000 Train loss: 0.346290 Train acc: 0.865000\n",
      "Epoch: 59/500 Iteration: 4000 Validation loss: 0.353075 Validation acc: 0.838154\n",
      "Epoch: 60/500 Iteration: 4050 Train loss: 0.331351 Train acc: 0.842500\n",
      "Epoch: 61/500 Iteration: 4100 Train loss: 0.411800 Train acc: 0.805000\n",
      "Epoch: 61/500 Iteration: 4100 Validation loss: 0.351374 Validation acc: 0.837969\n",
      "Epoch: 61/500 Iteration: 4150 Train loss: 0.395044 Train acc: 0.805000\n",
      "Epoch: 62/500 Iteration: 4200 Train loss: 0.319772 Train acc: 0.867500\n",
      "Epoch: 62/500 Iteration: 4200 Validation loss: 0.349694 Validation acc: 0.839970\n",
      "Epoch: 63/500 Iteration: 4250 Train loss: 0.370516 Train acc: 0.822500\n",
      "Epoch: 64/500 Iteration: 4300 Train loss: 0.359041 Train acc: 0.832500\n",
      "Epoch: 64/500 Iteration: 4300 Validation loss: 0.348891 Validation acc: 0.840264\n",
      "Epoch: 64/500 Iteration: 4350 Train loss: 0.396813 Train acc: 0.805000\n",
      "Epoch: 65/500 Iteration: 4400 Train loss: 0.366659 Train acc: 0.817500\n",
      "Epoch: 65/500 Iteration: 4400 Validation loss: 0.348208 Validation acc: 0.840302\n",
      "Epoch: 66/500 Iteration: 4450 Train loss: 0.360261 Train acc: 0.825000\n",
      "Epoch: 67/500 Iteration: 4500 Train loss: 0.347362 Train acc: 0.832500\n",
      "Epoch: 67/500 Iteration: 4500 Validation loss: 0.347493 Validation acc: 0.840136\n",
      "Epoch: 67/500 Iteration: 4550 Train loss: 0.325934 Train acc: 0.855000\n",
      "Epoch: 68/500 Iteration: 4600 Train loss: 0.326817 Train acc: 0.847500\n",
      "Epoch: 68/500 Iteration: 4600 Validation loss: 0.347773 Validation acc: 0.839586\n",
      "Epoch: 69/500 Iteration: 4650 Train loss: 0.358274 Train acc: 0.835000\n",
      "Epoch: 70/500 Iteration: 4700 Train loss: 0.348492 Train acc: 0.852500\n",
      "Epoch: 70/500 Iteration: 4700 Validation loss: 0.345847 Validation acc: 0.841313\n",
      "Epoch: 70/500 Iteration: 4750 Train loss: 0.412566 Train acc: 0.807500\n",
      "Epoch: 71/500 Iteration: 4800 Train loss: 0.337327 Train acc: 0.837500\n",
      "Epoch: 71/500 Iteration: 4800 Validation loss: 0.345953 Validation acc: 0.840469\n",
      "Epoch: 72/500 Iteration: 4850 Train loss: 0.357588 Train acc: 0.822500\n",
      "Epoch: 73/500 Iteration: 4900 Train loss: 0.377361 Train acc: 0.832500\n",
      "Epoch: 73/500 Iteration: 4900 Validation loss: 0.344219 Validation acc: 0.841607\n",
      "Epoch: 73/500 Iteration: 4950 Train loss: 0.402785 Train acc: 0.810000\n",
      "Epoch: 74/500 Iteration: 5000 Train loss: 0.366658 Train acc: 0.837500\n",
      "Epoch: 74/500 Iteration: 5000 Validation loss: 0.347318 Validation acc: 0.843499\n",
      "Epoch: 75/500 Iteration: 5050 Train loss: 0.412236 Train acc: 0.802500\n",
      "Epoch: 76/500 Iteration: 5100 Train loss: 0.371421 Train acc: 0.840000\n",
      "Epoch: 76/500 Iteration: 5100 Validation loss: 0.342667 Validation acc: 0.842949\n",
      "Epoch: 76/500 Iteration: 5150 Train loss: 0.317234 Train acc: 0.845000\n",
      "Epoch: 77/500 Iteration: 5200 Train loss: 0.389571 Train acc: 0.812500\n",
      "Epoch: 77/500 Iteration: 5200 Validation loss: 0.347706 Validation acc: 0.842764\n",
      "Epoch: 78/500 Iteration: 5250 Train loss: 0.358386 Train acc: 0.840000\n",
      "Epoch: 79/500 Iteration: 5300 Train loss: 0.341914 Train acc: 0.867500\n",
      "Epoch: 79/500 Iteration: 5300 Validation loss: 0.340770 Validation acc: 0.842802\n",
      "Epoch: 79/500 Iteration: 5350 Train loss: 0.424419 Train acc: 0.830000\n",
      "Epoch: 80/500 Iteration: 5400 Train loss: 0.353601 Train acc: 0.832500\n",
      "Epoch: 80/500 Iteration: 5400 Validation loss: 0.345718 Validation acc: 0.843352\n",
      "Epoch: 81/500 Iteration: 5450 Train loss: 0.346356 Train acc: 0.845000\n",
      "Epoch: 82/500 Iteration: 5500 Train loss: 0.318664 Train acc: 0.865000\n",
      "Epoch: 82/500 Iteration: 5500 Validation loss: 0.339627 Validation acc: 0.843665\n",
      "Epoch: 82/500 Iteration: 5550 Train loss: 0.347592 Train acc: 0.835000\n",
      "Epoch: 83/500 Iteration: 5600 Train loss: 0.356740 Train acc: 0.832500\n",
      "Epoch: 83/500 Iteration: 5600 Validation loss: 0.339472 Validation acc: 0.845283\n",
      "Epoch: 84/500 Iteration: 5650 Train loss: 0.324353 Train acc: 0.857500\n",
      "Epoch: 85/500 Iteration: 5700 Train loss: 0.359153 Train acc: 0.837500\n",
      "Epoch: 85/500 Iteration: 5700 Validation loss: 0.337988 Validation acc: 0.845430\n",
      "Epoch: 85/500 Iteration: 5750 Train loss: 0.414201 Train acc: 0.800000\n",
      "Epoch: 86/500 Iteration: 5800 Train loss: 0.371847 Train acc: 0.837500\n",
      "Epoch: 86/500 Iteration: 5800 Validation loss: 0.336871 Validation acc: 0.844567\n",
      "Epoch: 87/500 Iteration: 5850 Train loss: 0.315092 Train acc: 0.850000\n",
      "Epoch: 88/500 Iteration: 5900 Train loss: 0.365053 Train acc: 0.840000\n",
      "Epoch: 88/500 Iteration: 5900 Validation loss: 0.336345 Validation acc: 0.846460\n",
      "Epoch: 88/500 Iteration: 5950 Train loss: 0.344688 Train acc: 0.850000\n",
      "Epoch: 89/500 Iteration: 6000 Train loss: 0.338554 Train acc: 0.842500\n",
      "Epoch: 89/500 Iteration: 6000 Validation loss: 0.338288 Validation acc: 0.846223\n",
      "Epoch: 90/500 Iteration: 6050 Train loss: 0.345541 Train acc: 0.847500\n",
      "Epoch: 91/500 Iteration: 6100 Train loss: 0.338065 Train acc: 0.845000\n",
      "Epoch: 91/500 Iteration: 6100 Validation loss: 0.335219 Validation acc: 0.844567\n",
      "Epoch: 91/500 Iteration: 6150 Train loss: 0.326636 Train acc: 0.870000\n",
      "Epoch: 92/500 Iteration: 6200 Train loss: 0.365034 Train acc: 0.850000\n",
      "Epoch: 92/500 Iteration: 6200 Validation loss: 0.339779 Validation acc: 0.845910\n",
      "Epoch: 93/500 Iteration: 6250 Train loss: 0.336299 Train acc: 0.840000\n",
      "Epoch: 94/500 Iteration: 6300 Train loss: 0.329477 Train acc: 0.840000\n",
      "Epoch: 94/500 Iteration: 6300 Validation loss: 0.333537 Validation acc: 0.847489\n",
      "Epoch: 94/500 Iteration: 6350 Train loss: 0.356349 Train acc: 0.835000\n",
      "Epoch: 95/500 Iteration: 6400 Train loss: 0.320092 Train acc: 0.840000\n",
      "Epoch: 95/500 Iteration: 6400 Validation loss: 0.338032 Validation acc: 0.846939\n",
      "Epoch: 96/500 Iteration: 6450 Train loss: 0.349790 Train acc: 0.837500\n",
      "Epoch: 97/500 Iteration: 6500 Train loss: 0.333898 Train acc: 0.842500\n",
      "Epoch: 97/500 Iteration: 6500 Validation loss: 0.332460 Validation acc: 0.848793\n",
      "Epoch: 97/500 Iteration: 6550 Train loss: 0.336394 Train acc: 0.835000\n",
      "Epoch: 98/500 Iteration: 6600 Train loss: 0.370773 Train acc: 0.827500\n",
      "Epoch: 98/500 Iteration: 6600 Validation loss: 0.333378 Validation acc: 0.847713\n",
      "Epoch: 99/500 Iteration: 6650 Train loss: 0.388844 Train acc: 0.820000\n",
      "Epoch: 99/500 Iteration: 6700 Train loss: 0.337860 Train acc: 0.865385\n",
      "Epoch: 99/500 Iteration: 6700 Validation loss: 0.330884 Validation acc: 0.849382\n",
      "Epoch: 100/500 Iteration: 6750 Train loss: 0.328023 Train acc: 0.832500\n",
      "Epoch: 101/500 Iteration: 6800 Train loss: 0.335552 Train acc: 0.840000\n",
      "Epoch: 101/500 Iteration: 6800 Validation loss: 0.329829 Validation acc: 0.850705\n",
      "Epoch: 102/500 Iteration: 6850 Train loss: 0.311292 Train acc: 0.872500\n",
      "Epoch: 102/500 Iteration: 6900 Train loss: 0.357324 Train acc: 0.842500\n",
      "Epoch: 102/500 Iteration: 6900 Validation loss: 0.330392 Validation acc: 0.850411\n",
      "Epoch: 103/500 Iteration: 6950 Train loss: 0.404418 Train acc: 0.797500\n",
      "Epoch: 104/500 Iteration: 7000 Train loss: 0.346036 Train acc: 0.847500\n",
      "Epoch: 104/500 Iteration: 7000 Validation loss: 0.330934 Validation acc: 0.850980\n",
      "Epoch: 105/500 Iteration: 7050 Train loss: 0.317347 Train acc: 0.872500\n",
      "Epoch: 105/500 Iteration: 7100 Train loss: 0.323307 Train acc: 0.840000\n",
      "Epoch: 105/500 Iteration: 7100 Validation loss: 0.333050 Validation acc: 0.848902\n",
      "Epoch: 106/500 Iteration: 7150 Train loss: 0.272311 Train acc: 0.905000\n",
      "Epoch: 107/500 Iteration: 7200 Train loss: 0.302665 Train acc: 0.865000\n",
      "Epoch: 107/500 Iteration: 7200 Validation loss: 0.333310 Validation acc: 0.849030\n",
      "Epoch: 108/500 Iteration: 7250 Train loss: 0.342106 Train acc: 0.837500\n",
      "Epoch: 108/500 Iteration: 7300 Train loss: 0.319014 Train acc: 0.845000\n",
      "Epoch: 108/500 Iteration: 7300 Validation loss: 0.332915 Validation acc: 0.849324\n",
      "Epoch: 109/500 Iteration: 7350 Train loss: 0.314410 Train acc: 0.877500\n",
      "Epoch: 110/500 Iteration: 7400 Train loss: 0.299888 Train acc: 0.860000\n",
      "Epoch: 110/500 Iteration: 7400 Validation loss: 0.335334 Validation acc: 0.848736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 111/500 Iteration: 7450 Train loss: 0.367276 Train acc: 0.837500\n",
      "Epoch: 111/500 Iteration: 7500 Train loss: 0.352657 Train acc: 0.827500\n",
      "Epoch: 111/500 Iteration: 7500 Validation loss: 0.330555 Validation acc: 0.851530\n",
      "Epoch: 112/500 Iteration: 7550 Train loss: 0.310524 Train acc: 0.867500\n",
      "Epoch: 113/500 Iteration: 7600 Train loss: 0.346823 Train acc: 0.827500\n",
      "Epoch: 113/500 Iteration: 7600 Validation loss: 0.333564 Validation acc: 0.849324\n",
      "Epoch: 114/500 Iteration: 7650 Train loss: 0.306149 Train acc: 0.867500\n",
      "Epoch: 114/500 Iteration: 7700 Train loss: 0.376737 Train acc: 0.825000\n",
      "Epoch: 114/500 Iteration: 7700 Validation loss: 0.325335 Validation acc: 0.854656\n",
      "Epoch: 115/500 Iteration: 7750 Train loss: 0.346558 Train acc: 0.837500\n",
      "Epoch: 116/500 Iteration: 7800 Train loss: 0.323198 Train acc: 0.847500\n",
      "Epoch: 116/500 Iteration: 7800 Validation loss: 0.326971 Validation acc: 0.853147\n",
      "Epoch: 117/500 Iteration: 7850 Train loss: 0.310813 Train acc: 0.857500\n",
      "Epoch: 117/500 Iteration: 7900 Train loss: 0.289819 Train acc: 0.880000\n",
      "Epoch: 117/500 Iteration: 7900 Validation loss: 0.323790 Validation acc: 0.854950\n",
      "Epoch: 118/500 Iteration: 7950 Train loss: 0.308089 Train acc: 0.847500\n",
      "Epoch: 119/500 Iteration: 8000 Train loss: 0.325416 Train acc: 0.845000\n",
      "Epoch: 119/500 Iteration: 8000 Validation loss: 0.322918 Validation acc: 0.855372\n",
      "Epoch: 120/500 Iteration: 8050 Train loss: 0.324345 Train acc: 0.852500\n",
      "Epoch: 120/500 Iteration: 8100 Train loss: 0.404445 Train acc: 0.805000\n",
      "Epoch: 120/500 Iteration: 8100 Validation loss: 0.324032 Validation acc: 0.854950\n",
      "Epoch: 121/500 Iteration: 8150 Train loss: 0.306526 Train acc: 0.867500\n",
      "Epoch: 122/500 Iteration: 8200 Train loss: 0.322809 Train acc: 0.837500\n",
      "Epoch: 122/500 Iteration: 8200 Validation loss: 0.321206 Validation acc: 0.855078\n",
      "Epoch: 123/500 Iteration: 8250 Train loss: 0.364732 Train acc: 0.837500\n",
      "Epoch: 123/500 Iteration: 8300 Train loss: 0.380568 Train acc: 0.817500\n",
      "Epoch: 123/500 Iteration: 8300 Validation loss: 0.323144 Validation acc: 0.855245\n",
      "Epoch: 124/500 Iteration: 8350 Train loss: 0.343342 Train acc: 0.837500\n",
      "Epoch: 125/500 Iteration: 8400 Train loss: 0.379468 Train acc: 0.820000\n",
      "Epoch: 125/500 Iteration: 8400 Validation loss: 0.321105 Validation acc: 0.855814\n",
      "Epoch: 126/500 Iteration: 8450 Train loss: 0.341743 Train acc: 0.842500\n",
      "Epoch: 126/500 Iteration: 8500 Train loss: 0.298176 Train acc: 0.857500\n",
      "Epoch: 126/500 Iteration: 8500 Validation loss: 0.320127 Validation acc: 0.855814\n",
      "Epoch: 127/500 Iteration: 8550 Train loss: 0.378074 Train acc: 0.822500\n",
      "Epoch: 128/500 Iteration: 8600 Train loss: 0.341339 Train acc: 0.845000\n",
      "Epoch: 128/500 Iteration: 8600 Validation loss: 0.321020 Validation acc: 0.856549\n",
      "Epoch: 129/500 Iteration: 8650 Train loss: 0.291883 Train acc: 0.885000\n",
      "Epoch: 129/500 Iteration: 8700 Train loss: 0.393895 Train acc: 0.847500\n",
      "Epoch: 129/500 Iteration: 8700 Validation loss: 0.318307 Validation acc: 0.857118\n",
      "Epoch: 130/500 Iteration: 8750 Train loss: 0.324453 Train acc: 0.845000\n",
      "Epoch: 131/500 Iteration: 8800 Train loss: 0.322077 Train acc: 0.845000\n",
      "Epoch: 131/500 Iteration: 8800 Validation loss: 0.319590 Validation acc: 0.858000\n",
      "Epoch: 132/500 Iteration: 8850 Train loss: 0.299873 Train acc: 0.855000\n",
      "Epoch: 132/500 Iteration: 8900 Train loss: 0.317288 Train acc: 0.842500\n",
      "Epoch: 132/500 Iteration: 8900 Validation loss: 0.318298 Validation acc: 0.856990\n",
      "Epoch: 133/500 Iteration: 8950 Train loss: 0.346710 Train acc: 0.860000\n",
      "Epoch: 134/500 Iteration: 9000 Train loss: 0.293414 Train acc: 0.870000\n",
      "Epoch: 134/500 Iteration: 9000 Validation loss: 0.316965 Validation acc: 0.858019\n",
      "Epoch: 135/500 Iteration: 9050 Train loss: 0.336025 Train acc: 0.852500\n",
      "Epoch: 135/500 Iteration: 9100 Train loss: 0.380191 Train acc: 0.832500\n",
      "Epoch: 135/500 Iteration: 9100 Validation loss: 0.318561 Validation acc: 0.858019\n",
      "Epoch: 136/500 Iteration: 9150 Train loss: 0.335048 Train acc: 0.862500\n",
      "Epoch: 137/500 Iteration: 9200 Train loss: 0.282337 Train acc: 0.880000\n",
      "Epoch: 137/500 Iteration: 9200 Validation loss: 0.316036 Validation acc: 0.859196\n",
      "Epoch: 138/500 Iteration: 9250 Train loss: 0.323363 Train acc: 0.880000\n",
      "Epoch: 138/500 Iteration: 9300 Train loss: 0.323103 Train acc: 0.855000\n",
      "Epoch: 138/500 Iteration: 9300 Validation loss: 0.322324 Validation acc: 0.856510\n",
      "Epoch: 139/500 Iteration: 9350 Train loss: 0.321932 Train acc: 0.865000\n",
      "Epoch: 140/500 Iteration: 9400 Train loss: 0.329818 Train acc: 0.865000\n",
      "Epoch: 140/500 Iteration: 9400 Validation loss: 0.314919 Validation acc: 0.859138\n",
      "Epoch: 141/500 Iteration: 9450 Train loss: 0.322527 Train acc: 0.855000\n",
      "Epoch: 141/500 Iteration: 9500 Train loss: 0.289441 Train acc: 0.885000\n",
      "Epoch: 141/500 Iteration: 9500 Validation loss: 0.319243 Validation acc: 0.859177\n",
      "Epoch: 142/500 Iteration: 9550 Train loss: 0.347021 Train acc: 0.850000\n",
      "Epoch: 143/500 Iteration: 9600 Train loss: 0.327647 Train acc: 0.837500\n",
      "Epoch: 143/500 Iteration: 9600 Validation loss: 0.313855 Validation acc: 0.858991\n",
      "Epoch: 144/500 Iteration: 9650 Train loss: 0.302673 Train acc: 0.865000\n",
      "Epoch: 144/500 Iteration: 9700 Train loss: 0.318446 Train acc: 0.847500\n",
      "Epoch: 144/500 Iteration: 9700 Validation loss: 0.315270 Validation acc: 0.859618\n",
      "Epoch: 145/500 Iteration: 9750 Train loss: 0.287388 Train acc: 0.855000\n",
      "Epoch: 146/500 Iteration: 9800 Train loss: 0.342425 Train acc: 0.842500\n",
      "Epoch: 146/500 Iteration: 9800 Validation loss: 0.312460 Validation acc: 0.860334\n",
      "Epoch: 147/500 Iteration: 9850 Train loss: 0.319196 Train acc: 0.852500\n",
      "Epoch: 147/500 Iteration: 9900 Train loss: 0.314776 Train acc: 0.857500\n",
      "Epoch: 147/500 Iteration: 9900 Validation loss: 0.312474 Validation acc: 0.860609\n",
      "Epoch: 148/500 Iteration: 9950 Train loss: 0.366546 Train acc: 0.832500\n",
      "Epoch: 149/500 Iteration: 10000 Train loss: 0.364007 Train acc: 0.847500\n",
      "Epoch: 149/500 Iteration: 10000 Validation loss: 0.311699 Validation acc: 0.861491\n",
      "Epoch: 149/500 Iteration: 10050 Train loss: 0.301835 Train acc: 0.826923\n",
      "Epoch: 150/500 Iteration: 10100 Train loss: 0.305596 Train acc: 0.855000\n",
      "Epoch: 150/500 Iteration: 10100 Validation loss: 0.312768 Validation acc: 0.861383\n",
      "Epoch: 151/500 Iteration: 10150 Train loss: 0.314207 Train acc: 0.850000\n",
      "Epoch: 152/500 Iteration: 10200 Train loss: 0.284258 Train acc: 0.875000\n",
      "Epoch: 152/500 Iteration: 10200 Validation loss: 0.311053 Validation acc: 0.861658\n",
      "Epoch: 152/500 Iteration: 10250 Train loss: 0.338393 Train acc: 0.862500\n",
      "Epoch: 153/500 Iteration: 10300 Train loss: 0.357294 Train acc: 0.837500\n",
      "Epoch: 153/500 Iteration: 10300 Validation loss: 0.315140 Validation acc: 0.857745\n",
      "Epoch: 154/500 Iteration: 10350 Train loss: 0.332350 Train acc: 0.840000\n",
      "Epoch: 155/500 Iteration: 10400 Train loss: 0.299916 Train acc: 0.877500\n",
      "Epoch: 155/500 Iteration: 10400 Validation loss: 0.310049 Validation acc: 0.861050\n",
      "Epoch: 155/500 Iteration: 10450 Train loss: 0.312160 Train acc: 0.855000\n",
      "Epoch: 156/500 Iteration: 10500 Train loss: 0.259411 Train acc: 0.907500\n",
      "Epoch: 156/500 Iteration: 10500 Validation loss: 0.318415 Validation acc: 0.854989\n",
      "Epoch: 157/500 Iteration: 10550 Train loss: 0.285360 Train acc: 0.875000\n",
      "Epoch: 158/500 Iteration: 10600 Train loss: 0.299352 Train acc: 0.857500\n",
      "Epoch: 158/500 Iteration: 10600 Validation loss: 0.311660 Validation acc: 0.862099\n",
      "Epoch: 158/500 Iteration: 10650 Train loss: 0.304348 Train acc: 0.865000\n",
      "Epoch: 159/500 Iteration: 10700 Train loss: 0.281322 Train acc: 0.885000\n",
      "Epoch: 159/500 Iteration: 10700 Validation loss: 0.313933 Validation acc: 0.857745\n",
      "Epoch: 160/500 Iteration: 10750 Train loss: 0.289531 Train acc: 0.880000\n",
      "Epoch: 161/500 Iteration: 10800 Train loss: 0.353333 Train acc: 0.845000\n",
      "Epoch: 161/500 Iteration: 10800 Validation loss: 0.308565 Validation acc: 0.862962\n",
      "Epoch: 161/500 Iteration: 10850 Train loss: 0.356257 Train acc: 0.825000\n",
      "Epoch: 162/500 Iteration: 10900 Train loss: 0.287380 Train acc: 0.872500\n",
      "Epoch: 162/500 Iteration: 10900 Validation loss: 0.308973 Validation acc: 0.864158\n",
      "Epoch: 163/500 Iteration: 10950 Train loss: 0.346627 Train acc: 0.852500\n",
      "Epoch: 164/500 Iteration: 11000 Train loss: 0.288723 Train acc: 0.877500\n",
      "Epoch: 164/500 Iteration: 11000 Validation loss: 0.307426 Validation acc: 0.864727\n",
      "Epoch: 164/500 Iteration: 11050 Train loss: 0.362805 Train acc: 0.837500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 165/500 Iteration: 11100 Train loss: 0.321339 Train acc: 0.842500\n",
      "Epoch: 165/500 Iteration: 11100 Validation loss: 0.306741 Validation acc: 0.864432\n",
      "Epoch: 166/500 Iteration: 11150 Train loss: 0.306965 Train acc: 0.860000\n",
      "Epoch: 167/500 Iteration: 11200 Train loss: 0.292571 Train acc: 0.875000\n",
      "Epoch: 167/500 Iteration: 11200 Validation loss: 0.306067 Validation acc: 0.864305\n",
      "Epoch: 167/500 Iteration: 11250 Train loss: 0.266669 Train acc: 0.897500\n",
      "Epoch: 168/500 Iteration: 11300 Train loss: 0.283695 Train acc: 0.885000\n",
      "Epoch: 168/500 Iteration: 11300 Validation loss: 0.305872 Validation acc: 0.865443\n",
      "Epoch: 169/500 Iteration: 11350 Train loss: 0.306646 Train acc: 0.852500\n",
      "Epoch: 170/500 Iteration: 11400 Train loss: 0.302590 Train acc: 0.865000\n",
      "Epoch: 170/500 Iteration: 11400 Validation loss: 0.305451 Validation acc: 0.865168\n",
      "Epoch: 170/500 Iteration: 11450 Train loss: 0.364219 Train acc: 0.845000\n",
      "Epoch: 171/500 Iteration: 11500 Train loss: 0.298605 Train acc: 0.862500\n",
      "Epoch: 171/500 Iteration: 11500 Validation loss: 0.307655 Validation acc: 0.862962\n",
      "Epoch: 172/500 Iteration: 11550 Train loss: 0.317526 Train acc: 0.845000\n",
      "Epoch: 173/500 Iteration: 11600 Train loss: 0.334253 Train acc: 0.842500\n",
      "Epoch: 173/500 Iteration: 11600 Validation loss: 0.304676 Validation acc: 0.866638\n",
      "Epoch: 173/500 Iteration: 11650 Train loss: 0.367925 Train acc: 0.825000\n",
      "Epoch: 174/500 Iteration: 11700 Train loss: 0.323733 Train acc: 0.825000\n",
      "Epoch: 174/500 Iteration: 11700 Validation loss: 0.311461 Validation acc: 0.861913\n",
      "Epoch: 175/500 Iteration: 11750 Train loss: 0.361408 Train acc: 0.827500\n",
      "Epoch: 176/500 Iteration: 11800 Train loss: 0.327103 Train acc: 0.867500\n",
      "Epoch: 176/500 Iteration: 11800 Validation loss: 0.303746 Validation acc: 0.866638\n",
      "Epoch: 176/500 Iteration: 11850 Train loss: 0.286492 Train acc: 0.880000\n",
      "Epoch: 177/500 Iteration: 11900 Train loss: 0.365659 Train acc: 0.827500\n",
      "Epoch: 177/500 Iteration: 11900 Validation loss: 0.319948 Validation acc: 0.857169\n",
      "Epoch: 178/500 Iteration: 11950 Train loss: 0.321052 Train acc: 0.852500\n",
      "Epoch: 179/500 Iteration: 12000 Train loss: 0.263066 Train acc: 0.907500\n",
      "Epoch: 179/500 Iteration: 12000 Validation loss: 0.303481 Validation acc: 0.866491\n",
      "Epoch: 179/500 Iteration: 12050 Train loss: 0.372361 Train acc: 0.837500\n",
      "Epoch: 180/500 Iteration: 12100 Train loss: 0.309354 Train acc: 0.855000\n",
      "Epoch: 180/500 Iteration: 12100 Validation loss: 0.316546 Validation acc: 0.858767\n",
      "Epoch: 181/500 Iteration: 12150 Train loss: 0.315157 Train acc: 0.850000\n",
      "Epoch: 182/500 Iteration: 12200 Train loss: 0.273308 Train acc: 0.877500\n",
      "Epoch: 182/500 Iteration: 12200 Validation loss: 0.303481 Validation acc: 0.864432\n",
      "Epoch: 182/500 Iteration: 12250 Train loss: 0.282469 Train acc: 0.885000\n",
      "Epoch: 183/500 Iteration: 12300 Train loss: 0.311977 Train acc: 0.850000\n",
      "Epoch: 183/500 Iteration: 12300 Validation loss: 0.306768 Validation acc: 0.864266\n",
      "Epoch: 184/500 Iteration: 12350 Train loss: 0.279251 Train acc: 0.892500\n",
      "Epoch: 185/500 Iteration: 12400 Train loss: 0.304230 Train acc: 0.865000\n",
      "Epoch: 185/500 Iteration: 12400 Validation loss: 0.302543 Validation acc: 0.865609\n",
      "Epoch: 185/500 Iteration: 12450 Train loss: 0.356794 Train acc: 0.825000\n",
      "Epoch: 186/500 Iteration: 12500 Train loss: 0.337406 Train acc: 0.865000\n",
      "Epoch: 186/500 Iteration: 12500 Validation loss: 0.300711 Validation acc: 0.867815\n",
      "Epoch: 187/500 Iteration: 12550 Train loss: 0.253375 Train acc: 0.900000\n",
      "Epoch: 188/500 Iteration: 12600 Train loss: 0.313348 Train acc: 0.880000\n",
      "Epoch: 188/500 Iteration: 12600 Validation loss: 0.300688 Validation acc: 0.868422\n",
      "Epoch: 188/500 Iteration: 12650 Train loss: 0.316306 Train acc: 0.862500\n",
      "Epoch: 189/500 Iteration: 12700 Train loss: 0.284074 Train acc: 0.880000\n",
      "Epoch: 189/500 Iteration: 12700 Validation loss: 0.305133 Validation acc: 0.864490\n",
      "Epoch: 190/500 Iteration: 12750 Train loss: 0.307832 Train acc: 0.877500\n",
      "Epoch: 191/500 Iteration: 12800 Train loss: 0.308551 Train acc: 0.860000\n",
      "Epoch: 191/500 Iteration: 12800 Validation loss: 0.302325 Validation acc: 0.867648\n",
      "Epoch: 191/500 Iteration: 12850 Train loss: 0.267418 Train acc: 0.900000\n",
      "Epoch: 192/500 Iteration: 12900 Train loss: 0.328941 Train acc: 0.852500\n",
      "Epoch: 192/500 Iteration: 12900 Validation loss: 0.307728 Validation acc: 0.863186\n",
      "Epoch: 193/500 Iteration: 12950 Train loss: 0.296880 Train acc: 0.867500\n",
      "Epoch: 194/500 Iteration: 13000 Train loss: 0.284711 Train acc: 0.875000\n",
      "Epoch: 194/500 Iteration: 13000 Validation loss: 0.300468 Validation acc: 0.868384\n",
      "Epoch: 194/500 Iteration: 13050 Train loss: 0.299215 Train acc: 0.867500\n",
      "Epoch: 195/500 Iteration: 13100 Train loss: 0.276572 Train acc: 0.860000\n",
      "Epoch: 195/500 Iteration: 13100 Validation loss: 0.301553 Validation acc: 0.866088\n",
      "Epoch: 196/500 Iteration: 13150 Train loss: 0.316401 Train acc: 0.847500\n",
      "Epoch: 197/500 Iteration: 13200 Train loss: 0.300042 Train acc: 0.872500\n",
      "Epoch: 197/500 Iteration: 13200 Validation loss: 0.298904 Validation acc: 0.868972\n",
      "Epoch: 197/500 Iteration: 13250 Train loss: 0.304428 Train acc: 0.857500\n",
      "Epoch: 198/500 Iteration: 13300 Train loss: 0.359362 Train acc: 0.842500\n",
      "Epoch: 198/500 Iteration: 13300 Validation loss: 0.302004 Validation acc: 0.866089\n",
      "Epoch: 199/500 Iteration: 13350 Train loss: 0.356715 Train acc: 0.850000\n",
      "Epoch: 199/500 Iteration: 13400 Train loss: 0.235164 Train acc: 0.903846\n",
      "Epoch: 199/500 Iteration: 13400 Validation loss: 0.297797 Validation acc: 0.870315\n",
      "Epoch: 200/500 Iteration: 13450 Train loss: 0.282731 Train acc: 0.860000\n",
      "Epoch: 201/500 Iteration: 13500 Train loss: 0.282870 Train acc: 0.885000\n",
      "Epoch: 201/500 Iteration: 13500 Validation loss: 0.297207 Validation acc: 0.868550\n",
      "Epoch: 202/500 Iteration: 13550 Train loss: 0.265221 Train acc: 0.880000\n",
      "Epoch: 202/500 Iteration: 13600 Train loss: 0.310405 Train acc: 0.877500\n",
      "Epoch: 202/500 Iteration: 13600 Validation loss: 0.297765 Validation acc: 0.869266\n",
      "Epoch: 203/500 Iteration: 13650 Train loss: 0.351301 Train acc: 0.832500\n",
      "Epoch: 204/500 Iteration: 13700 Train loss: 0.307627 Train acc: 0.865000\n",
      "Epoch: 204/500 Iteration: 13700 Validation loss: 0.297555 Validation acc: 0.867354\n",
      "Epoch: 205/500 Iteration: 13750 Train loss: 0.268516 Train acc: 0.887500\n",
      "Epoch: 205/500 Iteration: 13800 Train loss: 0.308191 Train acc: 0.847500\n",
      "Epoch: 205/500 Iteration: 13800 Validation loss: 0.303497 Validation acc: 0.866434\n",
      "Epoch: 206/500 Iteration: 13850 Train loss: 0.238835 Train acc: 0.920000\n",
      "Epoch: 207/500 Iteration: 13900 Train loss: 0.269541 Train acc: 0.885000\n",
      "Epoch: 207/500 Iteration: 13900 Validation loss: 0.300737 Validation acc: 0.868345\n",
      "Epoch: 208/500 Iteration: 13950 Train loss: 0.307876 Train acc: 0.865000\n",
      "Epoch: 208/500 Iteration: 14000 Train loss: 0.272131 Train acc: 0.852500\n",
      "Epoch: 208/500 Iteration: 14000 Validation loss: 0.303362 Validation acc: 0.866433\n",
      "Epoch: 209/500 Iteration: 14050 Train loss: 0.282626 Train acc: 0.885000\n",
      "Epoch: 210/500 Iteration: 14100 Train loss: 0.274327 Train acc: 0.865000\n",
      "Epoch: 210/500 Iteration: 14100 Validation loss: 0.307110 Validation acc: 0.862738\n",
      "Epoch: 211/500 Iteration: 14150 Train loss: 0.342996 Train acc: 0.842500\n",
      "Epoch: 211/500 Iteration: 14200 Train loss: 0.330700 Train acc: 0.855000\n",
      "Epoch: 211/500 Iteration: 14200 Validation loss: 0.304854 Validation acc: 0.865091\n",
      "Epoch: 212/500 Iteration: 14250 Train loss: 0.277975 Train acc: 0.872500\n",
      "Epoch: 213/500 Iteration: 14300 Train loss: 0.330576 Train acc: 0.842500\n",
      "Epoch: 213/500 Iteration: 14300 Validation loss: 0.307627 Validation acc: 0.862297\n",
      "Epoch: 214/500 Iteration: 14350 Train loss: 0.269172 Train acc: 0.867500\n",
      "Epoch: 214/500 Iteration: 14400 Train loss: 0.338059 Train acc: 0.845000\n",
      "Epoch: 214/500 Iteration: 14400 Validation loss: 0.296752 Validation acc: 0.868806\n",
      "Epoch: 215/500 Iteration: 14450 Train loss: 0.293422 Train acc: 0.872500\n",
      "Epoch: 216/500 Iteration: 14500 Train loss: 0.283812 Train acc: 0.860000\n",
      "Epoch: 216/500 Iteration: 14500 Validation loss: 0.301881 Validation acc: 0.867150\n",
      "Epoch: 217/500 Iteration: 14550 Train loss: 0.274922 Train acc: 0.865000\n",
      "Epoch: 217/500 Iteration: 14600 Train loss: 0.259476 Train acc: 0.890000\n",
      "Epoch: 217/500 Iteration: 14600 Validation loss: 0.294071 Validation acc: 0.872354\n",
      "Epoch: 218/500 Iteration: 14650 Train loss: 0.277340 Train acc: 0.865000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 219/500 Iteration: 14700 Train loss: 0.274151 Train acc: 0.880000\n",
      "Epoch: 219/500 Iteration: 14700 Validation loss: 0.294834 Validation acc: 0.870129\n",
      "Epoch: 220/500 Iteration: 14750 Train loss: 0.292371 Train acc: 0.865000\n",
      "Epoch: 220/500 Iteration: 14800 Train loss: 0.323831 Train acc: 0.870000\n",
      "Epoch: 220/500 Iteration: 14800 Validation loss: 0.294728 Validation acc: 0.870864\n",
      "Epoch: 221/500 Iteration: 14850 Train loss: 0.286046 Train acc: 0.872500\n",
      "Epoch: 222/500 Iteration: 14900 Train loss: 0.301408 Train acc: 0.867500\n",
      "Epoch: 222/500 Iteration: 14900 Validation loss: 0.293182 Validation acc: 0.871600\n",
      "Epoch: 223/500 Iteration: 14950 Train loss: 0.318007 Train acc: 0.865000\n",
      "Epoch: 223/500 Iteration: 15000 Train loss: 0.342587 Train acc: 0.845000\n",
      "Epoch: 223/500 Iteration: 15000 Validation loss: 0.296098 Validation acc: 0.869727\n",
      "Epoch: 224/500 Iteration: 15050 Train loss: 0.301069 Train acc: 0.855000\n",
      "Epoch: 225/500 Iteration: 15100 Train loss: 0.346986 Train acc: 0.827500\n",
      "Epoch: 225/500 Iteration: 15100 Validation loss: 0.293880 Validation acc: 0.871619\n",
      "Epoch: 226/500 Iteration: 15150 Train loss: 0.281181 Train acc: 0.877500\n",
      "Epoch: 226/500 Iteration: 15200 Train loss: 0.245976 Train acc: 0.900000\n",
      "Epoch: 226/500 Iteration: 15200 Validation loss: 0.295944 Validation acc: 0.870168\n",
      "Epoch: 227/500 Iteration: 15250 Train loss: 0.341923 Train acc: 0.837500\n",
      "Epoch: 228/500 Iteration: 15300 Train loss: 0.308127 Train acc: 0.855000\n",
      "Epoch: 228/500 Iteration: 15300 Validation loss: 0.295541 Validation acc: 0.869854\n",
      "Epoch: 229/500 Iteration: 15350 Train loss: 0.261067 Train acc: 0.902500\n",
      "Epoch: 229/500 Iteration: 15400 Train loss: 0.355324 Train acc: 0.865000\n",
      "Epoch: 229/500 Iteration: 15400 Validation loss: 0.292487 Validation acc: 0.871894\n",
      "Epoch: 230/500 Iteration: 15450 Train loss: 0.289021 Train acc: 0.872500\n",
      "Epoch: 231/500 Iteration: 15500 Train loss: 0.291076 Train acc: 0.875000\n",
      "Epoch: 231/500 Iteration: 15500 Validation loss: 0.291541 Validation acc: 0.873070\n",
      "Epoch: 232/500 Iteration: 15550 Train loss: 0.264039 Train acc: 0.887500\n",
      "Epoch: 232/500 Iteration: 15600 Train loss: 0.281459 Train acc: 0.880000\n",
      "Epoch: 232/500 Iteration: 15600 Validation loss: 0.290927 Validation acc: 0.873953\n",
      "Epoch: 233/500 Iteration: 15650 Train loss: 0.299497 Train acc: 0.862500\n",
      "Epoch: 234/500 Iteration: 15700 Train loss: 0.270489 Train acc: 0.877500\n",
      "Epoch: 234/500 Iteration: 15700 Validation loss: 0.290735 Validation acc: 0.872923\n",
      "Epoch: 235/500 Iteration: 15750 Train loss: 0.318195 Train acc: 0.847500\n",
      "Epoch: 235/500 Iteration: 15800 Train loss: 0.348161 Train acc: 0.840000\n",
      "Epoch: 235/500 Iteration: 15800 Validation loss: 0.293744 Validation acc: 0.870845\n",
      "Epoch: 236/500 Iteration: 15850 Train loss: 0.324190 Train acc: 0.865000\n",
      "Epoch: 237/500 Iteration: 15900 Train loss: 0.253763 Train acc: 0.890000\n",
      "Epoch: 237/500 Iteration: 15900 Validation loss: 0.289581 Validation acc: 0.873070\n",
      "Epoch: 238/500 Iteration: 15950 Train loss: 0.290653 Train acc: 0.880000\n",
      "Epoch: 238/500 Iteration: 16000 Train loss: 0.285337 Train acc: 0.877500\n",
      "Epoch: 238/500 Iteration: 16000 Validation loss: 0.298863 Validation acc: 0.868620\n",
      "Epoch: 239/500 Iteration: 16050 Train loss: 0.275994 Train acc: 0.877500\n",
      "Epoch: 240/500 Iteration: 16100 Train loss: 0.300629 Train acc: 0.860000\n",
      "Epoch: 240/500 Iteration: 16100 Validation loss: 0.289111 Validation acc: 0.873492\n",
      "Epoch: 241/500 Iteration: 16150 Train loss: 0.290751 Train acc: 0.867500\n",
      "Epoch: 241/500 Iteration: 16200 Train loss: 0.268153 Train acc: 0.887500\n",
      "Epoch: 241/500 Iteration: 16200 Validation loss: 0.300421 Validation acc: 0.867424\n",
      "Epoch: 242/500 Iteration: 16250 Train loss: 0.321073 Train acc: 0.852500\n",
      "Epoch: 243/500 Iteration: 16300 Train loss: 0.282325 Train acc: 0.870000\n",
      "Epoch: 243/500 Iteration: 16300 Validation loss: 0.289414 Validation acc: 0.871894\n",
      "Epoch: 244/500 Iteration: 16350 Train loss: 0.271344 Train acc: 0.875000\n",
      "Epoch: 244/500 Iteration: 16400 Train loss: 0.280716 Train acc: 0.875000\n",
      "Epoch: 244/500 Iteration: 16400 Validation loss: 0.292037 Validation acc: 0.872022\n",
      "Epoch: 245/500 Iteration: 16450 Train loss: 0.259128 Train acc: 0.890000\n",
      "Epoch: 246/500 Iteration: 16500 Train loss: 0.320789 Train acc: 0.855000\n",
      "Epoch: 246/500 Iteration: 16500 Validation loss: 0.288091 Validation acc: 0.874502\n",
      "Epoch: 247/500 Iteration: 16550 Train loss: 0.297861 Train acc: 0.860000\n",
      "Epoch: 247/500 Iteration: 16600 Train loss: 0.277353 Train acc: 0.882500\n",
      "Epoch: 247/500 Iteration: 16600 Validation loss: 0.289979 Validation acc: 0.873198\n",
      "Epoch: 248/500 Iteration: 16650 Train loss: 0.347478 Train acc: 0.842500\n",
      "Epoch: 249/500 Iteration: 16700 Train loss: 0.329192 Train acc: 0.860000\n",
      "Epoch: 249/500 Iteration: 16700 Validation loss: 0.288211 Validation acc: 0.873326\n",
      "Epoch: 249/500 Iteration: 16750 Train loss: 0.233687 Train acc: 0.884615\n",
      "Epoch: 250/500 Iteration: 16800 Train loss: 0.246950 Train acc: 0.880000\n",
      "Epoch: 250/500 Iteration: 16800 Validation loss: 0.287646 Validation acc: 0.875110\n",
      "Epoch: 251/500 Iteration: 16850 Train loss: 0.256269 Train acc: 0.887500\n",
      "Epoch: 252/500 Iteration: 16900 Train loss: 0.258019 Train acc: 0.890000\n",
      "Epoch: 252/500 Iteration: 16900 Validation loss: 0.287149 Validation acc: 0.874816\n",
      "Epoch: 252/500 Iteration: 16950 Train loss: 0.297411 Train acc: 0.877500\n",
      "Epoch: 253/500 Iteration: 17000 Train loss: 0.332207 Train acc: 0.847500\n",
      "Epoch: 253/500 Iteration: 17000 Validation loss: 0.290481 Validation acc: 0.872227\n",
      "Epoch: 254/500 Iteration: 17050 Train loss: 0.302464 Train acc: 0.870000\n",
      "Epoch: 255/500 Iteration: 17100 Train loss: 0.264028 Train acc: 0.885000\n",
      "Epoch: 255/500 Iteration: 17100 Validation loss: 0.287216 Validation acc: 0.874228\n",
      "Epoch: 255/500 Iteration: 17150 Train loss: 0.279787 Train acc: 0.855000\n",
      "Epoch: 256/500 Iteration: 17200 Train loss: 0.218377 Train acc: 0.927500\n",
      "Epoch: 256/500 Iteration: 17200 Validation loss: 0.297080 Validation acc: 0.869656\n",
      "Epoch: 257/500 Iteration: 17250 Train loss: 0.264701 Train acc: 0.885000\n",
      "Epoch: 258/500 Iteration: 17300 Train loss: 0.294111 Train acc: 0.860000\n",
      "Epoch: 258/500 Iteration: 17300 Validation loss: 0.286424 Validation acc: 0.875404\n",
      "Epoch: 258/500 Iteration: 17350 Train loss: 0.279089 Train acc: 0.857500\n",
      "Epoch: 259/500 Iteration: 17400 Train loss: 0.247255 Train acc: 0.877500\n",
      "Epoch: 259/500 Iteration: 17400 Validation loss: 0.296025 Validation acc: 0.869362\n",
      "Epoch: 260/500 Iteration: 17450 Train loss: 0.263268 Train acc: 0.872500\n",
      "Epoch: 261/500 Iteration: 17500 Train loss: 0.336159 Train acc: 0.827500\n",
      "Epoch: 261/500 Iteration: 17500 Validation loss: 0.285760 Validation acc: 0.876286\n",
      "Epoch: 261/500 Iteration: 17550 Train loss: 0.315273 Train acc: 0.870000\n",
      "Epoch: 262/500 Iteration: 17600 Train loss: 0.271701 Train acc: 0.855000\n",
      "Epoch: 262/500 Iteration: 17600 Validation loss: 0.290883 Validation acc: 0.871236\n",
      "Epoch: 263/500 Iteration: 17650 Train loss: 0.315330 Train acc: 0.862500\n",
      "Epoch: 264/500 Iteration: 17700 Train loss: 0.240597 Train acc: 0.892500\n",
      "Epoch: 264/500 Iteration: 17700 Validation loss: 0.287436 Validation acc: 0.873384\n",
      "Epoch: 264/500 Iteration: 17750 Train loss: 0.317404 Train acc: 0.850000\n",
      "Epoch: 265/500 Iteration: 17800 Train loss: 0.275942 Train acc: 0.870000\n",
      "Epoch: 265/500 Iteration: 17800 Validation loss: 0.286143 Validation acc: 0.873933\n",
      "Epoch: 266/500 Iteration: 17850 Train loss: 0.276200 Train acc: 0.867500\n",
      "Epoch: 267/500 Iteration: 17900 Train loss: 0.260863 Train acc: 0.887500\n",
      "Epoch: 267/500 Iteration: 17900 Validation loss: 0.284842 Validation acc: 0.876414\n",
      "Epoch: 267/500 Iteration: 17950 Train loss: 0.230570 Train acc: 0.907500\n",
      "Epoch: 268/500 Iteration: 18000 Train loss: 0.262617 Train acc: 0.862500\n",
      "Epoch: 268/500 Iteration: 18000 Validation loss: 0.284800 Validation acc: 0.877022\n",
      "Epoch: 269/500 Iteration: 18050 Train loss: 0.286496 Train acc: 0.857500\n",
      "Epoch: 270/500 Iteration: 18100 Train loss: 0.287882 Train acc: 0.880000\n",
      "Epoch: 270/500 Iteration: 18100 Validation loss: 0.284023 Validation acc: 0.877277\n",
      "Epoch: 270/500 Iteration: 18150 Train loss: 0.323416 Train acc: 0.857500\n",
      "Epoch: 271/500 Iteration: 18200 Train loss: 0.272095 Train acc: 0.887500\n",
      "Epoch: 271/500 Iteration: 18200 Validation loss: 0.286638 Validation acc: 0.874375\n",
      "Epoch: 272/500 Iteration: 18250 Train loss: 0.292855 Train acc: 0.870000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 273/500 Iteration: 18300 Train loss: 0.316044 Train acc: 0.852500\n",
      "Epoch: 273/500 Iteration: 18300 Validation loss: 0.283738 Validation acc: 0.878051\n",
      "Epoch: 273/500 Iteration: 18350 Train loss: 0.326334 Train acc: 0.850000\n",
      "Epoch: 274/500 Iteration: 18400 Train loss: 0.305273 Train acc: 0.840000\n",
      "Epoch: 274/500 Iteration: 18400 Validation loss: 0.292874 Validation acc: 0.872297\n",
      "Epoch: 275/500 Iteration: 18450 Train loss: 0.323028 Train acc: 0.857500\n",
      "Epoch: 276/500 Iteration: 18500 Train loss: 0.279744 Train acc: 0.890000\n",
      "Epoch: 276/500 Iteration: 18500 Validation loss: 0.283467 Validation acc: 0.877022\n",
      "Epoch: 276/500 Iteration: 18550 Train loss: 0.255269 Train acc: 0.882500\n",
      "Epoch: 277/500 Iteration: 18600 Train loss: 0.339008 Train acc: 0.842500\n",
      "Epoch: 277/500 Iteration: 18600 Validation loss: 0.303240 Validation acc: 0.865660\n",
      "Epoch: 278/500 Iteration: 18650 Train loss: 0.288980 Train acc: 0.855000\n",
      "Epoch: 279/500 Iteration: 18700 Train loss: 0.239909 Train acc: 0.902500\n",
      "Epoch: 279/500 Iteration: 18700 Validation loss: 0.285433 Validation acc: 0.876248\n",
      "Epoch: 279/500 Iteration: 18750 Train loss: 0.339123 Train acc: 0.860000\n",
      "Epoch: 280/500 Iteration: 18800 Train loss: 0.290600 Train acc: 0.882500\n",
      "Epoch: 280/500 Iteration: 18800 Validation loss: 0.299899 Validation acc: 0.867719\n",
      "Epoch: 281/500 Iteration: 18850 Train loss: 0.276746 Train acc: 0.875000\n",
      "Epoch: 282/500 Iteration: 18900 Train loss: 0.261382 Train acc: 0.885000\n",
      "Epoch: 282/500 Iteration: 18900 Validation loss: 0.285157 Validation acc: 0.876267\n",
      "Epoch: 282/500 Iteration: 18950 Train loss: 0.266522 Train acc: 0.892500\n",
      "Epoch: 283/500 Iteration: 19000 Train loss: 0.309646 Train acc: 0.845000\n",
      "Epoch: 283/500 Iteration: 19000 Validation loss: 0.283704 Validation acc: 0.876875\n",
      "Epoch: 284/500 Iteration: 19050 Train loss: 0.256130 Train acc: 0.867500\n",
      "Epoch: 285/500 Iteration: 19100 Train loss: 0.302012 Train acc: 0.855000\n",
      "Epoch: 285/500 Iteration: 19100 Validation loss: 0.282236 Validation acc: 0.878492\n",
      "Epoch: 285/500 Iteration: 19150 Train loss: 0.326511 Train acc: 0.857500\n",
      "Epoch: 286/500 Iteration: 19200 Train loss: 0.320247 Train acc: 0.867500\n",
      "Epoch: 286/500 Iteration: 19200 Validation loss: 0.281704 Validation acc: 0.877719\n",
      "Epoch: 287/500 Iteration: 19250 Train loss: 0.242553 Train acc: 0.900000\n",
      "Epoch: 288/500 Iteration: 19300 Train loss: 0.277129 Train acc: 0.880000\n",
      "Epoch: 288/500 Iteration: 19300 Validation loss: 0.281641 Validation acc: 0.878933\n",
      "Epoch: 288/500 Iteration: 19350 Train loss: 0.286443 Train acc: 0.880000\n",
      "Epoch: 289/500 Iteration: 19400 Train loss: 0.248613 Train acc: 0.905000\n",
      "Epoch: 289/500 Iteration: 19400 Validation loss: 0.284906 Validation acc: 0.875884\n",
      "Epoch: 290/500 Iteration: 19450 Train loss: 0.294712 Train acc: 0.872500\n",
      "Epoch: 291/500 Iteration: 19500 Train loss: 0.284300 Train acc: 0.867500\n",
      "Epoch: 291/500 Iteration: 19500 Validation loss: 0.281514 Validation acc: 0.878748\n",
      "Epoch: 291/500 Iteration: 19550 Train loss: 0.247055 Train acc: 0.905000\n",
      "Epoch: 292/500 Iteration: 19600 Train loss: 0.321510 Train acc: 0.860000\n",
      "Epoch: 292/500 Iteration: 19600 Validation loss: 0.286935 Validation acc: 0.874305\n",
      "Epoch: 293/500 Iteration: 19650 Train loss: 0.274129 Train acc: 0.860000\n",
      "Epoch: 294/500 Iteration: 19700 Train loss: 0.242266 Train acc: 0.902500\n",
      "Epoch: 294/500 Iteration: 19700 Validation loss: 0.282180 Validation acc: 0.879061\n",
      "Epoch: 294/500 Iteration: 19750 Train loss: 0.285747 Train acc: 0.882500\n",
      "Epoch: 295/500 Iteration: 19800 Train loss: 0.269797 Train acc: 0.865000\n",
      "Epoch: 295/500 Iteration: 19800 Validation loss: 0.291668 Validation acc: 0.872559\n",
      "Epoch: 296/500 Iteration: 19850 Train loss: 0.290115 Train acc: 0.847500\n",
      "Epoch: 297/500 Iteration: 19900 Train loss: 0.291298 Train acc: 0.877500\n",
      "Epoch: 297/500 Iteration: 19900 Validation loss: 0.283688 Validation acc: 0.876913\n",
      "Epoch: 297/500 Iteration: 19950 Train loss: 0.275369 Train acc: 0.877500\n",
      "Epoch: 298/500 Iteration: 20000 Train loss: 0.352998 Train acc: 0.827500\n",
      "Epoch: 298/500 Iteration: 20000 Validation loss: 0.282452 Validation acc: 0.877354\n",
      "Epoch: 299/500 Iteration: 20050 Train loss: 0.321572 Train acc: 0.875000\n",
      "Epoch: 299/500 Iteration: 20100 Train loss: 0.197379 Train acc: 0.942308\n",
      "Epoch: 299/500 Iteration: 20100 Validation loss: 0.282551 Validation acc: 0.878384\n",
      "Epoch: 300/500 Iteration: 20150 Train loss: 0.233344 Train acc: 0.910000\n",
      "Epoch: 301/500 Iteration: 20200 Train loss: 0.268087 Train acc: 0.895000\n",
      "Epoch: 301/500 Iteration: 20200 Validation loss: 0.279430 Validation acc: 0.880071\n",
      "Epoch: 302/500 Iteration: 20250 Train loss: 0.236038 Train acc: 0.907500\n",
      "Epoch: 302/500 Iteration: 20300 Train loss: 0.291813 Train acc: 0.872500\n",
      "Epoch: 302/500 Iteration: 20300 Validation loss: 0.279285 Validation acc: 0.881855\n",
      "Epoch: 303/500 Iteration: 20350 Train loss: 0.299537 Train acc: 0.872500\n",
      "Epoch: 304/500 Iteration: 20400 Train loss: 0.283802 Train acc: 0.875000\n",
      "Epoch: 304/500 Iteration: 20400 Validation loss: 0.279042 Validation acc: 0.881561\n",
      "Epoch: 305/500 Iteration: 20450 Train loss: 0.240104 Train acc: 0.892500\n",
      "Epoch: 305/500 Iteration: 20500 Train loss: 0.281098 Train acc: 0.872500\n",
      "Epoch: 305/500 Iteration: 20500 Validation loss: 0.285652 Validation acc: 0.877277\n",
      "Epoch: 306/500 Iteration: 20550 Train loss: 0.213040 Train acc: 0.922500\n",
      "Epoch: 307/500 Iteration: 20600 Train loss: 0.249704 Train acc: 0.897500\n",
      "Epoch: 307/500 Iteration: 20600 Validation loss: 0.280329 Validation acc: 0.878473\n",
      "Epoch: 308/500 Iteration: 20650 Train loss: 0.282050 Train acc: 0.855000\n",
      "Epoch: 308/500 Iteration: 20700 Train loss: 0.263453 Train acc: 0.867500\n",
      "Epoch: 308/500 Iteration: 20700 Validation loss: 0.290998 Validation acc: 0.873786\n",
      "Epoch: 309/500 Iteration: 20750 Train loss: 0.239961 Train acc: 0.902500\n",
      "Epoch: 310/500 Iteration: 20800 Train loss: 0.268967 Train acc: 0.877500\n",
      "Epoch: 310/500 Iteration: 20800 Validation loss: 0.294663 Validation acc: 0.870257\n",
      "Epoch: 311/500 Iteration: 20850 Train loss: 0.331618 Train acc: 0.850000\n",
      "Epoch: 311/500 Iteration: 20900 Train loss: 0.297139 Train acc: 0.867500\n",
      "Epoch: 311/500 Iteration: 20900 Validation loss: 0.289715 Validation acc: 0.874816\n",
      "Epoch: 312/500 Iteration: 20950 Train loss: 0.247198 Train acc: 0.907500\n",
      "Epoch: 313/500 Iteration: 21000 Train loss: 0.293870 Train acc: 0.870000\n",
      "Epoch: 313/500 Iteration: 21000 Validation loss: 0.291595 Validation acc: 0.872316\n",
      "Epoch: 314/500 Iteration: 21050 Train loss: 0.243920 Train acc: 0.897500\n",
      "Epoch: 314/500 Iteration: 21100 Train loss: 0.296796 Train acc: 0.862500\n",
      "Epoch: 314/500 Iteration: 21100 Validation loss: 0.279619 Validation acc: 0.879483\n",
      "Epoch: 315/500 Iteration: 21150 Train loss: 0.268936 Train acc: 0.867500\n",
      "Epoch: 316/500 Iteration: 21200 Train loss: 0.264692 Train acc: 0.865000\n",
      "Epoch: 316/500 Iteration: 21200 Validation loss: 0.281191 Validation acc: 0.877150\n",
      "Epoch: 317/500 Iteration: 21250 Train loss: 0.254904 Train acc: 0.877500\n",
      "Epoch: 317/500 Iteration: 21300 Train loss: 0.224829 Train acc: 0.902500\n",
      "Epoch: 317/500 Iteration: 21300 Validation loss: 0.278275 Validation acc: 0.881120\n",
      "Epoch: 318/500 Iteration: 21350 Train loss: 0.262430 Train acc: 0.885000\n",
      "Epoch: 319/500 Iteration: 21400 Train loss: 0.266404 Train acc: 0.875000\n",
      "Epoch: 319/500 Iteration: 21400 Validation loss: 0.277140 Validation acc: 0.882463\n",
      "Epoch: 320/500 Iteration: 21450 Train loss: 0.268317 Train acc: 0.907500\n",
      "Epoch: 320/500 Iteration: 21500 Train loss: 0.309402 Train acc: 0.875000\n",
      "Epoch: 320/500 Iteration: 21500 Validation loss: 0.277678 Validation acc: 0.880845\n",
      "Epoch: 321/500 Iteration: 21550 Train loss: 0.272364 Train acc: 0.882500\n",
      "Epoch: 322/500 Iteration: 21600 Train loss: 0.288833 Train acc: 0.870000\n",
      "Epoch: 322/500 Iteration: 21600 Validation loss: 0.276651 Validation acc: 0.881120\n",
      "Epoch: 323/500 Iteration: 21650 Train loss: 0.307010 Train acc: 0.865000\n",
      "Epoch: 323/500 Iteration: 21700 Train loss: 0.316102 Train acc: 0.860000\n",
      "Epoch: 323/500 Iteration: 21700 Validation loss: 0.282524 Validation acc: 0.876932\n",
      "Epoch: 324/500 Iteration: 21750 Train loss: 0.283995 Train acc: 0.870000\n",
      "Epoch: 325/500 Iteration: 21800 Train loss: 0.319129 Train acc: 0.855000\n",
      "Epoch: 325/500 Iteration: 21800 Validation loss: 0.280352 Validation acc: 0.878237\n",
      "Epoch: 326/500 Iteration: 21850 Train loss: 0.266303 Train acc: 0.902500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 326/500 Iteration: 21900 Train loss: 0.223260 Train acc: 0.900000\n",
      "Epoch: 326/500 Iteration: 21900 Validation loss: 0.280862 Validation acc: 0.877668\n",
      "Epoch: 327/500 Iteration: 21950 Train loss: 0.321011 Train acc: 0.857500\n",
      "Epoch: 328/500 Iteration: 22000 Train loss: 0.274407 Train acc: 0.870000\n",
      "Epoch: 328/500 Iteration: 22000 Validation loss: 0.280233 Validation acc: 0.878953\n",
      "Epoch: 329/500 Iteration: 22050 Train loss: 0.244028 Train acc: 0.887500\n",
      "Epoch: 329/500 Iteration: 22100 Train loss: 0.332862 Train acc: 0.867500\n",
      "Epoch: 329/500 Iteration: 22100 Validation loss: 0.276711 Validation acc: 0.881306\n",
      "Epoch: 330/500 Iteration: 22150 Train loss: 0.280104 Train acc: 0.870000\n",
      "Epoch: 331/500 Iteration: 22200 Train loss: 0.290826 Train acc: 0.867500\n",
      "Epoch: 331/500 Iteration: 22200 Validation loss: 0.277918 Validation acc: 0.879100\n",
      "Epoch: 332/500 Iteration: 22250 Train loss: 0.239660 Train acc: 0.885000\n",
      "Epoch: 332/500 Iteration: 22300 Train loss: 0.263489 Train acc: 0.887500\n",
      "Epoch: 332/500 Iteration: 22300 Validation loss: 0.275551 Validation acc: 0.884170\n",
      "Epoch: 333/500 Iteration: 22350 Train loss: 0.279626 Train acc: 0.865000\n",
      "Epoch: 334/500 Iteration: 22400 Train loss: 0.245589 Train acc: 0.882500\n",
      "Epoch: 334/500 Iteration: 22400 Validation loss: 0.275705 Validation acc: 0.881728\n",
      "Epoch: 335/500 Iteration: 22450 Train loss: 0.287051 Train acc: 0.870000\n",
      "Epoch: 335/500 Iteration: 22500 Train loss: 0.323854 Train acc: 0.850000\n",
      "Epoch: 335/500 Iteration: 22500 Validation loss: 0.276452 Validation acc: 0.879944\n",
      "Epoch: 336/500 Iteration: 22550 Train loss: 0.291167 Train acc: 0.865000\n",
      "Epoch: 337/500 Iteration: 22600 Train loss: 0.243304 Train acc: 0.892500\n",
      "Epoch: 337/500 Iteration: 22600 Validation loss: 0.275015 Validation acc: 0.883473\n",
      "Epoch: 338/500 Iteration: 22650 Train loss: 0.256458 Train acc: 0.875000\n",
      "Epoch: 338/500 Iteration: 22700 Train loss: 0.275817 Train acc: 0.890000\n",
      "Epoch: 338/500 Iteration: 22700 Validation loss: 0.283029 Validation acc: 0.878326\n",
      "Epoch: 339/500 Iteration: 22750 Train loss: 0.256620 Train acc: 0.895000\n",
      "Epoch: 340/500 Iteration: 22800 Train loss: 0.280173 Train acc: 0.892500\n",
      "Epoch: 340/500 Iteration: 22800 Validation loss: 0.274069 Validation acc: 0.883307\n",
      "Epoch: 341/500 Iteration: 22850 Train loss: 0.289451 Train acc: 0.862500\n",
      "Epoch: 341/500 Iteration: 22900 Train loss: 0.229357 Train acc: 0.907500\n",
      "Epoch: 341/500 Iteration: 22900 Validation loss: 0.279487 Validation acc: 0.880219\n",
      "Epoch: 342/500 Iteration: 22950 Train loss: 0.290043 Train acc: 0.862500\n",
      "Epoch: 343/500 Iteration: 23000 Train loss: 0.262174 Train acc: 0.865000\n",
      "Epoch: 343/500 Iteration: 23000 Validation loss: 0.275236 Validation acc: 0.880992\n",
      "Epoch: 344/500 Iteration: 23050 Train loss: 0.265419 Train acc: 0.882500\n",
      "Epoch: 344/500 Iteration: 23100 Train loss: 0.254120 Train acc: 0.902500\n",
      "Epoch: 344/500 Iteration: 23100 Validation loss: 0.279376 Validation acc: 0.878639\n",
      "Epoch: 345/500 Iteration: 23150 Train loss: 0.259108 Train acc: 0.877500\n",
      "Epoch: 346/500 Iteration: 23200 Train loss: 0.273498 Train acc: 0.887500\n",
      "Epoch: 346/500 Iteration: 23200 Validation loss: 0.273714 Validation acc: 0.883140\n",
      "Epoch: 347/500 Iteration: 23250 Train loss: 0.288505 Train acc: 0.872500\n",
      "Epoch: 347/500 Iteration: 23300 Train loss: 0.267823 Train acc: 0.885000\n",
      "Epoch: 347/500 Iteration: 23300 Validation loss: 0.276918 Validation acc: 0.880219\n",
      "Epoch: 348/500 Iteration: 23350 Train loss: 0.320573 Train acc: 0.850000\n",
      "Epoch: 349/500 Iteration: 23400 Train loss: 0.294912 Train acc: 0.892500\n",
      "Epoch: 349/500 Iteration: 23400 Validation loss: 0.273037 Validation acc: 0.883914\n",
      "Epoch: 349/500 Iteration: 23450 Train loss: 0.145024 Train acc: 1.000000\n",
      "Epoch: 350/500 Iteration: 23500 Train loss: 0.239252 Train acc: 0.890000\n",
      "Epoch: 350/500 Iteration: 23500 Validation loss: 0.273333 Validation acc: 0.884464\n",
      "Epoch: 351/500 Iteration: 23550 Train loss: 0.242246 Train acc: 0.910000\n",
      "Epoch: 352/500 Iteration: 23600 Train loss: 0.223140 Train acc: 0.905000\n",
      "Epoch: 352/500 Iteration: 23600 Validation loss: 0.273417 Validation acc: 0.883140\n",
      "Epoch: 352/500 Iteration: 23650 Train loss: 0.270563 Train acc: 0.880000\n",
      "Epoch: 353/500 Iteration: 23700 Train loss: 0.291265 Train acc: 0.882500\n",
      "Epoch: 353/500 Iteration: 23700 Validation loss: 0.275128 Validation acc: 0.881894\n",
      "Epoch: 354/500 Iteration: 23750 Train loss: 0.275377 Train acc: 0.882500\n",
      "Epoch: 355/500 Iteration: 23800 Train loss: 0.247551 Train acc: 0.897500\n",
      "Epoch: 355/500 Iteration: 23800 Validation loss: 0.273741 Validation acc: 0.882572\n",
      "Epoch: 355/500 Iteration: 23850 Train loss: 0.266089 Train acc: 0.867500\n",
      "Epoch: 356/500 Iteration: 23900 Train loss: 0.203567 Train acc: 0.925000\n",
      "Epoch: 356/500 Iteration: 23900 Validation loss: 0.277361 Validation acc: 0.880570\n",
      "Epoch: 357/500 Iteration: 23950 Train loss: 0.256705 Train acc: 0.900000\n",
      "Epoch: 358/500 Iteration: 24000 Train loss: 0.264608 Train acc: 0.885000\n",
      "Epoch: 358/500 Iteration: 24000 Validation loss: 0.273598 Validation acc: 0.880493\n",
      "Epoch: 358/500 Iteration: 24050 Train loss: 0.261137 Train acc: 0.870000\n",
      "Epoch: 359/500 Iteration: 24100 Train loss: 0.243822 Train acc: 0.897500\n",
      "Epoch: 359/500 Iteration: 24100 Validation loss: 0.282047 Validation acc: 0.876805\n",
      "Epoch: 360/500 Iteration: 24150 Train loss: 0.254545 Train acc: 0.890000\n",
      "Epoch: 361/500 Iteration: 24200 Train loss: 0.291619 Train acc: 0.865000\n",
      "Epoch: 361/500 Iteration: 24200 Validation loss: 0.272667 Validation acc: 0.882699\n",
      "Epoch: 361/500 Iteration: 24250 Train loss: 0.286387 Train acc: 0.877500\n",
      "Epoch: 362/500 Iteration: 24300 Train loss: 0.253279 Train acc: 0.880000\n",
      "Epoch: 362/500 Iteration: 24300 Validation loss: 0.276292 Validation acc: 0.879688\n",
      "Epoch: 363/500 Iteration: 24350 Train loss: 0.277708 Train acc: 0.882500\n",
      "Epoch: 364/500 Iteration: 24400 Train loss: 0.236698 Train acc: 0.902500\n",
      "Epoch: 364/500 Iteration: 24400 Validation loss: 0.272016 Validation acc: 0.882719\n",
      "Epoch: 364/500 Iteration: 24450 Train loss: 0.302774 Train acc: 0.860000\n",
      "Epoch: 365/500 Iteration: 24500 Train loss: 0.244580 Train acc: 0.905000\n",
      "Epoch: 365/500 Iteration: 24500 Validation loss: 0.275443 Validation acc: 0.881011\n",
      "Epoch: 366/500 Iteration: 24550 Train loss: 0.263588 Train acc: 0.877500\n",
      "Epoch: 367/500 Iteration: 24600 Train loss: 0.256058 Train acc: 0.877500\n",
      "Epoch: 367/500 Iteration: 24600 Validation loss: 0.270893 Validation acc: 0.885238\n",
      "Epoch: 367/500 Iteration: 24650 Train loss: 0.219688 Train acc: 0.902500\n",
      "Epoch: 368/500 Iteration: 24700 Train loss: 0.247356 Train acc: 0.882500\n",
      "Epoch: 368/500 Iteration: 24700 Validation loss: 0.273264 Validation acc: 0.882629\n",
      "Epoch: 369/500 Iteration: 24750 Train loss: 0.254092 Train acc: 0.885000\n",
      "Epoch: 370/500 Iteration: 24800 Train loss: 0.246343 Train acc: 0.905000\n",
      "Epoch: 370/500 Iteration: 24800 Validation loss: 0.270917 Validation acc: 0.884669\n",
      "Epoch: 370/500 Iteration: 24850 Train loss: 0.305800 Train acc: 0.872500\n",
      "Epoch: 371/500 Iteration: 24900 Train loss: 0.256886 Train acc: 0.892500\n",
      "Epoch: 371/500 Iteration: 24900 Validation loss: 0.270572 Validation acc: 0.885199\n",
      "Epoch: 372/500 Iteration: 24950 Train loss: 0.273191 Train acc: 0.892500\n",
      "Epoch: 373/500 Iteration: 25000 Train loss: 0.270818 Train acc: 0.892500\n",
      "Epoch: 373/500 Iteration: 25000 Validation loss: 0.272992 Validation acc: 0.882482\n",
      "Epoch: 373/500 Iteration: 25050 Train loss: 0.295854 Train acc: 0.870000\n",
      "Epoch: 374/500 Iteration: 25100 Train loss: 0.272027 Train acc: 0.877500\n",
      "Epoch: 374/500 Iteration: 25100 Validation loss: 0.277810 Validation acc: 0.878492\n",
      "Epoch: 375/500 Iteration: 25150 Train loss: 0.308532 Train acc: 0.855000\n",
      "Epoch: 376/500 Iteration: 25200 Train loss: 0.263547 Train acc: 0.877500\n",
      "Epoch: 376/500 Iteration: 25200 Validation loss: 0.269806 Validation acc: 0.885385\n",
      "Epoch: 376/500 Iteration: 25250 Train loss: 0.214815 Train acc: 0.907500\n",
      "Epoch: 377/500 Iteration: 25300 Train loss: 0.307509 Train acc: 0.860000\n",
      "Epoch: 377/500 Iteration: 25300 Validation loss: 0.286096 Validation acc: 0.874228\n",
      "Epoch: 378/500 Iteration: 25350 Train loss: 0.268513 Train acc: 0.872500\n",
      "Epoch: 379/500 Iteration: 25400 Train loss: 0.230072 Train acc: 0.900000\n",
      "Epoch: 379/500 Iteration: 25400 Validation loss: 0.269965 Validation acc: 0.887258\n",
      "Epoch: 379/500 Iteration: 25450 Train loss: 0.312821 Train acc: 0.877500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380/500 Iteration: 25500 Train loss: 0.267509 Train acc: 0.885000\n",
      "Epoch: 380/500 Iteration: 25500 Validation loss: 0.291515 Validation acc: 0.870168\n",
      "Epoch: 381/500 Iteration: 25550 Train loss: 0.262558 Train acc: 0.882500\n",
      "Epoch: 382/500 Iteration: 25600 Train loss: 0.233439 Train acc: 0.892500\n",
      "Epoch: 382/500 Iteration: 25600 Validation loss: 0.270325 Validation acc: 0.884886\n",
      "Epoch: 382/500 Iteration: 25650 Train loss: 0.239573 Train acc: 0.902500\n",
      "Epoch: 383/500 Iteration: 25700 Train loss: 0.265684 Train acc: 0.880000\n",
      "Epoch: 383/500 Iteration: 25700 Validation loss: 0.274646 Validation acc: 0.880532\n",
      "Epoch: 384/500 Iteration: 25750 Train loss: 0.238753 Train acc: 0.882500\n",
      "Epoch: 385/500 Iteration: 25800 Train loss: 0.283058 Train acc: 0.877500\n",
      "Epoch: 385/500 Iteration: 25800 Validation loss: 0.271645 Validation acc: 0.881983\n",
      "Epoch: 385/500 Iteration: 25850 Train loss: 0.306418 Train acc: 0.870000\n",
      "Epoch: 386/500 Iteration: 25900 Train loss: 0.284741 Train acc: 0.880000\n",
      "Epoch: 386/500 Iteration: 25900 Validation loss: 0.268947 Validation acc: 0.886120\n",
      "Epoch: 387/500 Iteration: 25950 Train loss: 0.220197 Train acc: 0.915000\n",
      "Epoch: 388/500 Iteration: 26000 Train loss: 0.259555 Train acc: 0.872500\n",
      "Epoch: 388/500 Iteration: 26000 Validation loss: 0.270286 Validation acc: 0.884630\n",
      "Epoch: 388/500 Iteration: 26050 Train loss: 0.257059 Train acc: 0.897500\n",
      "Epoch: 389/500 Iteration: 26100 Train loss: 0.236701 Train acc: 0.897500\n",
      "Epoch: 389/500 Iteration: 26100 Validation loss: 0.269706 Validation acc: 0.885551\n",
      "Epoch: 390/500 Iteration: 26150 Train loss: 0.248860 Train acc: 0.895000\n",
      "Epoch: 391/500 Iteration: 26200 Train loss: 0.277378 Train acc: 0.880000\n",
      "Epoch: 391/500 Iteration: 26200 Validation loss: 0.268376 Validation acc: 0.886561\n",
      "Epoch: 391/500 Iteration: 26250 Train loss: 0.229150 Train acc: 0.910000\n",
      "Epoch: 392/500 Iteration: 26300 Train loss: 0.297270 Train acc: 0.875000\n",
      "Epoch: 392/500 Iteration: 26300 Validation loss: 0.276222 Validation acc: 0.879854\n",
      "Epoch: 393/500 Iteration: 26350 Train loss: 0.256242 Train acc: 0.867500\n",
      "Epoch: 394/500 Iteration: 26400 Train loss: 0.257891 Train acc: 0.885000\n",
      "Epoch: 394/500 Iteration: 26400 Validation loss: 0.268753 Validation acc: 0.885992\n",
      "Epoch: 394/500 Iteration: 26450 Train loss: 0.245591 Train acc: 0.905000\n",
      "Epoch: 395/500 Iteration: 26500 Train loss: 0.244367 Train acc: 0.885000\n",
      "Epoch: 395/500 Iteration: 26500 Validation loss: 0.274918 Validation acc: 0.881031\n",
      "Epoch: 396/500 Iteration: 26550 Train loss: 0.264468 Train acc: 0.870000\n",
      "Epoch: 397/500 Iteration: 26600 Train loss: 0.275549 Train acc: 0.867500\n",
      "Epoch: 397/500 Iteration: 26600 Validation loss: 0.270323 Validation acc: 0.885404\n",
      "Epoch: 397/500 Iteration: 26650 Train loss: 0.254447 Train acc: 0.880000\n",
      "Epoch: 398/500 Iteration: 26700 Train loss: 0.355357 Train acc: 0.830000\n",
      "Epoch: 398/500 Iteration: 26700 Validation loss: 0.269987 Validation acc: 0.885257\n",
      "Epoch: 399/500 Iteration: 26750 Train loss: 0.289221 Train acc: 0.880000\n",
      "Epoch: 399/500 Iteration: 26800 Train loss: 0.115125 Train acc: 0.980769\n",
      "Epoch: 399/500 Iteration: 26800 Validation loss: 0.272374 Validation acc: 0.883217\n",
      "Epoch: 400/500 Iteration: 26850 Train loss: 0.227326 Train acc: 0.902500\n",
      "Epoch: 401/500 Iteration: 26900 Train loss: 0.240203 Train acc: 0.900000\n",
      "Epoch: 401/500 Iteration: 26900 Validation loss: 0.266799 Validation acc: 0.885973\n",
      "Epoch: 402/500 Iteration: 26950 Train loss: 0.239213 Train acc: 0.905000\n",
      "Epoch: 402/500 Iteration: 27000 Train loss: 0.257987 Train acc: 0.885000\n",
      "Epoch: 402/500 Iteration: 27000 Validation loss: 0.266989 Validation acc: 0.887002\n",
      "Epoch: 403/500 Iteration: 27050 Train loss: 0.288117 Train acc: 0.875000\n",
      "Epoch: 404/500 Iteration: 27100 Train loss: 0.269453 Train acc: 0.875000\n",
      "Epoch: 404/500 Iteration: 27100 Validation loss: 0.266383 Validation acc: 0.887738\n",
      "Epoch: 405/500 Iteration: 27150 Train loss: 0.235492 Train acc: 0.895000\n",
      "Epoch: 405/500 Iteration: 27200 Train loss: 0.250834 Train acc: 0.872500\n",
      "Epoch: 405/500 Iteration: 27200 Validation loss: 0.266318 Validation acc: 0.888748\n",
      "Epoch: 406/500 Iteration: 27250 Train loss: 0.196370 Train acc: 0.925000\n",
      "Epoch: 407/500 Iteration: 27300 Train loss: 0.233148 Train acc: 0.905000\n",
      "Epoch: 407/500 Iteration: 27300 Validation loss: 0.269865 Validation acc: 0.883454\n",
      "Epoch: 408/500 Iteration: 27350 Train loss: 0.270229 Train acc: 0.857500\n",
      "Epoch: 408/500 Iteration: 27400 Train loss: 0.231502 Train acc: 0.895000\n",
      "Epoch: 408/500 Iteration: 27400 Validation loss: 0.273385 Validation acc: 0.881855\n",
      "Epoch: 409/500 Iteration: 27450 Train loss: 0.227259 Train acc: 0.890000\n",
      "Epoch: 410/500 Iteration: 27500 Train loss: 0.243295 Train acc: 0.890000\n",
      "Epoch: 410/500 Iteration: 27500 Validation loss: 0.273139 Validation acc: 0.881561\n",
      "Epoch: 411/500 Iteration: 27550 Train loss: 0.293707 Train acc: 0.865000\n",
      "Epoch: 411/500 Iteration: 27600 Train loss: 0.286289 Train acc: 0.880000\n",
      "Epoch: 411/500 Iteration: 27600 Validation loss: 0.274030 Validation acc: 0.881267\n",
      "Epoch: 412/500 Iteration: 27650 Train loss: 0.243370 Train acc: 0.895000\n",
      "Epoch: 413/500 Iteration: 27700 Train loss: 0.274629 Train acc: 0.880000\n",
      "Epoch: 413/500 Iteration: 27700 Validation loss: 0.275360 Validation acc: 0.878786\n",
      "Epoch: 414/500 Iteration: 27750 Train loss: 0.230189 Train acc: 0.915000\n",
      "Epoch: 414/500 Iteration: 27800 Train loss: 0.302305 Train acc: 0.862500\n",
      "Epoch: 414/500 Iteration: 27800 Validation loss: 0.271806 Validation acc: 0.883620\n",
      "Epoch: 415/500 Iteration: 27850 Train loss: 0.241221 Train acc: 0.895000\n",
      "Epoch: 416/500 Iteration: 27900 Train loss: 0.249570 Train acc: 0.900000\n",
      "Epoch: 416/500 Iteration: 27900 Validation loss: 0.270388 Validation acc: 0.881855\n",
      "Epoch: 417/500 Iteration: 27950 Train loss: 0.235936 Train acc: 0.892500\n",
      "Epoch: 417/500 Iteration: 28000 Train loss: 0.213545 Train acc: 0.907500\n",
      "Epoch: 417/500 Iteration: 28000 Validation loss: 0.265306 Validation acc: 0.887738\n",
      "Epoch: 418/500 Iteration: 28050 Train loss: 0.237669 Train acc: 0.887500\n",
      "Epoch: 419/500 Iteration: 28100 Train loss: 0.249868 Train acc: 0.890000\n",
      "Epoch: 419/500 Iteration: 28100 Validation loss: 0.265563 Validation acc: 0.888160\n",
      "Epoch: 420/500 Iteration: 28150 Train loss: 0.261352 Train acc: 0.892500\n",
      "Epoch: 420/500 Iteration: 28200 Train loss: 0.269312 Train acc: 0.870000\n",
      "Epoch: 420/500 Iteration: 28200 Validation loss: 0.265326 Validation acc: 0.889630\n",
      "Epoch: 421/500 Iteration: 28250 Train loss: 0.249846 Train acc: 0.890000\n",
      "Epoch: 422/500 Iteration: 28300 Train loss: 0.270798 Train acc: 0.885000\n",
      "Epoch: 422/500 Iteration: 28300 Validation loss: 0.264769 Validation acc: 0.888013\n",
      "Epoch: 423/500 Iteration: 28350 Train loss: 0.293207 Train acc: 0.867500\n",
      "Epoch: 423/500 Iteration: 28400 Train loss: 0.293061 Train acc: 0.860000\n",
      "Epoch: 423/500 Iteration: 28400 Validation loss: 0.266850 Validation acc: 0.887169\n",
      "Epoch: 424/500 Iteration: 28450 Train loss: 0.259978 Train acc: 0.870000\n",
      "Epoch: 425/500 Iteration: 28500 Train loss: 0.296692 Train acc: 0.862500\n",
      "Epoch: 425/500 Iteration: 28500 Validation loss: 0.265399 Validation acc: 0.887591\n",
      "Epoch: 426/500 Iteration: 28550 Train loss: 0.255847 Train acc: 0.897500\n",
      "Epoch: 426/500 Iteration: 28600 Train loss: 0.220559 Train acc: 0.902500\n",
      "Epoch: 426/500 Iteration: 28600 Validation loss: 0.266984 Validation acc: 0.887022\n",
      "Epoch: 427/500 Iteration: 28650 Train loss: 0.277108 Train acc: 0.870000\n",
      "Epoch: 428/500 Iteration: 28700 Train loss: 0.241348 Train acc: 0.885000\n",
      "Epoch: 428/500 Iteration: 28700 Validation loss: 0.265503 Validation acc: 0.887169\n",
      "Epoch: 429/500 Iteration: 28750 Train loss: 0.219346 Train acc: 0.915000\n",
      "Epoch: 429/500 Iteration: 28800 Train loss: 0.317599 Train acc: 0.875000\n",
      "Epoch: 429/500 Iteration: 28800 Validation loss: 0.266514 Validation acc: 0.887463\n",
      "Epoch: 430/500 Iteration: 28850 Train loss: 0.258661 Train acc: 0.887500\n",
      "Epoch: 431/500 Iteration: 28900 Train loss: 0.277200 Train acc: 0.867500\n",
      "Epoch: 431/500 Iteration: 28900 Validation loss: 0.265398 Validation acc: 0.887444\n",
      "Epoch: 432/500 Iteration: 28950 Train loss: 0.214899 Train acc: 0.915000\n",
      "Epoch: 432/500 Iteration: 29000 Train loss: 0.221300 Train acc: 0.912500\n",
      "Epoch: 432/500 Iteration: 29000 Validation loss: 0.263747 Validation acc: 0.888326\n",
      "Epoch: 433/500 Iteration: 29050 Train loss: 0.254476 Train acc: 0.890000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 434/500 Iteration: 29100 Train loss: 0.222713 Train acc: 0.892500\n",
      "Epoch: 434/500 Iteration: 29100 Validation loss: 0.263975 Validation acc: 0.887591\n",
      "Epoch: 435/500 Iteration: 29150 Train loss: 0.270681 Train acc: 0.890000\n",
      "Epoch: 435/500 Iteration: 29200 Train loss: 0.304268 Train acc: 0.880000\n",
      "Epoch: 435/500 Iteration: 29200 Validation loss: 0.263594 Validation acc: 0.888345\n",
      "Epoch: 436/500 Iteration: 29250 Train loss: 0.271215 Train acc: 0.882500\n",
      "Epoch: 437/500 Iteration: 29300 Train loss: 0.205685 Train acc: 0.922500\n",
      "Epoch: 437/500 Iteration: 29300 Validation loss: 0.263575 Validation acc: 0.887591\n",
      "Epoch: 438/500 Iteration: 29350 Train loss: 0.254209 Train acc: 0.892500\n",
      "Epoch: 438/500 Iteration: 29400 Train loss: 0.249286 Train acc: 0.907500\n",
      "Epoch: 438/500 Iteration: 29400 Validation loss: 0.265013 Validation acc: 0.887719\n",
      "Epoch: 439/500 Iteration: 29450 Train loss: 0.234417 Train acc: 0.907500\n",
      "Epoch: 440/500 Iteration: 29500 Train loss: 0.270491 Train acc: 0.885000\n",
      "Epoch: 440/500 Iteration: 29500 Validation loss: 0.263167 Validation acc: 0.887591\n",
      "Epoch: 441/500 Iteration: 29550 Train loss: 0.247531 Train acc: 0.892500\n",
      "Epoch: 441/500 Iteration: 29600 Train loss: 0.206392 Train acc: 0.932500\n",
      "Epoch: 441/500 Iteration: 29600 Validation loss: 0.268167 Validation acc: 0.885071\n",
      "Epoch: 442/500 Iteration: 29650 Train loss: 0.293376 Train acc: 0.872500\n",
      "Epoch: 443/500 Iteration: 29700 Train loss: 0.238914 Train acc: 0.875000\n",
      "Epoch: 443/500 Iteration: 29700 Validation loss: 0.262775 Validation acc: 0.888933\n",
      "Epoch: 444/500 Iteration: 29750 Train loss: 0.224945 Train acc: 0.897500\n",
      "Epoch: 444/500 Iteration: 29800 Train loss: 0.243546 Train acc: 0.895000\n",
      "Epoch: 444/500 Iteration: 29800 Validation loss: 0.268843 Validation acc: 0.885091\n",
      "Epoch: 445/500 Iteration: 29850 Train loss: 0.242135 Train acc: 0.875000\n",
      "Epoch: 446/500 Iteration: 29900 Train loss: 0.268331 Train acc: 0.862500\n",
      "Epoch: 446/500 Iteration: 29900 Validation loss: 0.262781 Validation acc: 0.887316\n",
      "Epoch: 447/500 Iteration: 29950 Train loss: 0.281350 Train acc: 0.877500\n",
      "Epoch: 447/500 Iteration: 30000 Train loss: 0.245806 Train acc: 0.885000\n",
      "Epoch: 447/500 Iteration: 30000 Validation loss: 0.268800 Validation acc: 0.883601\n",
      "Epoch: 448/500 Iteration: 30050 Train loss: 0.316895 Train acc: 0.860000\n",
      "Epoch: 449/500 Iteration: 30100 Train loss: 0.273385 Train acc: 0.877500\n",
      "Epoch: 449/500 Iteration: 30100 Validation loss: 0.263186 Validation acc: 0.888473\n",
      "Epoch: 449/500 Iteration: 30150 Train loss: 0.123629 Train acc: 1.000000\n",
      "Epoch: 450/500 Iteration: 30200 Train loss: 0.213077 Train acc: 0.905000\n",
      "Epoch: 450/500 Iteration: 30200 Validation loss: 0.263556 Validation acc: 0.888179\n",
      "Epoch: 451/500 Iteration: 30250 Train loss: 0.239200 Train acc: 0.917500\n",
      "Epoch: 452/500 Iteration: 30300 Train loss: 0.205402 Train acc: 0.912500\n",
      "Epoch: 452/500 Iteration: 30300 Validation loss: 0.261928 Validation acc: 0.889650\n",
      "Epoch: 452/500 Iteration: 30350 Train loss: 0.256111 Train acc: 0.900000\n",
      "Epoch: 453/500 Iteration: 30400 Train loss: 0.261592 Train acc: 0.900000\n",
      "Epoch: 453/500 Iteration: 30400 Validation loss: 0.261885 Validation acc: 0.889522\n",
      "Epoch: 454/500 Iteration: 30450 Train loss: 0.231158 Train acc: 0.905000\n",
      "Epoch: 455/500 Iteration: 30500 Train loss: 0.212120 Train acc: 0.900000\n",
      "Epoch: 455/500 Iteration: 30500 Validation loss: 0.261797 Validation acc: 0.888620\n",
      "Epoch: 455/500 Iteration: 30550 Train loss: 0.271356 Train acc: 0.855000\n",
      "Epoch: 456/500 Iteration: 30600 Train loss: 0.189374 Train acc: 0.925000\n",
      "Epoch: 456/500 Iteration: 30600 Validation loss: 0.266424 Validation acc: 0.887463\n",
      "Epoch: 457/500 Iteration: 30650 Train loss: 0.206670 Train acc: 0.920000\n",
      "Epoch: 458/500 Iteration: 30700 Train loss: 0.258253 Train acc: 0.882500\n",
      "Epoch: 458/500 Iteration: 30700 Validation loss: 0.267153 Validation acc: 0.884483\n",
      "Epoch: 458/500 Iteration: 30750 Train loss: 0.224083 Train acc: 0.897500\n",
      "Epoch: 459/500 Iteration: 30800 Train loss: 0.225102 Train acc: 0.887500\n",
      "Epoch: 459/500 Iteration: 30800 Validation loss: 0.265133 Validation acc: 0.888326\n",
      "Epoch: 460/500 Iteration: 30850 Train loss: 0.242253 Train acc: 0.892500\n",
      "Epoch: 461/500 Iteration: 30900 Train loss: 0.281071 Train acc: 0.880000\n",
      "Epoch: 461/500 Iteration: 30900 Validation loss: 0.269608 Validation acc: 0.881581\n",
      "Epoch: 461/500 Iteration: 30950 Train loss: 0.263511 Train acc: 0.880000\n",
      "Epoch: 462/500 Iteration: 31000 Train loss: 0.226169 Train acc: 0.907500\n",
      "Epoch: 462/500 Iteration: 31000 Validation loss: 0.263848 Validation acc: 0.888620\n",
      "Epoch: 463/500 Iteration: 31050 Train loss: 0.239521 Train acc: 0.895000\n",
      "Epoch: 464/500 Iteration: 31100 Train loss: 0.218582 Train acc: 0.900000\n",
      "Epoch: 464/500 Iteration: 31100 Validation loss: 0.268046 Validation acc: 0.884170\n",
      "Epoch: 464/500 Iteration: 31150 Train loss: 0.253258 Train acc: 0.890000\n",
      "Epoch: 465/500 Iteration: 31200 Train loss: 0.246298 Train acc: 0.892500\n",
      "Epoch: 465/500 Iteration: 31200 Validation loss: 0.263368 Validation acc: 0.888767\n",
      "Epoch: 466/500 Iteration: 31250 Train loss: 0.244256 Train acc: 0.885000\n",
      "Epoch: 467/500 Iteration: 31300 Train loss: 0.235701 Train acc: 0.895000\n",
      "Epoch: 467/500 Iteration: 31300 Validation loss: 0.260759 Validation acc: 0.888326\n",
      "Epoch: 467/500 Iteration: 31350 Train loss: 0.196506 Train acc: 0.915000\n",
      "Epoch: 468/500 Iteration: 31400 Train loss: 0.230209 Train acc: 0.882500\n",
      "Epoch: 468/500 Iteration: 31400 Validation loss: 0.261857 Validation acc: 0.889208\n",
      "Epoch: 469/500 Iteration: 31450 Train loss: 0.226804 Train acc: 0.897500\n",
      "Epoch: 470/500 Iteration: 31500 Train loss: 0.260211 Train acc: 0.892500\n",
      "Epoch: 470/500 Iteration: 31500 Validation loss: 0.259978 Validation acc: 0.889502\n",
      "Epoch: 470/500 Iteration: 31550 Train loss: 0.252008 Train acc: 0.902500\n",
      "Epoch: 471/500 Iteration: 31600 Train loss: 0.250610 Train acc: 0.880000\n",
      "Epoch: 471/500 Iteration: 31600 Validation loss: 0.260247 Validation acc: 0.889669\n",
      "Epoch: 472/500 Iteration: 31650 Train loss: 0.255046 Train acc: 0.892500\n",
      "Epoch: 473/500 Iteration: 31700 Train loss: 0.269015 Train acc: 0.895000\n",
      "Epoch: 473/500 Iteration: 31700 Validation loss: 0.262706 Validation acc: 0.889502\n",
      "Epoch: 473/500 Iteration: 31750 Train loss: 0.305874 Train acc: 0.875000\n",
      "Epoch: 474/500 Iteration: 31800 Train loss: 0.236465 Train acc: 0.890000\n",
      "Epoch: 474/500 Iteration: 31800 Validation loss: 0.266263 Validation acc: 0.885660\n",
      "Epoch: 475/500 Iteration: 31850 Train loss: 0.274630 Train acc: 0.875000\n",
      "Epoch: 476/500 Iteration: 31900 Train loss: 0.243950 Train acc: 0.902500\n",
      "Epoch: 476/500 Iteration: 31900 Validation loss: 0.259450 Validation acc: 0.890532\n",
      "Epoch: 476/500 Iteration: 31950 Train loss: 0.210872 Train acc: 0.917500\n",
      "Epoch: 477/500 Iteration: 32000 Train loss: 0.309452 Train acc: 0.857500\n",
      "Epoch: 477/500 Iteration: 32000 Validation loss: 0.275624 Validation acc: 0.878953\n",
      "Epoch: 478/500 Iteration: 32050 Train loss: 0.239281 Train acc: 0.887500\n",
      "Epoch: 479/500 Iteration: 32100 Train loss: 0.226226 Train acc: 0.900000\n",
      "Epoch: 479/500 Iteration: 32100 Validation loss: 0.260559 Validation acc: 0.889355\n",
      "Epoch: 479/500 Iteration: 32150 Train loss: 0.300111 Train acc: 0.875000\n",
      "Epoch: 480/500 Iteration: 32200 Train loss: 0.244249 Train acc: 0.887500\n",
      "Epoch: 480/500 Iteration: 32200 Validation loss: 0.284895 Validation acc: 0.875884\n",
      "Epoch: 481/500 Iteration: 32250 Train loss: 0.241367 Train acc: 0.882500\n",
      "Epoch: 482/500 Iteration: 32300 Train loss: 0.223636 Train acc: 0.910000\n",
      "Epoch: 482/500 Iteration: 32300 Validation loss: 0.262034 Validation acc: 0.887885\n",
      "Epoch: 482/500 Iteration: 32350 Train loss: 0.213717 Train acc: 0.920000\n",
      "Epoch: 483/500 Iteration: 32400 Train loss: 0.254653 Train acc: 0.887500\n",
      "Epoch: 483/500 Iteration: 32400 Validation loss: 0.273604 Validation acc: 0.880551\n",
      "Epoch: 484/500 Iteration: 32450 Train loss: 0.225697 Train acc: 0.900000\n",
      "Epoch: 485/500 Iteration: 32500 Train loss: 0.262237 Train acc: 0.897500\n",
      "Epoch: 485/500 Iteration: 32500 Validation loss: 0.266105 Validation acc: 0.885219\n",
      "Epoch: 485/500 Iteration: 32550 Train loss: 0.260717 Train acc: 0.887500\n",
      "Epoch: 486/500 Iteration: 32600 Train loss: 0.274426 Train acc: 0.882500\n",
      "Epoch: 486/500 Iteration: 32600 Validation loss: 0.260063 Validation acc: 0.889355\n",
      "Epoch: 487/500 Iteration: 32650 Train loss: 0.211517 Train acc: 0.922500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 488/500 Iteration: 32700 Train loss: 0.246523 Train acc: 0.910000\n",
      "Epoch: 488/500 Iteration: 32700 Validation loss: 0.262049 Validation acc: 0.888767\n",
      "Epoch: 488/500 Iteration: 32750 Train loss: 0.208106 Train acc: 0.917500\n",
      "Epoch: 489/500 Iteration: 32800 Train loss: 0.219733 Train acc: 0.920000\n",
      "Epoch: 489/500 Iteration: 32800 Validation loss: 0.259747 Validation acc: 0.889924\n",
      "Epoch: 490/500 Iteration: 32850 Train loss: 0.263307 Train acc: 0.897500\n",
      "Epoch: 491/500 Iteration: 32900 Train loss: 0.259574 Train acc: 0.882500\n",
      "Epoch: 491/500 Iteration: 32900 Validation loss: 0.259675 Validation acc: 0.890532\n",
      "Epoch: 491/500 Iteration: 32950 Train loss: 0.195445 Train acc: 0.917500\n",
      "Epoch: 492/500 Iteration: 33000 Train loss: 0.299963 Train acc: 0.855000\n",
      "Epoch: 492/500 Iteration: 33000 Validation loss: 0.268113 Validation acc: 0.884394\n",
      "Epoch: 493/500 Iteration: 33050 Train loss: 0.231036 Train acc: 0.880000\n",
      "Epoch: 494/500 Iteration: 33100 Train loss: 0.228266 Train acc: 0.905000\n",
      "Epoch: 494/500 Iteration: 33100 Validation loss: 0.259611 Validation acc: 0.889944\n",
      "Epoch: 494/500 Iteration: 33150 Train loss: 0.216559 Train acc: 0.905000\n",
      "Epoch: 495/500 Iteration: 33200 Train loss: 0.253932 Train acc: 0.885000\n",
      "Epoch: 495/500 Iteration: 33200 Validation loss: 0.266196 Validation acc: 0.886286\n",
      "Epoch: 496/500 Iteration: 33250 Train loss: 0.248507 Train acc: 0.880000\n",
      "Epoch: 497/500 Iteration: 33300 Train loss: 0.254837 Train acc: 0.895000\n",
      "Epoch: 497/500 Iteration: 33300 Validation loss: 0.269430 Validation acc: 0.883659\n",
      "Epoch: 497/500 Iteration: 33350 Train loss: 0.231554 Train acc: 0.902500\n",
      "Epoch: 498/500 Iteration: 33400 Train loss: 0.322231 Train acc: 0.867500\n",
      "Epoch: 498/500 Iteration: 33400 Validation loss: 0.262511 Validation acc: 0.888620\n",
      "Epoch: 499/500 Iteration: 33450 Train loss: 0.268051 Train acc: 0.875000\n",
      "Epoch: 499/500 Iteration: 33500 Train loss: 0.097002 Train acc: 1.000000\n",
      "Epoch: 499/500 Iteration: 33500 Validation loss: 0.267476 Validation acc: 0.885110\n",
      "Total training time: 2495.7941052913666 sec\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    training_start_time = time.time()\n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_train, y_train, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 50 iters\n",
    "            if (iteration % 50 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc)\n",
    "                      )\n",
    "            \n",
    "            # Compute validation loss at every 100 iterations\n",
    "            if (iteration%100 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v in get_batches(X_validation, y_validation, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    training_duration = time.time() - training_start_time\n",
    "    print(\"Total training time: {} sec\".format(training_duration))\n",
    "    saver.save(sess,\"checkpoints-cnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAF3CAYAAACL/h32AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XecVNX9//HXYSm7NEWkrBRZlFhA6tpiwRYjajQoCoo9CRH0q2nfaKJRozG/xESjRtBoosYuIkaTL2psWIIonQAqIqAsXZRed/fz++PO7JS9MzszO3Xn/Xw87uP2ez+7DPPZc8495zozQ0REJFnNch2AiIgUJiUQERFJiRKIiIikRAlERERSogQiIiIpUQIREZGUKIGIiEhKlEBERCQlSiAiIpISJRAREUlJ81wHkKx9993XevXqleswREQKyqxZs740s07pvGbBJZBevXoxc+bMXIchIlJQnHOfp/uaqsISEZGUKIGIiEhKlEBERCQlBdcGIiJNy549e6iqqmLnzp25DqVJKC0tpXv37rRo0SLj91ICEZGcqqqqol27dvTq1QvnXK7DKWhmxoYNG6iqqqKioiLj91MVlojk1M6dO+nYsaOSRxo45+jYsWPWSnMZTSDOudOcc58455Y456732f8n59zcwLTYObcxk/GISH5S8kifbP4uM5ZAnHMlwHhgGHAocIFz7tDwY8zsx2Y20MwGAn8GJmcqHhERPxs3bmTChAlJn3f66aezcWNx/82byRLIEcASM1tqZruBZ4Cz4xx/AfB0BuMREaknVgKpqamJe96UKVPYe++9MxVWQchkI3o3YEXYehVwpN+Bzrn9gQrgzQzGIyJSz/XXX89nn33GwIEDadGiBW3btqW8vJy5c+eyaNEivvvd77JixQp27tzJtddey5gxY4DQqBhbt25l2LBhHHvssUybNo1u3brx4osvUlZWluOfLPMymUD8KuIsxrGjgElm5pvynXNjgDEAPXv2TE90IpJ/fvQjmDs3vdccOBDuvjvm7t/97ncsWLCAuXPnMnXqVM444wwWLFhQ9xTTww8/zD777MOOHTs4/PDDOffcc+nYsWPENT799FOefvppHnroIc4//3yef/55LrroovT+HHkok1VYVUCPsPXuwKoYx44iTvWVmT1oZpVmVtmpU4pjgZnBu++mdq6IFI0jjjgi4hHYe++9lwEDBnDUUUexYsUKPv3003rnVFRUMHDgQACGDBnC8uXLsxVuTmWyBDID6OOcqwBW4iWJC6MPcs4dBHQA3s9gLNAskCtHjoRnnsnorUQkRXFKCtnSpk2buuWpU6fy+uuv8/7779O6dWtOOOEE30dkW7VqVbdcUlLCjh07shJrrmWsBGJm1cDVwKvAR8BEM1vonLvVOXdW2KEXAM+YWazqrfR69tms3EZECkO7du3YsmWL775NmzbRoUMHWrduzccff8z06dOzHF1+y2hPdDObAkyJ2nZT1PotmYxBRCSejh07cswxx9CvXz/Kysro0qVL3b7TTjuNBx54gP79+3PQQQdx1FFH5TDS/OOy9Yd/ulRWVlpK7wMJ71xTYD+zSFP20Ucfccghh+Q6jCbF73fqnJtlZpXpvE/xDGVSmdbfm4hI0SueBPLd7+Y6AhGRJqV4Ekig84+IiKRH8SSQVPuPiIiIr6JJIKtXw1CmsoYuDR8sIiINKpoEcttt8B7Hcis3wcqVuQ5HRKTgNfkEUlbmPcF7//1QSwn3Mw7XvRtFMM6ZiGRA27ZtAVi1ahUjRozwPeaEE06goe4Gd999N9u3b69bL8Th4Zt8Alm6FC68EFq39tZbs43R+7/HsmW5jUtEUrd6NQwdCmvW5C6G/fbbj0mTJqV8fnQCKcTh4Zt8Aikvh/btYedOKGUHOyml/dfL6do115GJSKpuuw3eew9uvbXx17ruuusi3gdyyy238Otf/5qTTz6ZwYMHc9hhh/Hiiy/WO2/58uX069cPgB07djBq1Cj69+/PyJEjI8bCGjt2LJWVlfTt25ebb74Z8AZoXLVqFSeeeCInnngi4A0P/+WXXwJw11130a9fP/r168fdgfHBli9fziGHHMIPfvAD+vbty6mnnpr7MbfMrKCmIUOGWLKGDzcbN85sLv1tHPfZ8NavJH0NEcmMRYsWJXxsaamZN5RE5FRamvr9Z8+ebccff3zd+iGHHGKff/65bdq0yczM1q9fbwcccIDV1taamVmbNm3MzGzZsmXWt29fMzO788477fLLLzczs3nz5llJSYnNmDHDzMw2bNhgZmbV1dU2dOhQmzdvnpmZ7b///rZ+/fq6+wbXZ86caf369bOtW7fali1b7NBDD7XZs2fbsmXLrKSkxObMmWNmZuedd549/vjjvj+T3+8UmGlp/j5u8iUQgMmTYfx4GMB8xnM1k7uMzXVIIpKCelXSrWH0aBpVJT1o0CDWrVvHqlWrmDdvHh06dKC8vJxf/vKX9O/fn1NOOYWVK1eydu3amNd455136t7/0b9/f/r371+3b+LEiQwePJhBgwaxcOFCFi1aFDee9957j+HDh9OmTRvatm3LOeecw7uBV1Hk27DxGR1MMW81K4q8KdLkRFRJl3rz9u1pdJX0iBEjmDRpEmvWrGHUqFE8+eSTrF+/nlmzZtGiRQt69erlO4x7OOfqv0Nv2bJl/PGPf2TGjBl06NCByy67rMHrWJyx+vJt2Pji/CYN+0cQkcKydi1ceSVMn+7N09GQPmrUKJ555hkmTZrEiBEj2LRpE507d6ZFixa89dZbfP7553HPP/7443nyyScBWLBgAfPnzwdg8+bNtGnThr322ou1a9fy8ssv150Taxj5448/nn/84x9s376dbdu28cILL3Dcccc1/ofMgOIqgXTsCBs2wGGH5ToSEUnR5Mmh5fHj03PNvn37smXLFrp160Z5eTmjR4/mO9/5DpWVlQwcOJCDDz447vljx47l8ssvp3///gwcOJAjjjgCgAEDBjBo0CD69u1L7969OeaYY+rOGTNmDMOGDaO8vJy33nqrbvvgwYO57LLL6q7x/e9/n0GDBuW8uspP8QznDnDIIfDxxzBqFDwd8w26IpJFGs49/TSceyYEHrkj1QQkIiJ1iiuBBHqQsnt3buMQEWkCiiuBBJ++qqnJbRwiIk1AcSWQww/35mENWSKSe4XWFpvPsvm7LK4EEnz6av363MYhInVKS0vZsGGDkkgamBkbNmygtLQ0K/crrsd4g4/BhT0yJyK51b17d6qqqlivP+zSorS0lO7du2flXsWVQIKdcS6+OLdxiEidFi1aUFFRkeswJAXFVYUVHCp5wIDcxiEi0gQUVwIpKfHmegpLRKTRiiuBNA/U2FVX5zYOEZEmoLgSSLAEcsMNuY1DRKQJKM4EIiIijVZcCcRnvH4REUlNcSUQERFJGyUQERFJiRKIiIikRAlERERSogQiIiIpUQIREZGUKIGIiEhKlEBERCQlSiAiIpISJRAREUlJ8SaQqVNzHYGISEHLaAJxzp3mnPvEObfEOXd9jGPOd84tcs4tdM49lcl4IgwfnrVbiYg0RRl7pa1zrgQYD3wLqAJmOOdeMrNFYcf0AX4BHGNmXzvnOmcqHhERSa9MlkCOAJaY2VIz2w08A5wddcwPgPFm9jWAma3LYDyRNDKviEijZDKBdANWhK1XBbaF+wbwDefcf5xz051zp2UwHhERSaOMVWEBfn/im8/9+wAnAN2Bd51z/cxsY8SFnBsDjAHo2bNn+iMVEZGkZbIEUgX0CFvvDqzyOeZFM9tjZsuAT/ASSgQze9DMKs2sslOnTumJbvv29FxHRKRIZTKBzAD6OOcqnHMtgVHAS1HH/AM4EcA5ty9eldbSDMYUsmsXfPVVVm4lItIUZSyBmFk1cDXwKvARMNHMFjrnbnXOnRU47FVgg3NuEfAW8L9mtiFTMdWzfn3WbiUi0tRksg0EM5sCTInadlPYsgE/CUwZt3o1jGIqzzKSrqzNxi1FRJqsouqJfttt8B7Hcis3NXywiIjE5bxCQOGorKy0mTNnJnVOWRns3Fl/e2mrWnbsLKocKiJFyjk3y8wq03nNovj2XLoULrwQWrf21luzjdE8wbLXs9NeLyLSFBVFAikvh/btvVJIKTvYSSnt2UzXTjW5Dk1EpGAVRQIBWLsWrrwSpnMUV/IAa+gCb7+d67BERApWUbSBRIgeA6vAfn4RkVSoDURERPKGEoiIiKRECURERFKiBCIiIilRAhERkZQogYiISEqUQPQYr4hISpRAHnww1xGIiBQkJZC5c3MdgYhIQVICERGRlCiBqA1ERCQlSiAiIpISJRCVQEREUqIEIiIiKVECERGRlCiBqApLRCQlSiDLluU6AhGRgqQE8vrruY5ARKQgKYGIiEhKlEAAVqzIdQQiIgVHCQTgyCNzHYGISMFRAgFYvTrXEYiIFBwlEBERSUnxJZATT/TfXlOT3ThERApc8SWQ9u39tzdvDk8/nd1YREQKWPElkHgmTcp1BCIiBUMJREREUlJ8CaRPn1xHICLSJBRfAjnrrMSPfestVWuJiMTQPNcB5JXJkyPXTzrJm2vEXhGReoqvBOJcriMQEWkSii+BiIhIWhRdAln9VSuGMpU1dMl1KCIiBS2jCcQ5d5pz7hPn3BLn3PU++y9zzq13zs0NTN/PZDwAt00Zwnscy63clOlbiYg0aRlLIM65EmA8MAw4FLjAOXeoz6HPmtnAwPTXTMVTVuY1f9z/l2bUUsL9jMNhlLG94ZPN4JVX1JguIhImkyWQI4AlZrbUzHYDzwBnZ/B+cS1dChdeCK1be+ut2cZonmAZFfUPrq6OTBaPPgrDhsHDD2clVhGRQpDJBNINCH9TU1VgW7RznXPznXOTnHM9MhVMebk3DNbOnVDKDnZSSns205W1kQeuWgUtWsADD4S2ffFF5FxERDKaQPyel42uA/on0MvM+gOvA3/3vZBzY5xzM51zM9evX59yQGvXwpVXwnSO4koe8G9I/81vvPlTT4W2bdmS8j1FRJqqTHYkrALCSxTdgVXhB5jZhrDVh4Df+13IzB4EHgSorKxMuSGirp/ghPmM52r/g+6/v/62O+9M9ZYiIk1WJksgM4A+zrkK51xLYBTwUvgBzrnysNWzgI8yGE9yvvwy1xGIiOS1jJVAzKzaOXc18CpQAjxsZgudc7cCM83sJeAa59xZQDXwFXBZpuJJ2scf5zoCEZG8ltGxsMxsCjAlattNYcu/AH6RyRhERCQziq4netpt25brCEREckIJpDE++QTatvX6iYiIFBklkMZYsMCb//OfoW2bN8NPfwq7duUmJhGRLFECSbebb4a77oJHHsl1JCIiGaUEkoxE3iWye7c3r6nJbCwiIjmmBJKs2lp48EFVUYlI0dMrbZOxZw/89rfwq19542INGuRt1yi9IlKElECS8dvfhpbvuQe2bo19rJKKiDRxqsJKVXjyeOGF0LLeuS4iRUIJJF3ilUZERJqgokwgq+ma/vein3de+q4lIlIAijKB3Mav0v9e9FdegcGD03c9EZE8V1QJpO696IxL/r3oiZgzB8aPT8+1RETyXFElkLr3ouMNgBj3vejpsG0bXHONBlwUkSapqBJI3XvRKY3/XvR0+dOf4M9/1hsNRaRJKqoEAoH3oh+zIP570dPhvffgllu85ZtvhlmzMnMfEZEccVZgHd4qKytt5syZjbvInj3QsmV6AkpU+/awaVN27ykiEuCcm2Vmlem8ZtGVQABo0SLXEYiIFLziTCAiItJoSiDZEhzi5Pnn4euvcxuLiEgaKIFk0xdfwIgRMHJkriMREWk0JZBs2rHDm3/+uTefP199RESkYBVtAsnIeFjxbNrkvYwqaNs2GDAARo3Kzv1FRNKsaBNIRsbDash113nzdeugbVtvecoUr31Ew8CLSIEpun4gZWWwc2f97aXsYAetGxFZGpjBypXw2Wdw/PG5jUVEmhT1A0mDrI+Hlazu3WHo0FxHISLSoKJLIFkfDysZ4W82nDjRm48dC089lZt4RETiKLoEAoHxsHgg8+NhJeucc0LLI0fCGWfAAw/A6NGw997wzDPevv/3/2Dx4tzEKCISUHRtIHWcYzVdGcUzPMvI/CiBNKRrV/joI+jQwStKrVqV64hEpECoDSTNcvIkVmOYeRPA9jS9BEtEJEVFmUDKysBhmXszYSbFetz3uedi9ymZMcM774MPMheXiBSdokwgS5fChTxZ9yQWGH34JH+exIpl7Vq4917/feefD88+679vypTIuYhIGhRlAikvh2cZyXbaBLY4PuUgylmT/6WQm2/25ps2eaWKkhJvSBQRkSwrygQCcGrHWfThE0rxxqcqoTq/+oMkqrYWPv20/vYNG7yBG/USKxHJkKJNIFPm7MfJvMluWlLKDgyXP/1BGmPSJG9+xx3e0PEPPJDbeESkySraBEKPHqylc372B0nWvHmh5fPOg+XLQ31Gdu2CF18M7a+tjRzU0c/69WkPUUSanuJNIMBkRjCeqxnAfG7kN2xg38JMIrfdFrleUeG9ewS8NpM5c0L7WraEgw4Krb/3HtTUhNYnToTOneE//8lcvCLSJBR1AglaTVeGMJN3C6lPSCruustLFkuWeOuzZ8Nxx0Hz5nD33V4fk7ff9vbNnZu7OEWkIBR9AiljO/uxmtV0wwqtT0iytm4NLe/ZA//3f6H1H/84cl1EpAHNcx1ALpWxnZ2U1dvejOrCexorWS1b1t+2YwdMmJD9WESkICVUAnHOHeCcaxVYPsE5d41zbu8EzjvNOfeJc26Jc+76OMeNcM6Zcy6t47Q0ZCm9uZAnKWFPYIsBxsU8XvhPYzXWz3/u/3hwSYn3hJeIFL1Eq7CeB2qccwcCfwMqgLhjjDvnSoDxwDDgUOAC59yhPse1A64Bsj7ORjlraM9maiihGdUAfIOP2Uz7bIeSf7Zvh7PPrr+9tjb0ZkURKWqJJpBaM6sGhgN3m9mPgfIGzjkCWGJmS81sN/AM4PONxG3AHYDPewIzby2dGcf9nMvzAHxOLyZwVS5CyT/Bp7MWLtTgjSJST6IJZI9z7gLgUuBfgW0tGjinG7AibL0qsK2Oc24Q0MPM/kWOvMzpTOAqnmMk4NhFWWEMaZIJflVWO3ZAv36xB2oEeO017zgRKSqJJpDLgaOB281smXOuAniigXP8ho2te/mIc64Z8Cfgpw3d3Dk3xjk30zk3c306O7n16cNSetdVX4XbSVnxJZEbbohcX7w4lBiCj/dGW7gQTj0Vrr46tO2zz6B1a/+EJCJNRkIJxMwWmdk1Zva0c64D0M7MftfAaVVAj7D17kD4G5DaAf2Aqc655cBRwEt+Delm9qCZVZpZZadOnRIJOTG33045axjNk0AtofxmlLKdDzgiffcqVAccEFoO7/H+9dde8ti40Vv/6CNvPmsWHHigl3ieaOhvjDCffQZ33tn4eEUkaxJ9Cmuqc669c24fYB7wiHPurgZOmwH0cc5VOOdaAqOAl4I7zWyTme1rZr3MrBcwHTjLzNLwusEEtfBq4bbSNlBcChaaHDtpzQD+S2mxlUKiBRPE5s0wcGBoe6dOXtXWmDGRx596auxrVVd7/U3Wrau/7+ST4Wc/g6++8j93167k4haRjEu0CmsvM9sMnAM8YmZDgFPinRBodL8aeBX4CJhoZgudc7c6585qTNBpE3i732RGcBov46g/RtQuypRE/AQb2Bct8ua7dsFZZ0UmgPDXJc+e7SXsu++Gq6IeUvjyS/j88/rnBH36KZSWwmOPpS9+EWm0RBNIc+dcOXA+oUb0BpnZFDP7hpkdYGa3B7bdZGYv+Rx7QlZLH95N6xancCYX8ThhzTR1dlFGM6oLc5ysbJk9G/75z8htt90GF17oJZsf/zi0vTqszWn0aK80E8+CBd78hRfSE6uIpEWiCeRWvJLEZ2Y2wznXG2hyLaRbacs3+Bi/JGKU0J2q7AdV6J5+Gv78Z3jnnfr73nwTnorbnUhE8liijejPmVl/MxsbWF9qZudmNrQs+OY3I1YnM4K+LApLIpGJpIbmuEADuyQhvPQRtGiR1+4RLdY730Uk7yTaiN7dOfeCc26dc26tc+5551z3TAeXcV271tsUTCIOI9aTyKN4JuOhNWnOJf6iq7VrExsZePt278kwEckaZ36NltEHOfca3tAljwc2XQSMNrNvZTA2X5WVlTZzZhqbStq2hW3b6m0+nX+xhANZygHUxBhzshU72Enr9MVSLMrKYnc8/PJL6NjRW37jDTgl6lmN6M9rdbX3+t7jjvMa2xP4PCds5kzv/p9+2nA7jUiec87NMrO0jjeYaBtIJzN7xMyqA9OjQNP4H7Vwoe/mKZzJybxJDSUxTlRJJGXxeq1XVMC3v+0tRyePoMmT4Ygj4K23YNw4ryQZ3WnxN7+J7LeSij/8wXun/JtvNu46Ik1UognkS+fcRc65ksB0EbAhk4Flzf77x9y1ls5cyqMM4/+o37Du+DuXq00k3bZsgX//G1591X//4sVw7rkwYwacdJL33vdoZvCrX3n9VqZNi9y3dat3rnPeY8cikrJEE8gVeI/wrgFWAyPwhjdp0iYzgke5gv35glCjengi8dbP4kWGMlWP+abTaaf5b09kKJvwd74fc0zkvu98xyu9gPfY8caNDQ8UaQaPPw4ffuitBxPQ++83HItIE5boU1hfmNlZZtbJzDqb2XfxOhUWheCIvb35LGqPAxzPMYp3GKrHfLPh9dcj12P1XPdTXQ1Tp0Zue/ttaNPGK/XMnu0li3796r9w65JL4MgjveVXXvHmU6YkFbpIU9OYV9r+JG1R5LnJjGA8V7ODMtqwhU6swa+vSPAx36IbhDGbbrkl/v6VK+s3pI8e7ZU8WvgMIB3sn3LDDTBkCIwf77WL7dkTavvQo8UivhqTQIruf9UqurOVvTiXeD2ijb4sVHVWrlx0Uf0E8tRT8K8YAyjcFRjS7ZNPvPn//E9o35dfevNUn+xasiQ05EsubdoEVSodS/o1JoGk8XnJHGvor9ooa+lMDz6nJ8vxa1yfRSXlrOJopimRZNvUqal94W/ZEntfrGHpf/ObyGFZwi1bBn361B8iP9xLL3lPkmXawQdDjx4NHyeSpLgJxDm3xTm32WfaAuyXpRgz78Ybkzp8MiP4ggpO52X8eqx7mjGdo9mPKoYylXkcpob2QnXTTbH3jRsXWq6t9YalB1izxpvHeo8KeK8MPumk1GIy82//2bnTGxY/PLEFYxFJs7gJxMzamVl7n6mdmfn3ritEJbH6esQXbFw/g38SK5EYzXmHoQxkHu9yLNfxOyWSTJs1K3v3evrp0PLtt3vvQnntNTj//MZfu6bGG0By6VKvw+vixaF999zjdbhcujTynN/+1hsW/9FHG39/kQY0pgqr6AUb11uyh74ERoyNWbPnMEp4jMv0xFamRY1xllbOeVVPQVu3hoaZDzbIn39+qM1hwwav4+SePTB4MPzE59mTvfaCVavqj4hw771wzjneS722bYP77w/tC458vGxZ5DmbNnlzn9EVGm3XrshHpJO1fr0efW5ilECC4lU1NGAyI/gGi6lgKT1ZRiLNQ3piq4BFD6Vz6aXewJDBR4TD22A+/dR7ve/QoTBnDvzpT9723btDx2zeDN26eaWMcNEN3/HG+nrwQbjjDi/pxHLjjV5sv/41TJ8e+7hYSku9nzVVRx+dWHKvqvLGQJP8Z2YFNQ0ZMsQyxvvv1ahpOJOsDZsMagOThc2jp1obwgxbTZe03FtTgUwLF5qNHeu/72c/C30ef/KTyH2XXBLad9JJ3rbXX/f/7B51lFltbf19c+aEllesMJsyJbH/G+vWhc5L1ubNZvffn/j5DR23dKnZl18mH0eRA2aapff7WCWQcP36NfoSkxnBqbzmU6VlYctBoSe21CZSRPr2jayOCvfHP3rVWQ0J9lHZudN/bLHp0/3fSW9hn8EePeD0073lr77yL4V/+KFXLTZgQGhb8JHnRF19NYwdG1q/6qrEX1H8f/9X/xHs3r29tqam4vbbC7avkRJIuLfeiv0fOwnBKq1xTOAk3qAvC9iPlYG90UkEoBnlrMFRHfHo72q66gmuYtStmzeP/lIxn8/OmWdCu3b+1/F797zfNcB7l/0JJ0Q+vbVnj9f7/owzYPXq0PaDD44ZekJxTJgAzz4bWp87N/ZwMmee6XUCjbZxY3IxJCPWo9mpWrkS7rsv9n6/p0B37vT+/e+8M72xpFu6izSZnjJahRWUgWqL4UyycdxnZ/CiRVZvRU+11plVdhTT7FIetmZUW1/mm6PayqlSdVexTGZmP/1p/e2rVpnt3p34da69NnJ91qz6x9xzj1nz5t7y7t1my5eb3Xmn2c6d3raWLf3ji+ell8yc86qvTjut/vmPPuod99VX3vq553rrVVX+P8f995t9+GHk/89MWL7cu/bf/pa+aw4c6F1zxQr//X4/z6pV3rauXdMWBhmowkrrxbIxZSWB3Hhjer8MwqbhTLK+zLfYCaThqZTtGYtPU55M77+fmevOnBl//6ZNoeV77ol9XEMGD/aOu+MOs1NPrX/+I494xwUTxn77eevHHhs/PrPEY0jFK6941z71VP/9995r9vzzyV2zZ8/Qv6kfv5+nQBKIqrD8JNmxMBnB6q0efE4ZWyCFDv07KdPTW03d0Ufn5r6XXBJavvbaxl/v5z/3BqqMtm0bvPuu99UJXrtPs2beSMepuvBCuOYab3nixPptQ7t3w8UXw4svRm5fs8Z7ydnMmaHha2K55hrvdQIA8+d71Ux//GP8c774wpun8m9qyX8/ZFW6M1Kmp6yUQMzM9t47M38Bhk29WGKh6qzwye/w4PYa68g6m0e/iANW0dWOZ6qquDTFn2bMiL9/r70Su0607YFS8Z13eutDhiR2nenTk4v/hRdCy3v2mK1cGYohuP3dd735D38YGePtt/vH/9hj3raLLgrtj1UCCT8/3u8jKFhFF++44L7f/c6sutrbtnq1t61Ll9jXThIqgTQtg5hLBUvpRhWt2UoJewJ7LDCFc3XzDezLt/g3RzOtroH9F/yW99TTXRor2BGxIc7BihXegJHadAH2AAAgAElEQVQQGlblzju97YmOBrB1a3LxDR8eWr7mGu+Bg+gG9eDP8MQToY6b8+blpm/Jzp2JH3v99V7JKZxFfw/kl6YzHEkBmsyIiPVzmMRcBuKoZSkHEkoi4U/jeMvrKGcd5QxkHuB4h6EAPMZlAHSnimp8hi/He7prFM/wLCPpijpsFZVEHhFOVM+e3vzll+Gww0LXD27PtGBv/A4d4L//rb9/2zav4+a113pvpwx37LFex8/mefYVGEw4wSfw1q3zEuTee+cupjhUAonl+uuzfsvJjGApBzKA+YxjAiN4LrCnlvolkiD/58eje7qvpitHMY0hzGAgc3iHYxnMLJVUis3ZZ6f/msOGRT6Wm4xg+0BjxRv7y2/Qyf/8J/LR5GRFDyGTLh9/XH/bfvk7bq0SSCzXXZf0MO/pEhxjq4aSQCKZFNhj+Fdv+fHe1f4BR7CargxhJh9wFLOpZB1dgRJW041y1qhBXhrvpz9N7bwrrkj9nuH9ZObNCy1HV/sMHpz6PWKJ168j3qsB/v53L+4NG/z333GH98bLhQtD23bsgEWLYORIr29OHlECScT+++fktuGJJNhW0o5gHXV4IvFLKI6dtGYA/2U/VrOabsQqreipLilIK1aElsNfdZxMZ+A9e/yrv8KTUPfuMGZMYtd79llo394b98xPcKyyz6Jfjx1m2DBvbLVwl1zitY+EJ8o8oAQSz8iR3vzll72htP0eR8yCYNVWFT05hTeoYCm9CTRexk0iiWvEGKsi+SXRd9X/9a/e0Pd/+IO3Hj40f9CGDV5P8ocegkmT6u+P9sor3nzuXP/9s2d78zxvHE9UnrUg5ZmDD478h+7TJ3exBAQb3s9hEqfxbz7mINbShS/pyFrKA0fFG1cn/IPr6tYv4JlMhCuSv269FSorQ+t+rx8+7bTQ8nnnhZajE8CTT8Lo0cnd3yzxdpg8TTgqgSQr0UHgMixYvfUG32IB/fkm70cN4BjdVuKtt2UzzQgf68cBjr9zOQ6jGdUJjb0VHKdLjfBS0ObP99/+2mteNVSs/dEuuij0PhjwnqYy82ov/EydCnffHRr3LFF5NuiiEkiyWrbMdQS+ogdw7EDwyZNQIunLAr7F63j/7H4fRMNoxjeZVveUVqxkchu/4j2O5VbivO5VJN+Fv5clWrKN7x9/HCopjBsHxx8P3/ue/7HXX+8lqUTlaQkkrb0SszFlrSd6PLnuTZzANJxJVsESO5+n7XyetgqW2HAmmeH1Wr+QJyzx8bhqbV/W2lFMs5bs9D2mVZzxuVLpJa+e9ZryYmrVyn/7j37U+Gv7DTIZa+oS+H8wa1YjvrbS3xNdbSCpeOIJrySSjvdeZ0h0J8Vw5ayhPZuhrnTiiN9u4viSznxJ58DxtTSnhmpaUMIeamjOqDhtKOGllQlclVD8t/Er3g2UgmYzRB0eJTdiVVmn45XByXTqDPaiz7MqLOclpsJRWVlpM6NfKZorefaPmYxzmEQ5a1hHJyZxXtTe1H+uVuxgJ60BKGUHuyitd0wpO9gROCZaGdvZSVlS54gUjTlz6veqT5BzbpaZVTZ8ZOLUBpIuV16Z/y9/CZNYH5OG/rgIP8brLd+eLXXtJmfxD7zSitf5qYztdGYtH3BEzCsupXdUI79HfVVE8o9KII21116webNXUwlNolTyMQcxh0F8zT4+RzXm5/N+R2O5P2ZV1mq6MpDZrKMLwaq15uxhJM/yR36mqiwpbiqBNDFr10a+jvPDD3MXSyOFPxp8AlMTGCk40T8+gsd5CeF+xkWM0xXuNn7FOrrQga9xGCVUU01z2rNZyUMkz/5AVQJprNJS72U0QYcfnrtY0ii89/s22nMW//QZ4DE4byiR+D8y/A0WM4QZHM00WrETh3E/44BmfE1HjGaUUM2lPMpEzqv3KHGifVH0bnmRzFACyYQzz8x1BGkXPcDjSbxJXxawH8EnSaLbTWLNgxzzGcBshjCdoyihGi8ZeYmpGTWcwyQ+pxet2cHX7FPX5ySYEILvQGmoL0rwia5vMo131XdFClmelUAy2gbinDsNuAcoAf5qZr+L2n8lcBVQA2wFxpjZonjXzLs2kFjWrYMuTf8v3eA7THbTks20Ywt7+RwVfFQYEm9DCa/2ine9EEcNq+hWV9UV6ymwoPAnxnJN72iRhMyfH3r3SpIKqg3EOVcCjAeGAYcCFzjnDo067CkzO8zMBgJ3AHdlKp6s69QJLrgA+vXLdSQZFT3QY7AnfF8WsC/rA/Mv6cuCQJtHIk93QWTflOhSTHTyMCrwRjcNL12M5Jk497K4fVfiycQwLsG+MnqjpMT1+ee5jiBSunsmBifgaODVsPVfAL+Ic/wFwMsNXTcveqInY8KE3PemzZOpnCrrwJcW+z3wifaMT+9UGqcXffgU7B1/KQ9bM6ptLOMbffNStvvuKmFPzv+9NOXhdPDBKX8VUWDvRO8GhA3YT1VgWwTn3FXOuc/wSiDXZDCe3PjWt0LLF1+cuzjywCq6N/B0V3BuUevJMJqxJ855oWu3ZhujeYJlVES8sfFopvmWAHqwgncYyt+5nFpK4j5NFrxerGsFLaU3F/JkvXij3ygpkpfSnZGCE3AeXrtHcP1i4M9xjr8Q+HuMfWOAmcDMnj17ppyBc2bXLrPNm82qqkJ/Sbz9du7/msmDaTiTbBz32Um8Zn2Zb/uyNqyUUhM1Dy+hRK83NHnHt2SHQa01Y4+Fj/F1KQ9H3Ce8dNGKHTGvOZrHfcfrGsv4uus1VFK5kgnmqK6LCcxaszXmtROZNJZYE50OOSTlryEyUAJJ68UiLpx8FVYzYFND1y24Kqxo69aZzZxp9t57uf8w5ukUP6nEmmJdrqFj4iehVmy3S3jEoMaas7vunOCX/aU8HHFCrCopiF1VNox/WTlVdib/CFy7Om4VWSLJYSzjrRnVdgmP5H0iUbJLYjr00JS/egotgTQHlgIVQEtgHtA36pg+YcvfSeQHLPgEEvTxx7n/MBbQFD26cGu2WGu2WG8WW+z2FG86j2fsUh627nxuyZda/Le3YptBrfVgWcSX3xz62z6ssxL21B3fjD3WkXU2j36+Nwp+2VewxMZxn82lv43jvrrRk2Md75dgCrFNJd7Poylq6ts35a+cgkogXrycDiwGPgNuCGy7FTgrsHwPsBCYC7wVnWD8piaTQMzMpk/P/QeywKfw0kp0KeUAFkcMYx+sKnJhVUXJTfFKMjW+VWHhUzlVEX9lx/qyj1VSSeT4VXS1PnwSM85EHxjIxpTsz68Js8MOS/nrpuASSCamJpVAzMzuuiv04Rivv8AaMwWTSay/4IP7R/CsNVRqyWSowXenzKG/dWKNlbHNwKyMbdaZNTFLKtHHR7eTxKs+A68klE/VRA39PJp8pv79U/6qUQKxJphAzMyWLjVbtMhbzvUHtAimYHVYN76wdnxt4YmjN5+afyJJNqnUWtu6a/vtr7bOrLZgacVRU7d8CY/YkUyzo5hW92W6iq5WTlXdMa3YbtFtMPVLH5GJMbq9JtdT+IMGpWwvqmqslNt9lECUQOL63/+N/MCsXJnzD3tTnqJLLeVUWQVLYrStBKumzOqXXDIRXq11ZlUgufjvb8l2O4ppcZ8Uc1TbN1hkHVkX8YWVyJdYsl90iRwfr50mVrtPU5tSbvfp0SPlrxYlECuCBBIU/MCEL2vK2hTeaO+VVDbafqywUCLxb+fwTvdLLJnuJFkTaAOqqVtvx9d2DG/bpTxsrdhuLuoLy3u6LPQoc6zHkR3VVk6VzeWwhJ/+ivfFGHylcmu2GhRX1VVa2n1S/kpRAinOBPLBBzn/4GuKLK1UsMQqWGIn8Zq1Y6O1ZrP5l1YaeuQ4OsnU+ByTzBS6Rl/mN9guEj41Y09dgoh9Xq3vo8HJfDEGq+Mc1UVZddXo5JnyV4oSSPEkkMpKs/PPD63v2OH/Ydpnn5z/p9Dk33elHRutG1/UPXbcjo0Wvy9LvDYYs/rJJtVE09B5NXYYcxs8Lvho8Cq62pFMswqW1J0TfCDgdU6ol2yCbR99md/gI8vBKrFESj/R5+RjiSYtyTNFSiBWRAnED5iNGhX5YfrTn3L+n0JTYlN44/0BLLZStllzdtUlmQqWNNAGk2hHSm+9lG3Wi6U++xOdEh2rLPb2vsyv69DYjGrf44KlFL8v/mCVWPA68TpXHsk0G8wM68zqetV1+TJFJ89Lebhe21SDU8pfH0ogxZ1AqqvNamvrf5iCy9Om5fw/iKb0TA0lm/gdKWuthD3WjGo7lP9aZJtNOsNMrS9NsJNlc3ZHVN+Et7fEfijAmxzVPqWa/O37Eu/BgaRLISlSArEiTyBB7dt7/3Sffeatr1ljtmmTt/zuu2aTJpkNHZrz/zSaMj/5JZp2bLSTeK3uqbL4fV9qrDm7rOFSRqpTIteL3TnT1ZVagsdUBx4IqLGxjE+gjac2Zr+aRKZEq9AaqjaLbvtINNn5XjdFSiCmBGJmZp98YvbAA/GPOeGEyE/m3Xen/J9IU+FPfn1fXKBUUr+UEu/psliJJrXSiJe8quOcH6+qLjg1XLoqZXtS7SnRQ/fHqkKLPi7e2GNXMsGaBdo+HNXWh098G9PDk4bvmGYpUgIxJZCELV8e+QE2M3vlFbOXXkr5S0hT05j8+r4EHwBox0YrZZu1ZnPdVP/R5XiJpqHHmbMxxU80ZWw1ryPnKhvMjHqPMK+ia4MxBxNSrOOixx5bRVfryDq7lIfrfu+9WGLNAiUqCHX0jFcdV8KelL8SMpFAMvpK20womFfa5oPg+5NPOQVee63+dpEGnMMkylnDGB5kOJMBqGAZMzicPbSgGytZSTeqaU4X1tKKnSzlQKh77XBwHs757A+f43MOMa4Vub8tW6imJOxVxbFiiDyvM2vozkrmMBj/1yQFr1FDR75iC+3ZTas41/SUsoOl9GYIM1lDV67kL0zgKiD0u13PvjzH+Tgsxr19rlsKO3YkdGidTLzSVgmkKXv7bWjeHI45JnJ7MIHcey9ccQW0beutDx3qnSOSouCX4sccxFq6sJYudGEta+lCDSV8zT7ETx6xko0f/6TQjBoMl/CXccP87t/QH2FGK3awm1LfOBw1tKA6RhKKnfBas43ho9vwxz9C164NxR11TyUQJZC0ePRRWLkSbrjBW582Da67Dt54A1qFfaC/+134xz9yEqI0PfGSS5fAlmVUsJYugLGdtnXnlrKDFuyhPZvDSjlBwS/bWvZjFbOo5Ar+xsccxHJ6YTT3iaahUkkykr1WLQ6jD4tZzEE0p4ZqWgBGM2qopQRHDUaJ73VLSqC6OvkoM5FA/H6z0tRddlnk+je/Ce++6y1PmADjxnnLLVtmNSxp2iYzIuFjw6vOHmQMq+lad/45TMJohqM2rLoMwHE2L9GVtUzhTMYygQf4IbFLMOHb41WZxSshhZ/bcFWZt78ZBizmEACq60oojtrAV7KXPMJjdJSygx58wYGnHhTnHtmlBCKRrrwylEBOOQUmTozcf++9cE3Te3W95JfwZDOeq333BRPJ4cwAYAaHR7x/fi2dqWAZu2nJ1+zNTkopZSe1lFBNc5pTTQt2s4W9aDjJ1BK7jcYoZQc7KQs7LvoYv/V4Caf+sbtpySm8wYQpSiCSr5yDM87wqrK+/304+2zoEvpPyWGH5S42kTANlWgSKfGcwyTmMtA3ybRgD63YVVfNtotW1NAsULUWmXDKWc0wXuFjDmIOg8LaeqB+4jGCyaMZ1dTWlTYik1Jw/wF8xv2MZTLnspokGz4yTAlE6vvXv0LLnTuHlj//HHr2zH48IhmSTLUaRCacUnayg1JasZuBzK0rKQWP+ZKO9Uo3XhuHoxsr2ZuNdGEtMzicLbQnOimVUI3hOIU3OJm3OJm3Anvyp91aCUQa1qkTrF+v5CFFL5GEEzxmP6royQpu4la+z1+poYRpHOPbphOelFbSjRbs4XBmcDCf5F2pI5yewpKGLVsG77wDl17qrQcfA66pgb/+FX74w8jjzz+/ftvJ7beHnvoSkdSl+J2tp7AkNyoqvClas2b+nRJvuQUWL4a5c0PbWreGjh1hw4aMhSki2ZWunjZSbPbd15tHP+r7m9/AIYfAnDnw8ste58TLL4cf/AB+/OPsxykiGaMqLEneunXeWArt28OePXDzzfDqqzB7Nrz5Jpx4ov95mzfDXntlN1aRpiaPqrBUApHkde7sJQ+AFi3gt7/12jwuvLD+sCnhgueISJOgBCLpccAB8OSTifde/9734MYbMxuTiGSUGtElN/76V29+8cVeNVi/frmNR0SSphKIZFd0NdY3vgF9+0KPHt56//6xz7322tjtKyKSdUogkl1Ll3r9SqLNmOGNCvyXv4S2hQ+hAtCmDdx3n/91P/oofTGKSEKUQCS7OnaEXr3qb+/SBY4+OtSv5NBDIxPN/vt7gzx27x55XnColYMPzki4IhKbEojkl8MPh//9X3jlFSgrC21fvhy6dat//Pz58J//RG5bty6jIYqIR43okl+aNYM77oi9P7zne1WVV3KJrurq1CkzsYlIBCUQyX9+gzi2bVu/RHLVVXDqqdmJSUSUQCTPffFF4h0QYzWwi0hGqA1E8luPHpHDn7Rp472C9+mncxeTiAAqgUihadasfqN5PK1be099LVqUsZBEipVKINJ0deoE27Z57ycRkbRTApGm6dNPY3cuXLYMVq1K7brHHZd6TCJNjBKINE0HHuh1WvTTqxeUlyd/zRkz/F+gJVKklECkuLRunfq5bdoogYiEUQKRpi9dX/oF9vI1kUxTApGmLzyBPPFE+q6ViAkTGnc/kTyW0QTinDvNOfeJc26Jc+56n/0/cc4tcs7Nd8694ZzbP5PxSJG78UYYPjy0ftVV8KMfxT6+Z0/4+OPQullyCeS666BVq+TjFCkQGUsgzrkSYDwwDDgUuMA5d2jUYXOASjPrD0wC4gyCJNJI0VVQ990Hf/oTPP+8//HOwUEHeSMDp0LtJdLEZbIEcgSwxMyWmtlu4Bng7PADzOwtM9seWJ0ORI3VLZIGDX2Rn3NOYtcxg9LSxO+rNhNp4jKZQLoBK8LWqwLbYvke8HIG4xFJTXgCevjh3MUhkmcyOZSJ3599vn+SOecuAiqBoTH2jwHGAPT0G5lVJBP8Si5duyZ3vkoh0oRlsgRSBfQIW+8O1Ov+65w7BbgBOMvMdvldyMweNLNKM6vspHc9SLYFRwNuluR/lwED0h+LSB7JZAKZAfRxzlU451oCo4CXwg9wzg0C/oKXPPQaOcmMcePgjDPg2msTO37YMG9+5pnefNIk+P3v4ZBD6h87cqT/Nd5+G0aNSj5WkQKSsSosM6t2zl0NvAqUAA+b2ULn3K3ATDN7CfgD0BZ4znnVBV+Y2VmZikmK1D77wL/+ldixwSqnVatC71vfbz/4+c/rH/ud78BPfgLPPuu9infGjNA+v2Qj0sRkdDh3M5sCTInadlPY8imZvL9IyvbbL7HjWrb05h06RG5X24cUAfVEF2mMAQPgnnu8Hu4ffJDraESySglEpDGcg2uu8d49csQR3jxc+NsUwTtGpIlQAhFJVSLVVOeeCw89FFr/f/8vsWunMty8SJYpgYhkQjC5OAff/378Y994o/62225L/d6XX576uSJJUAIRSaeGhk3x279/mscQveaa9F5PJAYlEBGA+fMjH8PNlOhqrxEjQssVFaHlPn1Cy+ee680PP7z+9YKPGofTII6SJUogIgCHHQaVlYkdG6yS+uUv6+9r29abJ/IlfuKJ8Nxz/scef3xo+dJLvXmXLvWPU7KQHFICEUnWQw95JYmjj66/77XXvF7rfiWDaG++Gbkeq1F+7729eY8e8OCDDV+3f/+GjxFJAyUQkXTq3du/13o8sUoRwWqs446DiRPhzjth4MDQfr+xtlq1irzeY48lF4tIEpRARLIpmR7qM2fCsmXe8nnnQVlZaN+BB8L06fXPiU5G5eWhNhSRNFMCEcm23/8e3n234ePat4devSK39e8PJ5wATz/tvdwqVunl5JO9uVlouBWRNMvoWFgi4iO6iqtFC2/etSu89BKsWFH/nKBWreCttxq+R3hiidfQvmKF11s+OGS9SBKUQERyrXt3eOQRbxj5Ll28J8IStd9+sGZN6vdu3hzatUv9fClqqsISyaZYL6W67DL/x3Qb8q9/wd//3qiQRFKlBCKSDT17eg3aQ33f2py68nK45JLQeqtW9Y9pzLAoInGoCkskGz7/PDv3mTbNm99yC8yd6/VeD/Yj8ZPsa3pFwiiBiDQlhx7qzY85Btavb/j4RDo8isSgPz9EilXPnrmOQAqcEoiIxPa3v+U6AsljSiAixeSKK0LLRx7Z8PHJPFIsRUdtICLF4NVXYdu2yB7wjz7a8HnxGuCl6KkEIlIMTj0Vhg+PHIurdeuGzwt/LwnA//xPeuOSgqYEItIU3HADfPObmbn24sWh5Xvvzcw9pCApgYg0Bb/5DfznP6mff/jh8N3v+u+LLoWkondv+NGPUj+/pKTxMUjaqQ1EpJjEGpn3ww+9eTrfcFhSAjU13vK4cckNZR9tzhy9KCsPqQQiUkxuvDF792pMwojWpk36riVpoxKISDFp1w4uvBDmzUvuvEGD4NvfzkxMUrCUQESKzZNPJn/O7NmNv2+wRHL11bBnD/zlL16V2ejR8MQT8c/VS7HykqqwRCR5jflCLy2Fo47yli+5BEaNavgc5yLfBy95QQlERJKzZk3yowv36BG5/q1vefOrrkrsfJVA8pISiIiEHHFEwz3Uu3TxXoObqFdegfPOi9zWrZtXpXX44XD00V7bTEVF/XNvvNF7aVanTonfT7JGCUREQj74AC69FM4+O/5xsfplvPRSaLlfP29+yileFVSsp7L22Qc2b/aGoI/WoQOccUbDcSersjL91yxCSiAiUt9zz8HGjbH3t2wJM2bAkiXeWxHfest7iVX4l/0bb8Drr9dPNsn0NUmmpJOM3/42tfPmzk1vHAVOT2GJSH0tWjT85R38K37VKm9+wgmR+/fdF04+OfF7/uIXoaexBg+GH/7Qe1d8tE6dEntZVrhmzaC2Nrlz/AwY0PhrNCEqgYhIfgi+TRHghRdgzJjI0suJJ3rzWbOSv3awR3y4srLkrwPw85+ndl4TpAQiIul17bXw4ov1tyfSM/2dd7xGd7+3Jd5xh1dlFv1EV7iJE712nBEj6u+7+OLIWF55peF4wt8ZP2yYN//97xs+r0gogYhIet19N5x1Vuz98dpAjjsudo/35s3hgAO85Suv9D/mvPO8J8mee67+vscei1w//nhYuxaqqhKL9YUXYh9XpJRARKTw3H9/eq7TubP3SPGaNbGPCXZ6bNUqPfdsQtSILiLSpUvsfW++6b3NUerJaAnEOXeac+4T59wS59z1PvuPd87Nds5VO+d8Ki1FpMm46CKvs+APf5ie6y1a5E1+DeQATz0Ft90Gf/tbaFuwaq1Dh8TvU1bmPVEWLrzBv4hlLIE450qA8cAw4FDgAudc9G/9C+Ay4KlMxSEieaJbN1i61Hu5VDoccog3NWsGEybA7bdH7r/gAq8n+xVXhLZNnAhTpng94Bvj8cdDyxddFPu44cNDy8k80nzggaHl8ASYZzJZAjkCWGJmS81sN/AMENG91cyWm9l8IA0PaItI0Ro7Fn75y4aPa9Uq9DRVIhrq9DhoUOiprHbt6u+fPDm03K1b4vc96ijYtMnrzBmeAPNMJhNIN2BF2HpVYJuISP7q3dsrpSSqa1evz8o770Ruf/fdhs+dPh1+/Wv/fe3bZ64nfppkshHdL3Wn9Ioy59wYYAxAT7/nw0VE0uWzz7z3lcQT7IsyerRXhfaXv9Q/pnXrhu915JHw/vvJx5gnMlkCqQLCe/x0B1alciEze9DMKs2sspNG5RSRTAtWXcV6D3unTrBrF/zkJ7GvEd1xMrwjI8B773nzMWMafrBg0qT4+3MkkwlkBtDHOVfhnGsJjAJeauAcEZHca94cpk6Ff/879jEtWyY3MOQpp4SGYRk4MDT6cOvW8MAD8a91yinePM8SScYSiJlVA1cDrwIfARPNbKFz7lbn3FkAzrnDnXNVwHnAX5xzCzMVj4hIXA89BNddF1ofOhQ6dkzuGn5DqISLlyQGDQotjxsXuW+vvbwSzbnnJhdPhmW0I6GZTQGmRG27KWx5Bl7VlohIbn3/+42/xlNPNb6UMHMmDBnS+FiyQD3RRUQyafTo9Awln4eUQEREMqFvX28efMdJE6TBFEVE0q1lSygtrb892K/D7+muYO/4ZIZZyTElEBGRdGnRwhs+5YMP/Pf37u11OHzggfr77rnHe01wuoZ6yQJnibzkJY9UVlbazJkzcx2GiEhBcc7NMrPKdF5TJRAREUmJEoiIiKRECURERFKiBCIiIilRAhERkZQogYiISEqUQEREJCVKICIikhIlEBERSYkSiIiIpEQJREREUqIEIiIiKVECERGRlBTcaLzOufXA5ymevi/wZRrDyZZCjLsQY4bCjFsxZ08hxh2MeX8z65TOCxdcAmkM59zMdA9nnA2FGHchxgyFGbdizp5CjDuTMasKS0REUqIEIiIiKSm2BPJgrgNIUSHGXYgxQ2HGrZizpxDjzljMRdUGIiIi6VNsJRAREUmTokkgzrnTnHOfOOeWOOeuz4N4ljvn/uucm+ucmxnYto9z7jXn3KeBeYfAduecuzcQ+3zn3OCw61waOP5T59ylGYjzYefcOufcgrBtaYvTOTck8HtYEjjXZSjmW5xzKwO/77nOudPD9v0icP9PnHPfDtvu+5lxzlU45z4I/CzPOudapiHmHs65t5xzHznnFjrnrg1sz9vfdZyY8/13Xeqc+9A5Ny8Q96/j3cs51yqwviSwv1eqP08GYn7UObcs7Hc9MLA9O58PM2vyE1ACfAb0BloC84BDcxzTcmDfqG13AFwtesgAAAYTSURBVNcHlq8Hfh9YPh14GXDAUcAHge37AEsD8w6B5Q5pjvN4YDCwIBNxAh8CRwfOeRkYlqGYbwF+5nPsoYHPQyugIvA5KYn3mQEmAqMCyw8AY9MQczkwOLDcDlgciC1vf9dxYs7337UD2gaWWwAfBH6HvvcCxgEPBJZHAc+m+vNkIOZHgRE+x2fl81EsJZAjgCVmttTMdgPPAGfnOCY/ZwN/Dyz/Hfhu2PbHzDMd2Ns5Vw58G3jNzL4ys6+B14DT0hmQmb0DfJWJOAP72pvZ++Z9gh8Lu1a6Y47lbOAZM9tlZsuAJXifF9/PTOCvspOASYHzw3/+xsS82sxmB5a3AB8B3cjj33WcmGPJl9+1mdnWwGqLwGRx7hX+bzAJODkQW1I/T4ZijiUrn49iSSDdgBVh61XE/6BngwH/ds7Ncs6NCWzrYmarwfvPCXQObI8Vf65+rnTF2S2wHL09U64OFOcfDlYFNRCb3/aOwEYzq85UzIEqkkF4f2UWxO86KmbI89+1c67EOTcXWIf3JfpZnHvVxRfYvykQW1b/X0bHbGbB3/Xtgd/1n5xzraJjTjC2lD4fxZJA/Orycv342TFmNhgYBlzlnDs+zrGx4s+3nyvZOLMZ//3AAcBAYDVwZ2B7XsXsnGsLPA/8yMw2xzs0RhxZj9sn5rz/XZtZjZkNBLrjlRgOiXOvvIg7OmbnXD/gF8DBwOF41VLXZTPmYkkgVUCPsPXuwKocxQKAma0KzNcBL+B9iNcGipIE5usCh8eKP1c/V7rirAosR29POzNbG/gPWAs8hPf7TiXmL/GqA5qnO2bnXAu8L+InzWxyYHNe/679Yi6E33WQmW0EpuK1E8S6V118gf174VWR5uT/ZVjMpwWqEc3MdgGPkPrvOrXPR0ONJE1hAprjNRZVEGrU6pvDeNoA7cKWp+G1XfyByAbTOwLLZxDZIPahhRrEluE1hnUILO+TgXh7EdkgnbY4gRmBY4MNd6dnKObysOUf49VdA/QlsiF0KV4jaMzPDPAckY2t49IQr8Ord747anve/q7jxJzvv+tOwN6B5TLgXeDMWPcCriKyEX1iqj9PBmIuD/u3uBv4XTY/H2n/cszXCe+phMV4dZ035DiW3oEP1TxgYTAevHrVN4BPA/PgP6wDxgdi/y9QGXatK/Aa75YAl2cg1qfxqiH24P2V8r10xglUAgsC59xHoHNrBmJ+PBDTfOAlIr/kbgjc/xPCnjyJ9ZkJ/Pt9GPhZngNapSHmY/GqDOYDcwPT6fn8u44Tc77/rvsDcwLxLQBuincvoDSwviSwv3eqP08GYn4z8LteADxB6EmtrHw+1BNdRERSUixtICIikmZKICIikhIlEBERSYkSiIiIpEQJREREUqIEIkXLOTctMO/lnLswzdf+pd+9RJoSPcYrRc85dwLe6LFnJnFOiZnVxNm/1czapiM+kXylEogULedccHTT3wHHBd6n8OPAoHV/cM7NCAxS98PA8Sc47/0XT+F1zsI594/AgJgLg4NiOud+B5QFrvdk+L0C72n4g3NuQeDdCyPDrj3VOTfJOfexc+7JhN7HIJJDzRs+RKTJu56wEkggEWwys8MDo5v+xzn378CxRwD9zBu+G+AKM/vKOVcGzHDOPW9m1zvnrjZv4Lto5+ANMjgA2DdwzjuBfYPwhsdYBfwHOAZ4L/0/rkh6qAQiUt+pwCWBobM/wBtOpE9g34dhyQPgGufcPGA63iB1fYjvWOBp8wYbXAu8jTeSavDaVeYNQjgXbzwvkbylEohIfQ74HzN7NWKj11ayLWr9FOBoM9vunJuKN25SQ9eOZVfYcg36/yl5TiUQEdiC90rWoFeBsYGhynHOfcM518bnvL2ArwPJ42C8kUyD9gTPj/IOMDLQztIJ7/W7H6blpxDJMv2FI+KNcFodqIp6FLgHr/podqAhez3+r/d8BbjSOTcfbzTW6WH7HgTmO+dmm9nosO0v4L13eh7eSLY/N7M1gQQkUlD0GK+IiKREVVgiIpISJRAREUmJEoiIiKRECURERFKiBCIiIilRAhERkZQogYiISEqUQEREJCX/H9dZyrurmMyWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 100 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()\n",
    "plt.savefig('loss.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 100 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()\n",
    "plt.savefig('accuracy.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "testStrings = '''4092,3677,1\n",
    "4556,4555,1\n",
    "4408,4242,1\n",
    "62210,4133,1\n",
    "4459,84509,1\n",
    "6750,2896,1\n",
    "3942,7158,1\n",
    "3754,65157,1\n",
    "3084,65157,1\n",
    "6985,65157,1\n",
    "3061,65157,1\n",
    "27939,65157,1\n",
    "4139,2915,1\n",
    "3058,2937,1\n",
    "4047,2937,1\n",
    "7335,3010,1\n",
    "3375,9343,1\n",
    "4150,45921,1'''\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "X_test_reverse = []\n",
    "\n",
    "for line in testStrings.splitlines():\n",
    "    word = line.replace(\"\\r\\n\", \"\").split(\",\")\n",
    "    X_test.append([word[0], word[1]])\n",
    "    X_test_reverse.append([word[1], word[0]])\n",
    "    y_test.append(int(word[2]))\n",
    "#     print(word)\n",
    "#     print(vector_model.docvecs[word[0]])\n",
    "#     print(vector_model.docvecs[word[1]])\n",
    "\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['4092', '3677'], ['4556', '4555'], ['4408', '4242'], ['62210', '4133'], ['4459', '84509'], ['6750', '2896'], ['3942', '7158'], ['3754', '65157'], ['3084', '65157'], ['6985', '65157'], ['3061', '65157'], ['27939', '65157'], ['4139', '2915'], ['3058', '2937'], ['4047', '2937'], ['7335', '3010'], ['3375', '9343'], ['4150', '45921']]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7335', '3010']  yes\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for pair in X_test:\n",
    "    if pair in X_train or pair in X_validation:\n",
    "        print(pair, ' yes')\n",
    "        X_test.remove(pair)\n",
    "\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints-cnn/har.ckpt\n",
      "Test accuracy: 0.176471\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "batch_size = len(X_test)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
