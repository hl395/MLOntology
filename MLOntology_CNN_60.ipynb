{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import multiprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['37225000', '52860004', 1], ['159386001', '159385002', 1], ['233836002', '233835003', 1], ['233836002', '304914007', 1], ['224923003', '224717003', 1]]\n",
      "502206\n"
     ]
    }
   ],
   "source": [
    "conceptPairDict={}\n",
    "errors=[]\n",
    "conceptPairList=[]\n",
    "\n",
    "def read_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                conceptPairList.append([splitted[1], splitted[2].replace(\"\\r\\n\", \"\"), 1])\n",
    "#                 conceptPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "pair_file = \"/home/hao/AnacondaProjects/MLOntology/ontHierarchy.txt\"\n",
    "read_pair(pair_file)\n",
    "\n",
    "first2pairs = conceptPairList[10:15]\n",
    "print(first2pairs)\n",
    "print(len(conceptPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['273187009', '272765000', 0], ['272877001', '272765000', 0], ['273216002', '272765000', 0], ['273125004', '272765000', 0], ['272973003', '272765000', 0]]\n",
      "6166563\n"
     ]
    }
   ],
   "source": [
    "conceptNotPairDict={}\n",
    "conceptNotPairList=[]\n",
    "\n",
    "def read_not_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==2:\n",
    "                conceptNotPairList.append([splitted[0], splitted[1].replace(\"\\r\\n\", \"\"), 0])\n",
    "#                 conceptNotPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "notPair_file = \"/home/hao/AnacondaProjects/MLOntology/taxNotPairs.txt\"\n",
    "read_not_pair(notPair_file)\n",
    "\n",
    "# first2pairs = {k: conceptNotPairDict[k] for k in list(conceptNotPairDict)[10:15]}\n",
    "first2pairs =conceptNotPairList[10:15]\n",
    "print(first2pairs)\n",
    "print(len(conceptNotPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('237267007', 0.6275264620780945),\n",
      " ('722912007', 0.6035534143447876),\n",
      " ('446466006', 0.5921777486801147),\n",
      " ('722913002', 0.5906990170478821),\n",
      " ('67798003', 0.5714336037635803),\n",
      " ('253745002', 0.5686008930206299),\n",
      " ('10759661000119108', 0.5671112537384033),\n",
      " ('277485007', 0.5654091835021973),\n",
      " ('177130000', 0.5643329620361328),\n",
      " ('312974005', 0.5596542954444885)]\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/hao/AnacondaProjects/MLOntology/model0\"\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(model.docvecs.most_similar([inferred_vector], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/MLOntology/model1\"\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(model.docvecs.most_similar([inferred_vector], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[360005, 360018, 360048, 360055, 360038, 360094, 360041, 360077, 360080, 360027]\n",
      "[360187, 360101, 360189, 360117, 360186, 360196, 360181, 360114, 360154, 360118]\n",
      "[360273, 360265, 360294, 360205, 360269, 360272, 360287, 360228, 360293, 360270]\n",
      "[360378, 360354, 360388, 360308, 360359, 360362, 360374, 360349, 360309, 360392]\n",
      "[360486, 360415, 360428, 360446, 360444, 360476, 360443, 360426, 360463, 360465]\n",
      "[360590, 360574, 360515, 360581, 360548, 360540, 360566, 360582, 360560, 360547]\n",
      "[360647, 360698, 360683, 360644, 360665, 360670, 360643, 360648, 360696, 360612]\n",
      "[360771, 360737, 360725, 360732, 360700, 360759, 360797, 360749, 360792, 360783]\n",
      "[360856, 360804, 360886, 360885, 360874, 360896, 360894, 360879, 360837, 360820]\n",
      "[360981, 360988, 360987, 360978, 360945, 360966, 360960, 360925, 360914, 360997]\n",
      "[361074, 361012, 361051, 361042, 361078, 361049, 361091, 361089, 361034, 361018]\n",
      "[361107, 361136, 361152, 361122, 361182, 361131, 361142, 361198, 361112, 361177]\n",
      "[361252, 361227, 361213, 361246, 361263, 361280, 361257, 361292, 361273, 361219]\n",
      "[361348, 361386, 361339, 361322, 361392, 361357, 361332, 361347, 361393, 361320]\n",
      "[361444, 361475, 361491, 361454, 361425, 361450, 361451, 361410, 361429, 361449]\n",
      "[361512, 361503, 361535, 361548, 361506, 361589, 361562, 361596, 361579, 361597]\n",
      "[361676, 361618, 361631, 361688, 361619, 361625, 361647, 361652, 361600, 361620]\n",
      "[361765, 361741, 361773, 361778, 361744, 361707, 361739, 361776, 361781, 361760]\n",
      "[361894, 361895, 361867, 361809, 361826, 361857, 361813, 361840, 361883, 361877]\n",
      "[361975, 361902, 361967, 361953, 361928, 361978, 361949, 361906, 361983, 361966]\n",
      "[362083, 362090, 362032, 362013, 362059, 362072, 362005, 362036, 362098, 362028]\n",
      "[362175, 362181, 362183, 362190, 362150, 362141, 362126, 362129, 362113, 362184]\n",
      "[362239, 362298, 362273, 362282, 362233, 362209, 362254, 362271, 362218, 362207]\n",
      "[362320, 362399, 362333, 362347, 362358, 362362, 362306, 362375, 362343, 362319]\n",
      "[362417, 362441, 362485, 362440, 362416, 362452, 362414, 362424, 362467, 362411]\n",
      "[362597, 362547, 362567, 362572, 362535, 362585, 362584, 362581, 362545, 362508]\n",
      "[362611, 362687, 362626, 362683, 362637, 362677, 362691, 362621, 362662, 362601]\n",
      "[362767, 362772, 362716, 362798, 362795, 362786, 362778, 362706, 362713, 362771]\n",
      "[362865, 362898, 362807, 362875, 362821, 362849, 362867, 362800, 362873, 362814]\n",
      "[362955, 362971, 362908, 362953, 362954, 362909, 362948, 362910, 362905, 362947]\n",
      "[363015, 363016, 363074, 363038, 363046, 363025, 363049, 363043, 363093, 363036]\n",
      "[363145, 363157, 363108, 363180, 363120, 363142, 363158, 363168, 363165, 363151]\n",
      "[363251, 363252, 363273, 363286, 363297, 363226, 363274, 363223, 363293, 363289]\n",
      "[363346, 363320, 363388, 363376, 363356, 363303, 363319, 363366, 363333, 363305]\n",
      "[363426, 363439, 363433, 363482, 363421, 363430, 363445, 363466, 363440, 363459]\n",
      "[363562, 363523, 363564, 363596, 363520, 363560, 363593, 363561, 363512, 363581]\n",
      "[363618, 363617, 363656, 363683, 363697, 363685, 363643, 363694, 363652, 363689]\n",
      "[363745, 363752, 363784, 363717, 363760, 363701, 363759, 363703, 363781, 363724]\n",
      "[363811, 363886, 363804, 363853, 363870, 363822, 363859, 363838, 363874, 363818]\n",
      "[363952, 363908, 363956, 363955, 363930, 363978, 363929, 363943, 363982, 363964]\n",
      "[364036, 364035, 364042, 364012, 364009, 364080, 364019, 364055, 364074, 364087]\n",
      "[364101, 364107, 364165, 364129, 364193, 364189, 364100, 364162, 364182, 364179]\n",
      "[364224, 364218, 364208, 364205, 364298, 364212, 364278, 364267, 364248, 364225]\n",
      "[364312, 364375, 364316, 364344, 364394, 364390, 364306, 364334, 364386, 364302]\n",
      "[364467, 364413, 364427, 364480, 364491, 364403, 364407, 364438, 364429, 364470]\n",
      "[364594, 364501, 364511, 364569, 364547, 364561, 364586, 364572, 364525, 364583]\n",
      "[364632, 364661, 364618, 364682, 364609, 364626, 364644, 364629, 364643, 364612]\n",
      "[364786, 364721, 364798, 364712, 364736, 364793, 364735, 364707, 364724, 364791]\n",
      "[364856, 364899, 364853, 364867, 364897, 364862, 364818, 364878, 364864, 364829]\n",
      "[364916, 364942, 364961, 364963, 364931, 364935, 364982, 364910, 364940, 364938]\n",
      "[365063, 365036, 365019, 365095, 365076, 365046, 365011, 365013, 365000, 365089]\n",
      "[365191, 365181, 365128, 365196, 365105, 365168, 365100, 365145, 365117, 365139]\n",
      "[365294, 365281, 365220, 365204, 365205, 365276, 365284, 365242, 365279, 365229]\n",
      "[365326, 365377, 365389, 365361, 365380, 365338, 365300, 365352, 365301, 365398]\n",
      "[365445, 365414, 365492, 365456, 365490, 365483, 365472, 365486, 365437, 365449]\n",
      "[365566, 365536, 365532, 365507, 365540, 365565, 365513, 365533, 365575, 365571]\n",
      "[365604, 365616, 365603, 365611, 365623, 365634, 365627, 365671, 365640, 365695]\n",
      "[365742, 365791, 365720, 365721, 365733, 365707, 365755, 365777, 365731, 365768]\n",
      "[365873, 365869, 365874, 365871, 365850, 365826, 365803, 365840, 365848, 365846]\n",
      "[365937, 365911, 365958, 365977, 365919, 365963, 365921, 365966, 365925, 365907]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "feature_number = 1024\n",
    "\n",
    "train_list_before=[]\n",
    "train_label_list=[]\n",
    "test_list_before=[]\n",
    "test_label_list =[]\n",
    "\n",
    "offset = 6000*60\n",
    "\n",
    "for i in range(60):\n",
    "    index = np.arange(100)     #generate numbers from 0 to 100\n",
    "    np.random.shuffle(index)        #shuffle the 100 values\n",
    "    index = [int(100*i+j + offset) for j in index]\n",
    "    print(index[10:20])\n",
    "    train_list_before.extend([conceptPairList[b] for b in index[0:40]]) \n",
    "    train_label_list.extend([1]*40)\n",
    "    train_list_before.extend([conceptNotPairList[b] for b in index[40:80]])\n",
    "    train_label_list.extend([0]*40)\n",
    "    test_list_before.extend([conceptPairList[b] for b in index[80:90]])\n",
    "    test_label_list.extend([1]*10)\n",
    "    test_list_before.extend([conceptNotPairList[b] for b in index[90:100]])\n",
    "    test_label_list.extend([0]*10)\n",
    "\n",
    "\n",
    "    \n",
    "train_list =[]\n",
    "test_list = []\n",
    "\n",
    "for line in train_list_before:\n",
    "    if line[0] in model.docvecs and line[1] in model.docvecs:\n",
    "        a= model.docvecs[line[0]]\n",
    "        b= model.docvecs[line[1]]\n",
    "        c = np.array((a, b))\n",
    "#         train_list.append(np.reshape(c, feature_number)) \n",
    "        train_list.append(np.reshape(c, feature_number, order='F'))\n",
    "\n",
    "\n",
    "test_list_ids={}\n",
    "for i, line in enumerate(test_list_before):\n",
    "    if line[0] in model.docvecs and line[1] in model.docvecs:\n",
    "        a= model.docvecs[line[0]]\n",
    "        b= model.docvecs[line[1]]\n",
    "        c = np.array((a, b))\n",
    "        test_list_ids[i] = (line[0], line[1])\n",
    "#         test_list.append(np.reshape(c, feature_number))\n",
    "        test_list.append(np.reshape(c, feature_number, order='F'))\n",
    "\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.01495404,  0.11697552, -0.00526454, ...,  0.22887585,\n",
      "       -0.07643021, -0.0583467 ], dtype=float32), array([-0.03035476, -0.02387035,  0.10174327, ...,  0.14418162,\n",
      "       -0.2018003 , -0.20918384], dtype=float32), array([-0.01980258, -0.01445416,  0.03391116, ..., -0.0258652 ,\n",
      "       -0.16861331, -0.19223757], dtype=float32), array([ 0.24361515,  0.40006682,  0.03442254, ...,  0.15849054,\n",
      "       -0.22546507, -0.22112577], dtype=float32), array([ 0.08940571,  0.20546579, -0.02829808, ...,  0.08946983,\n",
      "        0.11687979,  0.28465772], dtype=float32), array([ 0.10073645,  0.07827257, -0.01835088, ..., -0.00761409,\n",
      "       -0.05608595, -0.07972585], dtype=float32), array([ 0.08544349, -0.04785943, -0.07257003, ..., -0.10841242,\n",
      "       -0.01917861, -0.02966822], dtype=float32), array([-0.0378693 , -0.04193522, -0.026775  , ...,  0.03912581,\n",
      "        0.02320253, -0.00913203], dtype=float32), array([-0.08359588, -0.23890819,  0.04127171, ...,  0.24561314,\n",
      "       -0.00101606,  0.15927729], dtype=float32), array([ 0.03025668,  0.054161  ,  0.16147897, ..., -0.06174855,\n",
      "       -0.00990032,  0.04035609], dtype=float32), array([ 0.05758686,  0.10066577,  0.1496879 , ...,  0.01836385,\n",
      "       -0.01787448, -0.07778713], dtype=float32), array([ 0.1122681 ,  0.05960208,  0.13896435, ...,  0.14799228,\n",
      "       -0.15688147,  0.05488754], dtype=float32), array([ 0.06442745,  0.10066577,  0.16172379, ...,  0.01836385,\n",
      "       -0.13854341, -0.07778713], dtype=float32), array([ 0.15343194,  0.19130881,  0.07147412, ...,  0.26466662,\n",
      "       -0.05353092,  0.10966516], dtype=float32), array([ 0.31052968, -0.01472635,  0.03748251, ...,  0.24994515,\n",
      "       -0.3908129 , -0.31709516], dtype=float32), array([ 0.02295997,  0.10066577,  0.16743997, ...,  0.01836385,\n",
      "       -0.02675685, -0.07778713], dtype=float32), array([ 0.37901992, -0.01472635,  0.15361613, ...,  0.24994515,\n",
      "       -0.27972752, -0.31709516], dtype=float32), array([ 0.09600151,  0.05960208, -0.50247651, ...,  0.14799228,\n",
      "        0.0608584 ,  0.05488754], dtype=float32), array([ 0.08410931,  0.10066577,  0.16950575, ...,  0.01836385,\n",
      "        0.01202664, -0.07778713], dtype=float32), array([ 0.08410931,  0.05960208,  0.16950575, ...,  0.14799228,\n",
      "        0.01202664,  0.05488754], dtype=float32)]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "4800\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "print(train_list[30:50])\n",
    "print(train_label_list[30:50])\n",
    "print(len(train_list))\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "[0.96416666666666662]\n"
     ]
    }
   ],
   "source": [
    "#SVM \n",
    "\n",
    "\n",
    "print(len(train_list))\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(train_list, train_label_list)\n",
    "\n",
    "train_errors=[]\n",
    "train_errors.append(clf.score(train_list, train_label_list))\n",
    "print(train_errors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptLabelDict={}\n",
    "errors=[]\n",
    "\n",
    "def read_label(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                conceptLabelDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "label_file = \"/home/hao/AnacondaProjects/MLOntology/ontClassLabels.txt\"\n",
    "read_label(label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 16 predicted label [1], but true label is 0\n",
      "('414366001', '365634009') Concept Pairs: (granulocyte destruction finding --- finding of anticoagulant control)\n",
      "index 17 predicted label [1], but true label is 0\n",
      "('83460007', '365634009') Concept Pairs: (normal megakaryocyte maturation --- finding of anticoagulant control)\n",
      "index 22 predicted label [0], but true label is 1\n",
      "('733867005', '386053000') Concept Pairs: (assessment of knowledge of instructional material --- evaluation procedure)\n",
      "index 49 predicted label [0], but true label is 1\n",
      "('445504001', '363905002') Concept Pairs: (addiction research foundation clinical institute withdrawal assessment for alcohol score --- details of alcohol drinking behavior)\n",
      "index 57 predicted label [1], but true label is 0\n",
      "('36943003', '79524000') Concept Pairs: (making obscene telephone calls --- ecouteurism)\n",
      "index 58 predicted label [1], but true label is 0\n",
      "('115512000', '62978008') Concept Pairs: (diffuse antibody band pattern --- autosensitivity)\n",
      "index 59 predicted label [1], but true label is 0\n",
      "('442243005', '79524000') Concept Pairs: (psychosexual dysfunction associated with inhibited libido --- ecouteurism)\n",
      "index 100 predicted label [0], but true label is 1\n",
      "('702933008', '257585005') Concept Pairs: (orthopedic clinic --- clinic)\n",
      "index 116 predicted label [1], but true label is 0\n",
      "('2506003', '67711008') Concept Pairs: (early onset dysthymia --- primary dysthymia late onset)\n",
      "index 165 predicted label [0], but true label is 1\n",
      "('270390008', '229059009') Concept Pairs: (british association for adoption and fostering adult 1/2 - adoption: applicant report --- report)\n",
      "index 203 predicted label [0], but true label is 1\n",
      "('2571000175108', '129125009') Concept Pairs: (edinburgh postnatal depression scale screening offered --- procedure with explicit context)\n",
      "index 232 predicted label [1], but true label is 0\n",
      "('123813003', '49379003') Concept Pairs: (disorder of strontium metabolism --- disorder of chromium metabolism)\n",
      "index 234 predicted label [1], but true label is 0\n",
      "('30605009', '19527009') Concept Pairs: (major depression in partial remission --- single episode of major depression in full remission)\n",
      "index 290 predicted label [1], but true label is 0\n",
      "('36622002', '191627008') Concept Pairs: (mild mood disorder --- bipolar affective disorder, current episode depression)\n",
      "index 295 predicted label [1], but true label is 0\n",
      "('723912004', '191627008') Concept Pairs: (secondary mood disorder --- bipolar affective disorder, current episode depression)\n",
      "index 300 predicted label [0], but true label is 1\n",
      "('5531000179105', '229059009') Concept Pairs: (nursing report --- report)\n",
      "index 366 predicted label [0], but true label is 1\n",
      "('270391007', '170516003') Concept Pairs: (infectious disease notification --- notification of disease)\n",
      "index 398 predicted label [1], but true label is 0\n",
      "('231537008', '703389002') Concept Pairs: (developmental agnosia --- calcium/calmodulin-dependent serine protein kinase related intellectual disability)\n",
      "index 399 predicted label [1], but true label is 0\n",
      "('429715006', '931004') Concept Pairs: (gestation greater than 20 weeks --- gestation period, 9 weeks)\n",
      "index 401 predicted label [0], but true label is 1\n",
      "('124109002', '129456006') Concept Pairs: (deficiency of aldehyde reductase --- specific enzyme deficiency)\n",
      "index 431 predicted label [1], but true label is 0\n",
      "('86531000119105', '396338004') Concept Pairs: (abnormal lipid deposits --- metachromatic leucodystrophy)\n",
      "index 456 predicted label [1], but true label is 0\n",
      "('87414006', '719593009') Concept Pairs: (reactive depression (situational) --- moderately severe depression)\n",
      "index 495 predicted label [1], but true label is 0\n",
      "('286924000', '91632005') Concept Pairs: (phosphorus and calcium disorders --- hypophosphaturia)\n",
      "index 520 predicted label [0], but true label is 1\n",
      "('371580005', '225400002') Concept Pairs: (assessment of past history --- personal assessment)\n",
      "index 602 predicted label [0], but true label is 1\n",
      "('305519004', '305513003') Concept Pairs: (under care of rehabilitation psychiatrist --- under care of psychiatrist)\n",
      "index 630 predicted label [1], but true label is 0\n",
      "('413231006', '71922006') Concept Pairs: (decreased vascular pattern --- immune defect)\n",
      "index 659 predicted label [1], but true label is 0\n",
      "('312214005', '21542005') Concept Pairs: (floating-harbor syndrome --- behcet's syndrome, neurologic type)\n",
      "index 672 predicted label [1], but true label is 0\n",
      "('117541000119106', '397878005') Concept Pairs: (urinary incontinence due to benign prostatic hypertrophy --- overflow incontinence of urine)\n",
      "index 756 predicted label [1], but true label is 0\n",
      "('198862007', '156073000') Concept Pairs: (readmission for retained products of conception, legal abortion --- complete miscarriage)\n",
      "index 805 predicted label [0], but true label is 1\n",
      "('22925008', '414025005') Concept Pairs: (neonatal disorder --- disorder of fetus or newborn)\n",
      "index 899 predicted label [1], but true label is 0\n",
      "('82991003', '247348008') Concept Pairs: (generalized aches and pains --- tenderness)\n",
      "index 917 predicted label [1], but true label is 0\n",
      "('21243004', '28030000') Concept Pairs: (term birth of newborn --- twin birth)\n",
      "index 919 predicted label [1], but true label is 0\n",
      "('48022009', '106198007') Concept Pairs: (abnormal lymphocyte destruction --- autoimmune and/or graft reaction)\n",
      "index 933 predicted label [1], but true label is 0\n",
      "('213281004', '59455009') Concept Pairs: (ketonemia --- metabolic acidosis)\n",
      "index 937 predicted label [1], but true label is 0\n",
      "('85644003', '426487006') Concept Pairs: (toxic effect of food contaminant --- toxic effect from eating shellfish)\n",
      "index 981 predicted label [0], but true label is 1\n",
      "('408800002', '243826008') Concept Pairs: (antenatal chorionic villus sampling status --- antenatal care status)\n",
      "index 1004 predicted label [0], but true label is 1\n",
      "('62247001', '69280009') Concept Pairs: (family medicine specialist --- specialized physician)\n",
      "index 1027 predicted label [0], but true label is 1\n",
      "('124638000', '129456006') Concept Pairs: (deficiency of carboxy-lyase --- specific enzyme deficiency)\n",
      "index 1047 predicted label [0], but true label is 1\n",
      "('406179007', '225355000') Concept Pairs: (premenstrual syndrome management --- care of patient states)\n",
      "index 1092 predicted label [1], but true label is 0\n",
      "('315018008', '103298005') Concept Pairs: (dizzy spells --- severe vertigo)\n",
      "index 1094 predicted label [1], but true label is 0\n",
      "('407645004', '103298005') Concept Pairs: (dizziness on standing up --- severe vertigo)\n",
      "index 1159 predicted label [1], but true label is 0\n",
      "('1092851000119103', '293382000') Concept Pairs: (complication due to ulcerative colitis --- oral rehydration salts adverse reaction)\n",
      "index 1162 predicted label [0], but true label is 1\n",
      "('26597004', '46557008') Concept Pairs: (enamel hypoplasia --- disorder of hard tissues of teeth)\n",
      "index 1172 predicted label [1], but true label is 0\n",
      "('229667000', '229637006') Concept Pairs: (semantic impairment --- hyperfunctional dysphonia)\n",
      "index 1177 predicted label [1], but true label is 0\n",
      "('229731000', '229637006') Concept Pairs: (receptive language impairment --- hyperfunctional dysphonia)\n",
      "index 1179 predicted label [1], but true label is 0\n",
      "('199330009', '29997008') Concept Pairs: (multiple delivery, all by forceps and vacuum extractor --- premature birth of newborn triplets)\n"
     ]
    }
   ],
   "source": [
    "for i, (item, label) in enumerate(zip(test_list, test_label_list)):\n",
    "    result = clf.predict([item])\n",
    "    if result != label:\n",
    "        print(\"index %d predicted label %s, but true label is %s\" % (i, result, label))\n",
    "        idpair = test_list_ids[i] \n",
    "        concept1 = conceptLabelDict[idpair[0]]\n",
    "        concept2 = conceptLabelDict[idpair[1]]\n",
    "        print(\"%s Concept Pairs: (%s --- %s)\" % (idpair, concept1, concept2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "1200\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# m3 = np.array((a,d))\n",
    "# m3 = np.reshape(m3, 400, order='F')\n",
    "print(len(test_list))\n",
    "result = clf.predict(test_list)\n",
    "\n",
    "print(result.size)\n",
    "\n",
    "\n",
    "print(result[:29])\n",
    "print(np.array(test_label_list[:29]))\n",
    "\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  16   17   22   49   57   58   59  100  116  165  203  232  234  290  295\n",
      "  300  366  398  399  401  431  456  495  520  602  630  659  672  756  805\n",
      "  899  917  919  933  937  981 1004 1027 1047 1092 1094 1159 1162 1172 1177\n",
      " 1179]\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "\n",
    "err_ids=np.flatnonzero(result != test_label_list)\n",
    "\n",
    "print(err_ids)\n",
    "print(err_ids.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961666666667\n",
      "0.950776330076\n",
      "0.961661448364\n",
      "0.961666666667\n",
      "0.96167188497\n",
      "[ 0.96121417  0.96210873]\n",
      "[ 0.95        0.97333333]\n",
      "[ 0.97269625  0.95114007]\n",
      "0.96191815544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "print(accuracy_score(result, test_label_list))\n",
    "print(average_precision_score(result, test_label_list))\n",
    "\n",
    "print(f1_score(result, test_label_list, average='macro') ) \n",
    "\n",
    "print(f1_score(result, test_label_list, average='micro')  )\n",
    "\n",
    "print(f1_score(result, test_label_list, average='weighted') )\n",
    "\n",
    "print(f1_score(result, test_label_list, average=None))\n",
    "\n",
    "print(precision_score(result, test_label_list, average=None))\n",
    "print(recall_score(result, test_label_list, average=None))\n",
    "\n",
    "print(roc_auc_score(result, test_label_list, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label_list_m = np.eye(2)[train_label_list]\n",
    "# test_label_list_m = np.eye(2)[test_label_list]\n",
    "# print(test_label_list_m[10:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 100\n",
      "Train Loss: 0.653943 Acc: [0.52999997]\n",
      "None 200\n",
      "Train Loss: 0.609847 Acc: [0.73000002]\n",
      "None 300\n",
      "Train Loss: 0.5084 Acc: [0.83999997]\n",
      "None 400\n",
      "Train Loss: 0.435324 Acc: [0.81]\n",
      "None 500\n",
      "Train Loss: 0.4085 Acc: [0.80000001]\n",
      "None 600\n",
      "Train Loss: 0.319799 Acc: [0.86000001]\n",
      "None 700\n",
      "Train Loss: 0.282281 Acc: [0.89999998]\n",
      "None 800\n",
      "Train Loss: 0.176231 Acc: [0.94999999]\n",
      "None 900\n",
      "Train Loss: 0.153794 Acc: [0.97000003]\n",
      "None 1000\n",
      "Train Loss: 0.104842 Acc: [0.98000002]\n",
      "None 1100\n",
      "Train Loss: 0.104503 Acc: [0.97000003]\n",
      "None 1200\n",
      "Train Loss: 0.132833 Acc: [0.97000003]\n",
      "None 1300\n",
      "Train Loss: 0.129085 Acc: [0.93000001]\n",
      "None 1400\n",
      "Train Loss: 0.0879828 Acc: [0.95999998]\n",
      "0.966667\n",
      "Model saved in file: ./model-noleaky.ckpt\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "import numpy as np\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "'''\n",
    "In the data, there are 2 classes and every class has 3000 samples and every sample has 512 features\n",
    "The first 3000 samples are from class 0, second 3000 are from class 1\n",
    "'''\n",
    "# DATA_DIR = ''\n",
    "CLASS_NUM = 2       #there are 2 classes\n",
    "SPLIT_PERCENT = 0.8     #split the data into 80% for training and 20% for testing\n",
    "FEATURE_NUM = 1024   \n",
    "TRAIN_ITER = 1500    #the number of iterations for training\n",
    "display_step = 100        #how many iterations to display the results\n",
    "\n",
    "\n",
    "train_num = int(3000*SPLIT_PERCENT)     #the number of samples for training\n",
    "\n",
    "train_feature = train_list      #training features (list of list)\n",
    "train_y = train_label_list        #training lables    (list)\n",
    "test_feature = test_list       #test features  (list of list)\n",
    "test_y = test_label_list         #test labels    (list)\n",
    "\n",
    "\n",
    "y_m = np.eye(2)[train_y]\n",
    "test_y_m = np.eye(2)[test_y]\n",
    "\n",
    "'''\n",
    "y = wx+b        (vectors)\n",
    "'''\n",
    "#function to get variables 'w'\n",
    "def weight_variable(shape, num):\n",
    "    initial = tf.truncated_normal(shape, stddev=1/num)\n",
    "    return tf.Variable(initial, name='weight')\n",
    "\n",
    "#the bias 'b' in the equations\n",
    "def bias_variable(shape, num):\n",
    "    initial = tf.constant(0.0001, shape=shape)\n",
    "    return tf.Variable(initial, name='bias')\n",
    "\n",
    "#convolutional process\n",
    "def conv1d(x, W):\n",
    "    return tf.nn.conv1d(x, W, stride=1, padding='SAME')     #x: variable, w: weight, stride and padding (padding can be ignored currently) \n",
    "\n",
    "#pooling process\n",
    "def max_pool_1x1(x, shape):\n",
    "    x=tf.reshape(x,shape)       #it is transfered into four dimensions, but the other three are 1\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, 4, 1],\n",
    "                        strides=[1, 1, 2, 1], padding='SAME')\n",
    "\n",
    "'''\n",
    "The feature is 3 dimensional data.  [batch, length, channel] \n",
    "batch is usually ignored (for example there are 100 samples in a batch, so samples should not be modified mutually), length and channel are shown in the paper.\n",
    "At first, the length is 512, and channel is 1.\n",
    "Because our data are time series data, so length is enough, but for images, it may be [batch, length, width, channel]\n",
    "'''\n",
    "# the convolutional layer\n",
    "def layer(features, f, input_n, channel, hidden_units, layer_index):\n",
    "    \"\"\"Construct a convolutional layer\n",
    "    Args:\n",
    "    features: Features placeholder, from the previous layer.\n",
    "    f: the length\n",
    "    input_n: Size of the features used in the convention.\n",
    "    hidden_units: Size of the current hidden layer.\n",
    "    layer_index: the index of layer\n",
    "    Returns:\n",
    "    hidden units: The unit output for the next layer.\n",
    "    weights: the weights in the current hidden layer\n",
    "    \"\"\"\n",
    "    # Hidden 1\n",
    "    with tf.name_scope('hidden'+str(layer_index)) as scope:     # name scope may be ignored first\n",
    "        with tf.name_scope(\"weight\"):\n",
    "            weights = weight_variable([input_n, channel, hidden_units], math.sqrt(f))\n",
    "\n",
    "        with tf.name_scope(\"bias\"):\n",
    "            biases = bias_variable([hidden_units], math.sqrt(f))\n",
    "    hidden = relu(conv1d(features, weights) + biases, 0.01)\n",
    "    shape = [-1,1,f,hidden_units]\n",
    "    h_pool1 = max_pool_1x1(hidden,shape)\n",
    "    return h_pool1, weights\n",
    "\n",
    "# fully connected layer, here the data are two dimension, [batch, length]\n",
    "def densely_connect(features, input_n, hidden_units):\n",
    "    \"\"\"Construct a fully (densely) connected layer.\n",
    "    Args:\n",
    "    features: Features placeholder, from the previous layer.\n",
    "    input_n: Size of units in the previous layer.\n",
    "    hidden_units: Size of the current hidden layer.\n",
    "    Returns:\n",
    "    logits: The estimated output in last layer.\n",
    "    weights: the weights in the hidden layer\n",
    "    \"\"\"\n",
    "    with tf.name_scope('softmax_linear') as dense:\n",
    "        with tf.name_scope(\"weight\"):\n",
    "            weights = weight_variable([input_n, hidden_units], math.sqrt(input_n))\n",
    "        with tf.name_scope(\"bias\"):\n",
    "            biases = bias_variable([hidden_units], math.sqrt(input_n))\n",
    "    logits = relu(tf.matmul(features, weights) + biases, 0.01)      # the matrix product operation\n",
    "    return logits, weights\n",
    "\n",
    "# dropout layer (it is not necessary)\n",
    "# randomly set (1-keep_prob) percentage of units to be zero\n",
    "def dropout(features, input_n, hidden_units, keep_prob):\n",
    "    with tf.name_scope('dropout'):\n",
    "        with tf.name_scope(\"weight\"):\n",
    "            weights = weight_variable([input_n, hidden_units], math.sqrt(input_n))\n",
    "        with tf.name_scope(\"bias\"):\n",
    "            biases = bias_variable([hidden_units], math.sqrt(input_n))\n",
    "    h_fc1_drop = tf.nn.dropout(features, keep_prob)\n",
    "    drop_out = relu(tf.matmul(features, weights) + biases, 0.01)\n",
    "    return drop_out\n",
    "\n",
    "# calculate the loss in the neural network\n",
    "def loss(logits, labels):\n",
    "    \"\"\"Calculates the loss from the logits and the labels.\n",
    "    Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int32 - [batch_size, NUM_CLASSES].\n",
    "    Returns:\n",
    "    loss: Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"Loss\"):\n",
    "        labels = tf.to_int64(labels)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=labels, logits=logits, name='xentropy')\n",
    "    # tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "    return tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "\n",
    "def next_batch(data, label, num):\n",
    "    \"\"\"Generate the next batch randomly\n",
    "    Args:\n",
    "    data: training data.\n",
    "    label: training label.\n",
    "    num: the size in a batch\n",
    "    Returns:\n",
    "    next batch's training features and labels.\n",
    "    \"\"\"\n",
    "    index = np.arange(len(data))\n",
    "    np.random.shuffle(index)\n",
    "#     train_feature = data[np.array(index)[0:num]]\n",
    "#     train_label = label[np.array(index)[0:num]]\n",
    "    train_feature_batch = [data[b] for b in index[0:num]]\n",
    "    train_feature_batch = np.asarray(train_feature_batch)\n",
    "    train_label_batch = [label[b] for b in index[0:num]]\n",
    "    train_label_batch = np.asarray(train_label_batch)\n",
    "    return train_feature_batch, train_label_batch\n",
    "\n",
    "def relu(x, alpha=0., max_value=None):\n",
    "    '''ReLU.\n",
    "    alpha: slope of negative section.\n",
    "    '''\n",
    "    negative_part = tf.nn.relu(-x)\n",
    "    x = tf.nn.relu(x)\n",
    "    if max_value is not None:\n",
    "        x = tf.clip_by_value(x, tf.cast(0., dtype=tf.float32),\n",
    "                             tf.cast(max_value, dtype=tf.float32))\n",
    "    x -= tf.constant(alpha, dtype=tf.float32) * negative_part\n",
    "    return x\n",
    "\n",
    "#define a session to run the model\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#place holders for training features and label\n",
    "#None means the value is variable\n",
    "x = tf.placeholder(tf.float32, shape=[None, FEATURE_NUM])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, CLASS_NUM])\n",
    "\n",
    "# decide whether it is training or testing, it is not used in our model, but it may be used\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "#from [-1, 512, 1] -> [-1, 256, 32] -> [-1, 128, 64] -> [-1, 64, 64] -> [-1, 32, 64] -> [-1, 16, 64] -> [-1, 8, 64] -> [-1, 200]\n",
    "\n",
    "#6 hidden layers\n",
    "x_1 = tf.reshape(x, [-1,FEATURE_NUM,1])\n",
    "h_pool0, w0 = layer(x_1, FEATURE_NUM, 15, 1, 32, 0)\n",
    "h_pool0 = tf.reshape(h_pool0, [-1,512,32])\n",
    "h_pool1, w1 = layer(h_pool0, 512, 10, 32, 64, 1)\n",
    "\n",
    "h_pool1 = tf.reshape(h_pool1, [-1,256,64])\n",
    "h_pool2, w2 = layer(h_pool1, 256, 10, 64, 64, 2)\n",
    "h_pool2 = tf.reshape(h_pool2, [-1,128,64])\n",
    "h_pool3, w3 = layer(h_pool2, 128, 10, 64, 64, 3)\n",
    "h_pool3 = tf.reshape(h_pool3, [-1,64,64])\n",
    "h_pool4, w4 = layer(h_pool3, 64, 5, 64, 64, 4)\n",
    "h_pool4 = tf.reshape(h_pool4, [-1,32,64])\n",
    "h_pool5, w5 = layer(h_pool4, 32, 5, 64, 64, 5)\n",
    "h_pool5 = tf.reshape(h_pool5, [-1,16,64])\n",
    "h_pool6, w6 = layer(h_pool5, 16, 5, 64, 64, 6)\n",
    "h_pool6 = tf.reshape(h_pool6, [-1,8,64])\n",
    "\n",
    "#densely connected: 200 units\n",
    "h_pool_flat = tf.reshape(h_pool6, [-1, 8*64])\n",
    "h_dc, w_d = densely_connect(h_pool_flat, 8*64, 200)\n",
    "\n",
    "#dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "y_conv=dropout(h_dc, (int)(h_dc.get_shape()[1]), CLASS_NUM, keep_prob)\n",
    "\n",
    "\n",
    "beta = 0.001\n",
    "cross_entropy = loss(y_conv, y_)\n",
    "loss = cross_entropy +beta*(tf.nn.l2_loss(w0) + tf.nn.l2_loss(w1)+tf.nn.l2_loss(w2)+tf.nn.l2_loss(w3)+tf.nn.l2_loss(w4)+tf.nn.l2_loss(w5)+tf.nn.l2_loss(w6)+tf.nn.l2_loss(w_d))  #L2 regularization\n",
    "epsilon = 1e-5      # learning rate\n",
    "train_step = tf.train.AdamOptimizer(epsilon).minimize(loss)     #optimization function, our goal is to minimize the loss\n",
    "\n",
    "predict = tf.argmax(y_conv,1)   #the predicted class\n",
    "\n",
    "# calculate the accuray, the corrected classified divided by the total size\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "#saver to save the training check point\n",
    "# variables can be restored in a new model by 'saver.restore(sess, save_path)'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())  #initialize the variables\n",
    "\n",
    "\n",
    "for i in range(1,TRAIN_ITER):       #training iterations\n",
    "    d, l = next_batch(train_feature, y_m, 100)      # get 100 samples in one batch\n",
    "#     print(\"d size is %s, l size is %s \"% (len(d), len(l)))\n",
    "#     print(\"d size is %s, l size is %s \"% (len(d[0]), len(l[0])))\n",
    "    _, ls=sess.run([train_step,cross_entropy], feed_dict={x: d, y_: l, keep_prob: 1, is_training:True})     #run the train step (optimization function), the second one is just to show the loss in this iteration.   THE FEED dictionary is to feed the place holders which are needed in the optimization function.\n",
    "    \n",
    "    if i%display_step==0:\n",
    "        print(_, i)\n",
    "        acc = sess.run([accuracy], feed_dict={x: d, y_: l, keep_prob: 1, is_training:False})\n",
    "        print(\"Train Loss:\", ls, \"Acc:\", acc)\n",
    "\n",
    "# sess.run  or tensor.eval are two ways\n",
    "# get the accuracy in the testing data\n",
    "print(accuracy.eval(session=sess, feed_dict={x:test_feature, y_:test_y_m, keep_prob: 1, is_training:False}))\n",
    "\n",
    "\n",
    "# save the model results\n",
    "save_path = saver.save(sess, \"./model-noleaky.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[  22  116  147  203  234  274  290  295  296  398  401  431  458  573  664\n",
      "  735  756  870  871  874  876  904  913  914  917  919  933  937  939  955\n",
      " 1027 1028 1073 1074 1079 1092 1094 1099 1124 1140]\n",
      "40\n",
      "index 22 predicted label 0, but true label is 1\n",
      "('733867005', '386053000') Concept Pairs: (assessment of knowledge of instructional material --- evaluation procedure)\n",
      "index 116 predicted label 1, but true label is 0\n",
      "('2506003', '67711008') Concept Pairs: (early onset dysthymia --- primary dysthymia late onset)\n",
      "index 147 predicted label 0, but true label is 1\n",
      "('428203000', '273249006') Concept Pairs: (berg balance scale --- assessment scales)\n",
      "index 203 predicted label 0, but true label is 1\n",
      "('2571000175108', '129125009') Concept Pairs: (edinburgh postnatal depression scale screening offered --- procedure with explicit context)\n",
      "index 234 predicted label 1, but true label is 0\n",
      "('30605009', '19527009') Concept Pairs: (major depression in partial remission --- single episode of major depression in full remission)\n",
      "index 274 predicted label 1, but true label is 0\n",
      "('715924009', '191627008') Concept Pairs: (disruptive mood dysregulation disorder --- bipolar affective disorder, current episode depression)\n",
      "index 290 predicted label 1, but true label is 0\n",
      "('36622002', '191627008') Concept Pairs: (mild mood disorder --- bipolar affective disorder, current episode depression)\n",
      "index 295 predicted label 1, but true label is 0\n",
      "('723912004', '191627008') Concept Pairs: (secondary mood disorder --- bipolar affective disorder, current episode depression)\n",
      "index 296 predicted label 1, but true label is 0\n",
      "('26516009', '191627008') Concept Pairs: (severe mood disorder with psychotic features --- bipolar affective disorder, current episode depression)\n",
      "index 398 predicted label 1, but true label is 0\n",
      "('231537008', '703389002') Concept Pairs: (developmental agnosia --- calcium/calmodulin-dependent serine protein kinase related intellectual disability)\n",
      "index 401 predicted label 0, but true label is 1\n",
      "('124109002', '129456006') Concept Pairs: (deficiency of aldehyde reductase --- specific enzyme deficiency)\n",
      "index 431 predicted label 1, but true label is 0\n",
      "('86531000119105', '396338004') Concept Pairs: (abnormal lipid deposits --- metachromatic leucodystrophy)\n",
      "index 458 predicted label 1, but true label is 0\n",
      "('243850005', '310372008') Concept Pairs: (child agency involvement status --- immunization invitation status)\n",
      "index 573 predicted label 1, but true label is 0\n",
      "('308031009', '185237002') Concept Pairs: (seen in department --- seen in gastroscopy clinic)\n",
      "index 664 predicted label 0, but true label is 1\n",
      "('7196007', '408739003') Concept Pairs: (suggestive of --- unapproved attribute)\n",
      "index 735 predicted label 1, but true label is 0\n",
      "('170589001', '401253006') Concept Pairs: (no record of blood pressure reading --- coronary heart disease monitoring verbal invitation)\n",
      "index 756 predicted label 1, but true label is 0\n",
      "('198862007', '156073000') Concept Pairs: (readmission for retained products of conception, legal abortion --- complete miscarriage)\n",
      "index 870 predicted label 1, but true label is 0\n",
      "('441877007', '193462001') Concept Pairs: (sleep dysfunction with sleep stage disturbance --- insomnia)\n",
      "index 871 predicted label 1, but true label is 0\n",
      "('442176004', '193462001') Concept Pairs: (sleep dysfunction with arousal disturbance --- insomnia)\n",
      "index 874 predicted label 1, but true label is 0\n",
      "('268654005', '193462001') Concept Pairs: (repetitive intrusions of sleep --- insomnia)\n",
      "index 876 predicted label 1, but true label is 0\n",
      "('4681000119100', '193462001') Concept Pairs: (sleep disturbance in infancy --- insomnia)\n",
      "index 904 predicted label 0, but true label is 1\n",
      "('706608009', '49062001') Concept Pairs: (liner --- device)\n",
      "index 913 predicted label 1, but true label is 0\n",
      "('185212007', '185188008') Concept Pairs: (seen in hospital ward --- seen in family planning clinic)\n",
      "index 914 predicted label 1, but true label is 0\n",
      "('270420001', '185188008') Concept Pairs: (seen in own home --- seen in family planning clinic)\n",
      "index 917 predicted label 1, but true label is 0\n",
      "('21243004', '28030000') Concept Pairs: (term birth of newborn --- twin birth)\n",
      "index 919 predicted label 1, but true label is 0\n",
      "('48022009', '106198007') Concept Pairs: (abnormal lymphocyte destruction --- autoimmune and/or graft reaction)\n",
      "index 933 predicted label 1, but true label is 0\n",
      "('213281004', '59455009') Concept Pairs: (ketonemia --- metabolic acidosis)\n",
      "index 937 predicted label 1, but true label is 0\n",
      "('85644003', '426487006') Concept Pairs: (toxic effect of food contaminant --- toxic effect from eating shellfish)\n",
      "index 939 predicted label 1, but true label is 0\n",
      "('308998002', '308996003') Concept Pairs: (employment medical payment claim status --- seat belt exemption examination payment status)\n",
      "index 955 predicted label 1, but true label is 0\n",
      "('704303006', '390800000') Concept Pairs: (problem with continuity of care --- goal achievement finding)\n",
      "index 1027 predicted label 0, but true label is 1\n",
      "('124638000', '129456006') Concept Pairs: (deficiency of carboxy-lyase --- specific enzyme deficiency)\n",
      "index 1028 predicted label 0, but true label is 1\n",
      "('450744002', '273249006') Concept Pairs: (action for dysphasic adults comprehension battery --- assessment scales)\n",
      "index 1073 predicted label 1, but true label is 0\n",
      "('722187008', '170541005') Concept Pairs: (under immunized --- requires a hepatitis a vaccination)\n",
      "index 1074 predicted label 1, but true label is 0\n",
      "('84618009', '237911005') Concept Pairs: (disorder of propionate and/or methylmalonate metabolism --- disorder of amino acid and organic acid metabolism)\n",
      "index 1079 predicted label 1, but true label is 0\n",
      "('310373003', '170541005') Concept Pairs: (immunization advised --- requires a hepatitis a vaccination)\n",
      "index 1092 predicted label 1, but true label is 0\n",
      "('315018008', '103298005') Concept Pairs: (dizzy spells --- severe vertigo)\n",
      "index 1094 predicted label 1, but true label is 0\n",
      "('407645004', '103298005') Concept Pairs: (dizziness on standing up --- severe vertigo)\n",
      "index 1099 predicted label 1, but true label is 0\n",
      "('185209009', '185270007') Concept Pairs: (seen in recreation place --- seen in oncology clinic)\n",
      "index 1124 predicted label 0, but true label is 1\n",
      "('90035000', '63653004') Concept Pairs: (alcohol sponge, device --- biomedical device)\n",
      "index 1140 predicted label 0, but true label is 1\n",
      "('428724006', '399269003') Concept Pairs: (arthropathy of knee joint --- arthropathy)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = sess.run(predict, feed_dict={x:test_feature, keep_prob:1, is_training:False})\n",
    "print(y_pred[:20])\n",
    "print(test_y[:20])\n",
    "\n",
    "\n",
    "err_ids=np.flatnonzero(y_pred != test_y)\n",
    "\n",
    "print(err_ids)\n",
    "print(err_ids.size)\n",
    "for err_id in err_ids:\n",
    "    print(\"index %d predicted label %s, but true label is %s\" % (err_id, y_pred[err_id], test_y[err_id]))\n",
    "    idpair = test_list_ids[err_id] \n",
    "    concept1 = conceptLabelDict[idpair[0]]\n",
    "    concept2 = conceptLabelDict[idpair[1]]\n",
    "    print(\"%s Concept Pairs: (%s --- %s)\" % (idpair, concept1, concept2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n",
      "0.960752688172\n",
      "0.966657404835\n",
      "0.966666666667\n",
      "0.966675928499\n",
      "[ 0.96610169  0.96721311]\n",
      "[ 0.95        0.98333333]\n",
      "[ 0.98275862  0.9516129 ]\n",
      "0.967185761958\n"
     ]
    }
   ],
   "source": [
    "result = y_pred\n",
    "test_label_list = test_y\n",
    "\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "print(accuracy_score(result, test_label_list))\n",
    "print(average_precision_score(result, test_label_list))\n",
    "\n",
    "print(f1_score(result, test_label_list, average='macro') ) \n",
    "\n",
    "print(f1_score(result, test_label_list, average='micro')  )\n",
    "\n",
    "print(f1_score(result, test_label_list, average='weighted') )\n",
    "\n",
    "print(f1_score(result, test_label_list, average=None))\n",
    "\n",
    "print(precision_score(result, test_label_list, average=None))\n",
    "print(recall_score(result, test_label_list, average=None))\n",
    "\n",
    "print(roc_auc_score(result, test_label_list, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "err_ids=np.flatnonzero(result != test_label_list)\n",
    "\n",
    "print(err_ids)\n",
    "print(err_ids.size)\n",
    "for err_id in err_ids:\n",
    "    idpair = test_list_ids[err_id] \n",
    "    print(idpair)\n",
    "    concept1 = conceptLabelDict[idpair[0]]\n",
    "    concept2 = conceptLabelDict[idpair[1]]\n",
    "    print(\"(Concept 1 %s ---- Concept 2 %s)\" % (concept1, concept2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plist = [[1,2,3], [3,4,5], [3,4,5], [5,6,7],[2,3,7]]\n",
    "\n",
    "plist.extend([1]*4)\n",
    "print(plist)\n",
    "\n",
    "index = np.arange(5)\n",
    "\n",
    "c = [plist[b] for b in index[:2]]\n",
    "print(c)\n",
    "c.extend([plist[b] for b in index[2:]])\n",
    "print(c)\n",
    "\n",
    "for i in range(3):      # i is the class index, for example, i==0 for class 0, i==1 for class 1 ...\n",
    "    index = np.arange(30)     #generate numbers from 0 to 2999\n",
    "    np.random.shuffle(index)        #shuffle the 3000 values\n",
    "    index = [int(300*i+j) for j in index]\n",
    "    print(index)\n",
    "    print(np.array(index)[0:5])\n",
    "    print(np.array(index)[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([1,2,3])\n",
    "y=np.append(y, [1]*4)\n",
    "y= np.append(y, [0])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/MLOntology/model1\"\n",
    "\n",
    "print(path)\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(inferred_vector)\n",
    "print(inferred_vector.size)\n",
    "# pprint(model.docvecs.most_similar([inferred_vector], topn=20))\n",
    "\n",
    "\n",
    "path = \"D:/MLOntology/model0\"\n",
    "\n",
    "print(path)\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(inferred_vector)\n",
    "print(inferred_vector.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.docvecs['SENT_5690']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "print(X)\n",
    "print(y)\n",
    "train_errors=[]\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y)  \n",
    "\n",
    "train_errors.append(clf.score(X, y))\n",
    "print(train_errors)\n",
    "X_test=[[2,2]]\n",
    "y_test = [1]\n",
    "test_errors=[]\n",
    "clf.predict(X_test)\n",
    "\n",
    "test_errors.append(clf.score(X_test, y_test))\n",
    "print(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "a= model.docvecs[0]\n",
    "b= model.docvecs[1]\n",
    "m1 = np.array((a, b))\n",
    "\n",
    "# print(np.reshape(m1, 1024))\n",
    "# print(np.reshape(m1, 400, order='F')) # two ways of reshape\n",
    "\n",
    "c= model.docvecs[2]\n",
    "d= model.docvecs[3]\n",
    "print(c.shape)\n",
    "print(d.shape)\n",
    "print(c.shape[0]+d.shape[0])\n",
    "m2 = np.array((c, d))\n",
    "\n",
    "m1 = np.reshape(m1, 1024)\n",
    "m2 = np.reshape(m2, 1024)\n",
    "# m1 = np.reshape(m1, 1024, order='F')\n",
    "# m2 = np.reshape(m2, 1024, order='F')\n",
    "\n",
    "print(m1)\n",
    "\n",
    "X = [m1, m2]\n",
    "print(X)\n",
    "\n",
    "XX = np.append(m1, m2)\n",
    "print(XX)\n",
    "\n",
    "y = [0, 1]\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X, y)\n",
    "\n",
    "m3 = np.array((a,d))\n",
    "m3 = np.reshape(m3, 1024, order='F')\n",
    "\n",
    "result = clf.predict([m3])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a=  np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "m1 = np.array((a, b))\n",
    "print(m1)\n",
    "\n",
    "m2 = np.vstack((a, b)).T\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDict={}\n",
    "testDict[0] = (\"a\", \"b\")\n",
    "print(testDict[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,1,0,1,0,1,0])\n",
    "b = np.array([0,1,0,1,0,1,1])\n",
    "\n",
    "np.flatnonzero(a!=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
