{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import multiprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['37225000', '52860004', 1], ['159386001', '159385002', 1], ['233836002', '233835003', 1], ['233836002', '304914007', 1], ['224923003', '224717003', 1]]\n",
      "502206\n"
     ]
    }
   ],
   "source": [
    "conceptPairDict={}\n",
    "errors=[]\n",
    "conceptPairList=[]\n",
    "\n",
    "def read_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                conceptPairList.append([splitted[1], splitted[2].replace(\"\\r\\n\", \"\"), 1])\n",
    "#                 conceptPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "pair_file = \"D:/workspace/MLDataProcessing/output/ontHierarchy.txt\"\n",
    "read_pair(pair_file)\n",
    "\n",
    "first2pairs = conceptPairList[10:15]\n",
    "print(first2pairs)\n",
    "print(len(conceptPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['273187009', '272765000', 0], ['272877001', '272765000', 0], ['273216002', '272765000', 0], ['273125004', '272765000', 0], ['272973003', '272765000', 0]]\n",
      "6166563\n"
     ]
    }
   ],
   "source": [
    "conceptNotPairDict={}\n",
    "conceptNotPairList=[]\n",
    "\n",
    "def read_not_pair(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==2:\n",
    "                conceptNotPairList.append([splitted[0], splitted[1].replace(\"\\r\\n\", \"\"), 0])\n",
    "#                 conceptNotPairDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "notPair_file = \"D:/workspace/MLDataProcessing/output/taxNotPairs.txt\"\n",
    "read_not_pair(notPair_file)\n",
    "\n",
    "# first2pairs = {k: conceptNotPairDict[k] for k in list(conceptNotPairDict)[10:15]}\n",
    "first2pairs =conceptNotPairList[10:15]\n",
    "print(first2pairs)\n",
    "print(len(conceptNotPairList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('237267007', 0.5858957767486572),\n",
      " ('722912007', 0.5496571063995361),\n",
      " ('722913002', 0.5403773784637451),\n",
      " ('446466006', 0.5244610905647278),\n",
      " ('10759711000119103', 0.5155006647109985),\n",
      " ('267262008', 0.5105545520782471),\n",
      " ('10759661000119108', 0.5067751407623291),\n",
      " ('177130000', 0.5062116384506226),\n",
      " ('12729009', 0.5006874203681946),\n",
      " ('10759611000119105', 0.5006299018859863)]\n"
     ]
    }
   ],
   "source": [
    "path = \"D:/MLOntology/model0\"\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(model.docvecs.most_similar([inferred_vector], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"D:/MLOntology/model1\"\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(model.docvecs.most_similar([inferred_vector], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18062, 18077, 18054, 18005, 18038, 18095, 18083, 18065, 18034, 18098]\n",
      "[18194, 18123, 18182, 18191, 18149, 18183, 18119, 18129, 18175, 18102]\n",
      "[18278, 18215, 18223, 18296, 18251, 18292, 18235, 18299, 18280, 18255]\n",
      "[18303, 18324, 18369, 18374, 18378, 18396, 18355, 18381, 18333, 18336]\n",
      "[18452, 18497, 18442, 18446, 18480, 18413, 18461, 18432, 18468, 18467]\n",
      "[18558, 18506, 18530, 18599, 18538, 18584, 18559, 18550, 18556, 18501]\n",
      "[18698, 18668, 18682, 18602, 18671, 18622, 18637, 18679, 18651, 18630]\n",
      "[18775, 18751, 18756, 18765, 18738, 18750, 18794, 18732, 18785, 18753]\n",
      "[18888, 18883, 18890, 18894, 18885, 18832, 18814, 18801, 18843, 18840]\n",
      "[18945, 18939, 18992, 18915, 18902, 18938, 18970, 18919, 18916, 18924]\n",
      "[19027, 19041, 19089, 19046, 19088, 19003, 19084, 19052, 19004, 19025]\n",
      "[19147, 19172, 19115, 19120, 19184, 19113, 19189, 19154, 19178, 19139]\n",
      "[19291, 19277, 19212, 19206, 19279, 19251, 19204, 19240, 19234, 19268]\n",
      "[19315, 19379, 19374, 19327, 19393, 19371, 19383, 19368, 19390, 19310]\n",
      "[19460, 19418, 19446, 19465, 19410, 19413, 19438, 19425, 19481, 19485]\n",
      "[19595, 19541, 19547, 19545, 19538, 19550, 19526, 19530, 19508, 19536]\n",
      "[19601, 19682, 19664, 19638, 19605, 19621, 19698, 19648, 19660, 19686]\n",
      "[19739, 19752, 19775, 19770, 19742, 19702, 19701, 19709, 19762, 19705]\n",
      "[19842, 19839, 19830, 19822, 19849, 19883, 19809, 19816, 19853, 19891]\n",
      "[19917, 19933, 19968, 19950, 19943, 19997, 19913, 19995, 19994, 19919]\n",
      "[20018, 20028, 20091, 20061, 20029, 20067, 20023, 20036, 20050, 20081]\n",
      "[20115, 20132, 20182, 20136, 20107, 20140, 20189, 20159, 20183, 20114]\n",
      "[20219, 20249, 20262, 20239, 20292, 20271, 20244, 20250, 20263, 20274]\n",
      "[20341, 20340, 20389, 20369, 20349, 20311, 20304, 20345, 20338, 20393]\n",
      "[20401, 20434, 20417, 20469, 20468, 20483, 20423, 20444, 20451, 20404]\n",
      "[20561, 20582, 20514, 20560, 20508, 20580, 20587, 20583, 20570, 20563]\n",
      "[20693, 20610, 20628, 20618, 20656, 20689, 20695, 20662, 20605, 20694]\n",
      "[20773, 20780, 20789, 20783, 20782, 20778, 20741, 20787, 20772, 20709]\n",
      "[20855, 20841, 20872, 20814, 20817, 20868, 20867, 20847, 20839, 20852]\n",
      "[20966, 20986, 20913, 20914, 20996, 20994, 20955, 20924, 20946, 20965]\n",
      "[21040, 21020, 21074, 21065, 21032, 21097, 21026, 21052, 21034, 21002]\n",
      "[21162, 21149, 21192, 21189, 21103, 21132, 21169, 21173, 21179, 21195]\n",
      "[21282, 21240, 21249, 21212, 21290, 21238, 21289, 21253, 21278, 21246]\n",
      "[21376, 21377, 21362, 21335, 21369, 21387, 21339, 21321, 21371, 21329]\n",
      "[21473, 21467, 21407, 21464, 21409, 21474, 21458, 21472, 21479, 21447]\n",
      "[21546, 21543, 21508, 21557, 21580, 21578, 21569, 21512, 21516, 21502]\n",
      "[21674, 21691, 21659, 21628, 21623, 21643, 21675, 21611, 21646, 21678]\n",
      "[21726, 21712, 21773, 21749, 21752, 21772, 21734, 21797, 21781, 21710]\n",
      "[21842, 21890, 21802, 21814, 21807, 21862, 21859, 21881, 21811, 21803]\n",
      "[21988, 21966, 21985, 21933, 21939, 21903, 21944, 21980, 21977, 21973]\n",
      "[22055, 22013, 22031, 22014, 22071, 22041, 22002, 22001, 22050, 22093]\n",
      "[22124, 22112, 22193, 22199, 22148, 22142, 22126, 22170, 22135, 22187]\n",
      "[22219, 22210, 22298, 22260, 22220, 22289, 22200, 22233, 22257, 22237]\n",
      "[22334, 22387, 22364, 22340, 22353, 22343, 22362, 22346, 22328, 22319]\n",
      "[22417, 22462, 22464, 22488, 22401, 22495, 22479, 22467, 22437, 22430]\n",
      "[22511, 22576, 22559, 22589, 22516, 22598, 22558, 22519, 22561, 22521]\n",
      "[22610, 22686, 22614, 22603, 22612, 22654, 22615, 22662, 22619, 22685]\n",
      "[22779, 22744, 22718, 22730, 22752, 22757, 22766, 22726, 22794, 22789]\n",
      "[22860, 22837, 22893, 22855, 22812, 22852, 22843, 22838, 22818, 22870]\n",
      "[22944, 22910, 22959, 22952, 22992, 22990, 22965, 22972, 22953, 22989]\n",
      "[23049, 23097, 23032, 23077, 23090, 23063, 23025, 23061, 23070, 23017]\n",
      "[23107, 23113, 23120, 23182, 23165, 23106, 23137, 23190, 23185, 23156]\n",
      "[23261, 23293, 23207, 23299, 23208, 23264, 23259, 23233, 23268, 23285]\n",
      "[23378, 23368, 23348, 23321, 23367, 23310, 23338, 23317, 23306, 23335]\n",
      "[23465, 23406, 23407, 23460, 23421, 23423, 23425, 23454, 23499, 23478]\n",
      "[23500, 23509, 23524, 23567, 23502, 23520, 23588, 23550, 23582, 23504]\n",
      "[23617, 23630, 23650, 23631, 23689, 23686, 23601, 23662, 23683, 23633]\n",
      "[23703, 23764, 23721, 23767, 23780, 23752, 23735, 23733, 23779, 23755]\n",
      "[23863, 23881, 23817, 23862, 23839, 23813, 23837, 23856, 23838, 23866]\n",
      "[23966, 23910, 23902, 23919, 23983, 23917, 23905, 23986, 23998, 23920]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "feature_number = 1024\n",
    "\n",
    "train_list_before=[]\n",
    "train_label_list=[]\n",
    "test_list_before=[]\n",
    "test_label_list =[]\n",
    "\n",
    "offset = 6000*3\n",
    "\n",
    "for i in range(60):\n",
    "    index = np.arange(100)     #generate numbers from 0 to 100\n",
    "    np.random.shuffle(index)        #shuffle the 100 values\n",
    "    index = [int(100*i+j + offset) for j in index]\n",
    "    print(index[10:20])\n",
    "    train_list_before.extend([conceptPairList[b] for b in index[0:40]]) \n",
    "    train_label_list.extend([1]*40)\n",
    "    train_list_before.extend([conceptNotPairList[b] for b in index[40:80]])\n",
    "    train_label_list.extend([0]*40)\n",
    "    test_list_before.extend([conceptPairList[b] for b in index[80:90]])\n",
    "    test_label_list.extend([1]*10)\n",
    "    test_list_before.extend([conceptNotPairList[b] for b in index[90:100]])\n",
    "    test_label_list.extend([0]*10)\n",
    "\n",
    "\n",
    "    \n",
    "train_list =[]\n",
    "test_list = []\n",
    "\n",
    "for line in train_list_before:\n",
    "    if line[0] in model.docvecs and line[1] in model.docvecs:\n",
    "        a= model.docvecs[line[0]]\n",
    "        b= model.docvecs[line[1]]\n",
    "        c = np.array((a, b))\n",
    "#         train_list.append(np.reshape(c, feature_number)) \n",
    "        train_list.append(np.reshape(c, feature_number, order='F'))\n",
    "\n",
    "\n",
    "test_list_ids={}\n",
    "for i, line in enumerate(test_list_before):\n",
    "    if line[0] in model.docvecs and line[1] in model.docvecs:\n",
    "        a= model.docvecs[line[0]]\n",
    "        b= model.docvecs[line[1]]\n",
    "        c = np.array((a, b))\n",
    "        test_list_ids[i] = (line[0], line[1])\n",
    "#         test_list.append(np.reshape(c, feature_number))\n",
    "        test_list.append(np.reshape(c, feature_number, order='F'))\n",
    "\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.0659987 , -0.04136264,  0.0937554 , ..., -0.03956329,\n",
      "        0.05491421,  0.23198648], dtype=float32), array([-0.28132483, -0.32863292,  0.08709642, ..., -0.30906415,\n",
      "        0.0025386 ,  0.00081249], dtype=float32), array([-0.02299437, -0.04895541,  0.21812902, ..., -0.01513379,\n",
      "       -0.44944358, -0.44484413], dtype=float32), array([-0.10702286, -0.06982382,  0.12332793, ..., -0.05211287,\n",
      "       -0.01288092,  0.01848223], dtype=float32), array([-0.1260637 ,  0.11563843, -0.09873229, ..., -0.3271832 ,\n",
      "       -0.0586236 , -0.28286082], dtype=float32), array([-0.17743692, -0.07472633, -0.0164775 , ..., -0.14317074,\n",
      "       -0.107453  , -0.25046274], dtype=float32), array([ 0.03789663,  0.02754121,  0.05899603, ..., -0.08793858,\n",
      "       -0.11766901, -0.36573842], dtype=float32), array([-0.01451568, -0.07101998, -0.01741015, ..., -0.12769544,\n",
      "       -0.13964924, -0.21274097], dtype=float32), array([ 0.02638638,  0.05316922,  0.0395142 , ..., -0.08685812,\n",
      "       -0.09979493, -0.08873567], dtype=float32), array([-0.05177172,  0.03732433, -0.16501501, ..., -0.17151158,\n",
      "       -0.02948786, -0.02954718], dtype=float32), array([-0.2376155 ,  0.05083009,  0.49188632, ..., -0.14544162,\n",
      "       -0.1313629 , -0.1690348 ], dtype=float32), array([-0.26956907,  0.05083009,  0.47931507, ..., -0.14544162,\n",
      "       -0.0564019 , -0.1690348 ], dtype=float32), array([-0.1341165 ,  0.05083009,  0.49258688, ..., -0.14544162,\n",
      "        0.00586119, -0.1690348 ], dtype=float32), array([ 0.00589166, -0.08453225, -0.22362691, ..., -0.10653565,\n",
      "        0.21623862, -0.06227746], dtype=float32), array([-0.1979937 ,  0.05083009,  0.3971611 , ..., -0.14544162,\n",
      "       -0.12255853, -0.1690348 ], dtype=float32), array([-0.26594448,  0.05083009,  0.42618504, ..., -0.14544162,\n",
      "       -0.21601021, -0.1690348 ], dtype=float32), array([-0.24149658,  0.05083009,  0.46597478, ..., -0.14544162,\n",
      "        0.02563232, -0.1690348 ], dtype=float32), array([-0.12605345,  0.05083009,  0.41944602, ..., -0.14544162,\n",
      "       -0.0402599 , -0.1690348 ], dtype=float32), array([-0.14739615,  0.06569602, -0.02657075, ...,  0.079776  ,\n",
      "       -0.12632026, -0.24621429], dtype=float32), array([-0.38818341,  0.05083009,  0.31078824, ..., -0.14544162,\n",
      "        0.06683628, -0.1690348 ], dtype=float32)]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "4800\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "print(train_list[30:50])\n",
    "print(train_label_list[30:50])\n",
    "print(len(train_list))\n",
    "print(len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "[0.9402083333333333]\n"
     ]
    }
   ],
   "source": [
    "#SVM \n",
    "\n",
    "\n",
    "print(len(train_list))\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(train_list, train_label_list)\n",
    "\n",
    "train_errors=[]\n",
    "train_errors.append(clf.score(train_list, train_label_list))\n",
    "print(train_errors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conceptLabelDict={}\n",
    "errors=[]\n",
    "\n",
    "def read_label(fname):\n",
    "    with smart_open.smart_open(fname) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            #get the id for each concept paragraph\n",
    "            splitted = line.decode(\"iso-8859-1\").split(\"\\t\")\n",
    "            if len(splitted)==3:\n",
    "                conceptLabelDict[splitted[1]] = splitted[2].replace(\"\\r\\n\", \"\")\n",
    "            else:\n",
    "                errors.append(splitted)\n",
    "\n",
    "label_file = \"D:/MLOntology/ontClassLabels.txt\"\n",
    "read_label(label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 1 predicted label [0], but true label is 1\n",
      "('83382004', '312334008') Concept Pairs: (structure of arcuate artery of leg --- proximal lower limb artery)\n",
      "index 26 predicted label [0], but true label is 1\n",
      "('712532003', '709649008') Concept Pairs: (doppler ultrasonography of iliac vein --- doppler ultrasonography of iliac vessel)\n",
      "index 50 predicted label [1], but true label is 0\n",
      "('308916002', '118956008') Concept Pairs: (environment or geographical location --- body structure, altered from its original anatomical structure)\n",
      "index 52 predicted label [1], but true label is 0\n",
      "('260787004', '118956008') Concept Pairs: (physical object --- body structure, altered from its original anatomical structure)\n",
      "index 83 predicted label [0], but true label is 1\n",
      "('182469000', '228964002') Concept Pairs: (collateral ligament of third metatarsophalangeal joint --- structure of collateral ligaments of metatarsophalangeal joints)\n",
      "index 121 predicted label [0], but true label is 1\n",
      "('7884002', '4421005') Concept Pairs: (structure of corneal corpuscle --- cell structure)\n",
      "index 123 predicted label [0], but true label is 1\n",
      "('86002004', '113345001') Concept Pairs: (structure of lymphatic system of abdomen --- abdominal structure)\n",
      "index 127 predicted label [0], but true label is 1\n",
      "('22040008', '264050007') Concept Pairs: (structure of anterior surface of iris --- iris surface)\n",
      "index 129 predicted label [0], but true label is 1\n",
      "('362306003', '36405008') Concept Pairs: (entire cranial pia mater --- cranial pia mater structure)\n",
      "index 144 predicted label [0], but true label is 1\n",
      "('119557004', '122775001') Concept Pairs: (structure of superficial vein of upper extremity --- structure of vein of upper extremity)\n",
      "index 167 predicted label [0], but true label is 1\n",
      "('181422007', '41216001') Concept Pairs: (entire prostate --- prostatic structure)\n",
      "index 184 predicted label [0], but true label is 1\n",
      "('273178000', '273156007') Concept Pairs: (spinal acupuncture l2 --- spinal acupuncture points)\n",
      "index 204 predicted label [0], but true label is 1\n",
      "('40914000', '7148007') Concept Pairs: (structure of anulus fibrosus of intervertebral disc of ninth thoracic vertebra --- structure of anulus fibrosus of intervertebral disc of thoracic vertebra)\n",
      "index 247 predicted label [0], but true label is 1\n",
      "('272654004', '362898004') Concept Pairs: (entire lobe of right lung --- structure of lobe of right lung)\n",
      "index 261 predicted label [0], but true label is 1\n",
      "('113265005', '369301009') Concept Pairs: (entire left posterior cerebral artery --- structure of left posterior cerebral artery)\n",
      "index 263 predicted label [0], but true label is 1\n",
      "('182470004', '45230000') Concept Pairs: (collateral ligament of fourth metatarsophalangeal joint --- metatarsophalangeal joint structure of fourth toe)\n",
      "index 299 predicted label [1], but true label is 0\n",
      "('450807008', '53418001') Concept Pairs: (entire back --- structure of vertebral region of back)\n",
      "index 300 predicted label [0], but true label is 1\n",
      "('368068001', '29493001') Concept Pairs: (entire placental attachment of umbilical cord --- structure of placental attachment of umbilical cord)\n",
      "index 309 predicted label [0], but true label is 1\n",
      "('77092005', '26489008') Concept Pairs: (bacterial colony surface, rough --- bacterial colony surface appearance)\n",
      "index 313 predicted label [1], but true label is 0\n",
      "('79654002', '125312000') Concept Pairs: (edema --- loculated effusion)\n",
      "index 315 predicted label [1], but true label is 0\n",
      "('384709000', '11607000') Concept Pairs: (sprain --- gunpowder burn)\n",
      "index 316 predicted label [1], but true label is 0\n",
      "('19921004', '11607000') Concept Pairs: (crushing injury --- gunpowder burn)\n",
      "index 319 predicted label [1], but true label is 0\n",
      "('5770003', '11607000') Concept Pairs: (decompression injury --- gunpowder burn)\n",
      "index 321 predicted label [0], but true label is 1\n",
      "('422595006', '368703003') Concept Pairs: (entire deciduous second molar tooth --- entire deciduous molar tooth)\n",
      "index 329 predicted label [0], but true label is 1\n",
      "('400050009', '314932004') Concept Pairs: (benign neoplasm with pilar differentiation --- benign skin appendage tumor morphology)\n",
      "index 340 predicted label [0], but true label is 1\n",
      "('51926005', '362897009') Concept Pairs: (structure of intercalated duct of pancreas --- duct (organ part))\n",
      "index 344 predicted label [0], but true label is 1\n",
      "('305677003', '42424006') Concept Pairs: (entire superior articular process of lumbar vertebra --- entire superior articular process of vertebra)\n",
      "index 360 predicted label [0], but true label is 1\n",
      "('368592000', '89644007') Concept Pairs: (entire left ear --- left ear structure)\n",
      "index 394 predicted label [1], but true label is 0\n",
      "('417609007', '720843009') Concept Pairs: (dermoid tumor --- verruca filiformis)\n",
      "index 406 predicted label [0], but true label is 1\n",
      "('256925006', '62961004') Concept Pairs: (mustache --- structure of hair of face)\n",
      "index 427 predicted label [0], but true label is 1\n",
      "('699956003', '700022004') Concept Pairs: (biceps brachii muscle and/or tendon structure --- muscle and/or tendon structure of upper limb)\n",
      "index 444 predicted label [0], but true label is 1\n",
      "('361777006', '18943002') Concept Pairs: (entire obturator foramen --- obturator foramen structure)\n",
      "index 461 predicted label [0], but true label is 1\n",
      "('279987004', '90887002') Concept Pairs: (entire posterior surface of pancreas --- structure of posterior surface of pancreas)\n",
      "index 462 predicted label [0], but true label is 1\n",
      "('27284009', '425088001') Concept Pairs: (structure of thoracoacromial vein --- structure of tributary of axillary vein)\n",
      "index 508 predicted label [0], but true label is 1\n",
      "('48781005', '119216005') Concept Pairs: (hepatic capsule structure --- liver part)\n",
      "index 520 predicted label [0], but true label is 1\n",
      "('110646006', '116007004') Concept Pairs: (fallopian tubes, ovaries and broad ligaments (combined site) --- combined site)\n",
      "index 527 predicted label [0], but true label is 1\n",
      "('128472006', '8711009') Concept Pairs: (structure of periapical tissue --- periodontal tissues structure)\n",
      "index 531 predicted label [1], but true label is 0\n",
      "('25841003', '115416000') Concept Pairs: (pre-b lymphocyte --- t lymphocyte positive for cd16 antigen and cd57 antigen)\n",
      "index 541 predicted label [0], but true label is 1\n",
      "('728793003', '277926003') Concept Pairs: (entire right surface of heart --- right surface of heart)\n",
      "index 548 predicted label [0], but true label is 1\n",
      "('82858008', '44737009') Concept Pairs: (skin structure of fossa triangularis of ear --- skin structure of pinna)\n",
      "index 587 predicted label [0], but true label is 1\n",
      "('182476005', '34691003') Concept Pairs: (collateral ligament of interphalangeal joint of fourth toe --- structure of collateral ligaments of interphalangeal joints of foot)\n",
      "index 600 predicted label [0], but true label is 1\n",
      "('361776002', '426214007') Concept Pairs: (entire innominate bone --- entire bone organ of pelvis)\n",
      "index 601 predicted label [0], but true label is 1\n",
      "('256924005', '425441005') Concept Pairs: (entire beard --- group of hairs)\n",
      "index 609 predicted label [0], but true label is 1\n",
      "('731414005', '425281001') Concept Pairs: (entire tributary of inferior petrosal sinus --- structure of tributary of inferior petrosal sinus)\n",
      "index 641 predicted label [0], but true label is 1\n",
      "('304629007', '414781009') Concept Pairs: (body orifice mucosa --- mucous membrane structure)\n",
      "index 645 predicted label [0], but true label is 1\n",
      "('68703001', '303295006') Concept Pairs: (choroidal structure --- choroidal and/or retinal structures)\n",
      "index 707 predicted label [0], but true label is 1\n",
      "('272124008', '57661005') Concept Pairs: (entire interstitial tissue of liver --- structure of interstitial tissue of liver)\n",
      "index 745 predicted label [0], but true label is 1\n",
      "('39345001', '81016008') Concept Pairs: (structure of intralaminar part of optic nerve --- optic disc structure)\n",
      "index 806 predicted label [0], but true label is 1\n",
      "('113270003', '7657000') Concept Pairs: (structure of left femoral artery --- structure of femoral artery)\n",
      "index 861 predicted label [0], but true label is 1\n",
      "('87056002', '57222008') Concept Pairs: (infantile diploetic mastoid cell --- structure of mastoid cell)\n",
      "index 869 predicted label [0], but true label is 1\n",
      "('71852002', '74436006') Concept Pairs: (skin structure of medial surface of fourth toe --- skin structure of medial surface of toe)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 883 predicted label [0], but true label is 1\n",
      "('431506006', '79369007') Concept Pairs: (rejection of pancreas transplant --- complication of transplanted pancreas)\n",
      "index 902 predicted label [0], but true label is 1\n",
      "('728791001', '277919003') Concept Pairs: (entire cardiac surface groove --- cardiac surface groove)\n",
      "index 928 predicted label [0], but true label is 1\n",
      "('11558007', '700033001') Concept Pairs: (subcutaneous tissue structure of parietal region --- structure of parietal region of scalp)\n",
      "index 944 predicted label [0], but true label is 1\n",
      "('48259001', '424477009') Concept Pairs: (posterior longitudinal ligament structure --- structure of longitudinal ligament)\n",
      "index 987 predicted label [0], but true label is 1\n",
      "('303058004', '66575002') Concept Pairs: (entire iliopectinate arch of iliac fascia --- structure of iliopectinate arch of iliac fascia)\n",
      "index 1003 predicted label [0], but true label is 1\n",
      "('244863005', '244862000') Concept Pairs: (entire spinalis thoracis muscle --- entire spinalis muscle)\n",
      "index 1020 predicted label [0], but true label is 1\n",
      "('68705008', '424630009') Concept Pairs: (structure of axillary vein --- structure of tributary of subclavian vein)\n",
      "index 1064 predicted label [0], but true label is 1\n",
      "('32530005', '12123001') Concept Pairs: (structure of inferior bulb of internal jugular vein --- internal jugular vein structure)\n",
      "index 1065 predicted label [0], but true label is 1\n",
      "('244339007', '312333002') Concept Pairs: (foot artery --- distal lower limb artery)\n",
      "index 1066 predicted label [0], but true label is 1\n",
      "('261116000', '80830008') Concept Pairs: (entire lateral umbilical fold --- structure of lateral umbilical fold)\n",
      "index 1084 predicted label [0], but true label is 1\n",
      "('181431007', '300443000') Concept Pairs: (entire testis --- entire male genital organ)\n",
      "index 1085 predicted label [0], but true label is 1\n",
      "('182474008', '34691003') Concept Pairs: (collateral ligament of interphalangeal joint of second toe --- structure of collateral ligaments of interphalangeal joints of foot)\n",
      "index 1114 predicted label [1], but true label is 0\n",
      "('41110003', '50537008') Concept Pairs: (blast injury --- laser burn)\n",
      "index 1117 predicted label [1], but true label is 0\n",
      "('708539008', '50537008') Concept Pairs: (concussive injury --- laser burn)\n",
      "index 1124 predicted label [0], but true label is 1\n",
      "('110651000', '116007004') Concept Pairs: (prostate and seminal vesicle (combined site) --- combined site)\n",
      "index 1126 predicted label [0], but true label is 1\n",
      "('41444002', '708041002') Concept Pairs: (invagination --- mechanical lesion)\n",
      "index 1141 predicted label [0], but true label is 1\n",
      "('728255009', '245248007') Concept Pairs: (entire fascia of ring finger --- fascia of ring finger)\n",
      "index 1161 predicted label [0], but true label is 1\n",
      "('272659009', '181338002') Concept Pairs: (gonadal artery --- lateral branch of abdominal aorta)\n",
      "index 1183 predicted label [0], but true label is 1\n",
      "('432045005', '431938005') Concept Pairs: (entire urinary tract proper --- structure of urinary tract proper)\n",
      "index 1185 predicted label [0], but true label is 1\n",
      "('725109000', '312256009') Concept Pairs: (blast cell positive for cd36 antigen --- blast cell)\n"
     ]
    }
   ],
   "source": [
    "for i, (item, label) in enumerate(zip(test_list, test_label_list)):\n",
    "    result = clf.predict([item])\n",
    "    if result != label:\n",
    "        print(\"index %d predicted label %s, but true label is %s\" % (i, result, label))\n",
    "        idpair = test_list_ids[i] \n",
    "        concept1 = conceptLabelDict[idpair[0]]\n",
    "        concept2 = conceptLabelDict[idpair[1]]\n",
    "        print(\"%s Concept Pairs: (%s --- %s)\" % (idpair, concept1, concept2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "1200\n",
      "[1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# m3 = np.array((a,d))\n",
    "# m3 = np.reshape(m3, 400, order='F')\n",
    "print(len(test_list))\n",
    "result = clf.predict(test_list)\n",
    "\n",
    "print(result.size)\n",
    "\n",
    "\n",
    "print(result[:29])\n",
    "print(np.array(test_label_list[:29]))\n",
    "\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   26   50   52   83  121  123  127  129  144  167  184  204  247\n",
      "  261  263  299  300  309  313  315  316  319  321  329  340  344  360\n",
      "  394  406  427  444  461  462  508  520  527  531  541  548  587  600\n",
      "  601  609  641  645  707  745  806  861  869  883  902  928  944  987\n",
      " 1003 1020 1064 1065 1066 1084 1085 1114 1117 1124 1126 1141 1161 1183\n",
      " 1185]\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "err_ids=np.flatnonzero(result != test_label_list)\n",
    "\n",
    "print(err_ids)\n",
    "print(err_ids.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9408333333333333\n",
      "0.8911993345432547\n",
      "0.9407345163706986\n",
      "0.9408333333333333\n",
      "0.940932150295968\n",
      "[0.94315452 0.93831451]\n",
      "[0.98166667 0.9       ]\n",
      "[0.90755008 0.9800363 ]\n",
      "0.9437931873411279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "print(accuracy_score(result, test_label_list))\n",
    "print(average_precision_score(result, test_label_list))\n",
    "\n",
    "print(f1_score(result, test_label_list, average='macro') ) \n",
    "\n",
    "print(f1_score(result, test_label_list, average='micro')  )\n",
    "\n",
    "print(f1_score(result, test_label_list, average='weighted') )\n",
    "\n",
    "print(f1_score(result, test_label_list, average=None))\n",
    "\n",
    "print(precision_score(result, test_label_list, average=None))\n",
    "print(recall_score(result, test_label_list, average=None))\n",
    "\n",
    "print(roc_auc_score(result, test_label_list, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_label_list_m = np.eye(2)[train_label_list]\n",
    "# test_label_list_m = np.eye(2)[test_label_list]\n",
    "# print(test_label_list_m[10:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 100\n",
      "Train Loss: 0.66912645 Acc: [0.78]\n",
      "None 200\n",
      "Train Loss: 0.6264281 Acc: [0.86]\n",
      "None 300\n",
      "Train Loss: 0.57562363 Acc: [0.89]\n",
      "None 400\n",
      "Train Loss: 0.47517997 Acc: [0.87]\n",
      "None 500\n",
      "Train Loss: 0.38947964 Acc: [0.88]\n",
      "None 600\n",
      "Train Loss: 0.2506317 Acc: [0.93]\n",
      "None 700\n",
      "Train Loss: 0.16476612 Acc: [0.98]\n",
      "None 800\n",
      "Train Loss: 0.21596935 Acc: [0.94]\n",
      "None 900\n",
      "Train Loss: 0.1292753 Acc: [0.96]\n",
      "None 1000\n",
      "Train Loss: 0.1517473 Acc: [0.94]\n",
      "None 1100\n",
      "Train Loss: 0.16112703 Acc: [0.96]\n",
      "None 1200\n",
      "Train Loss: 0.123376176 Acc: [0.96]\n",
      "None 1300\n",
      "Train Loss: 0.14793715 Acc: [0.97]\n",
      "None 1400\n",
      "Train Loss: 0.18955512 Acc: [0.91]\n",
      "0.95916665\n",
      "Model saved in file: ./model-noleaky.ckpt\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "import numpy as np\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "'''\n",
    "In the data, there are 2 classes and every class has 3000 samples and every sample has 512 features\n",
    "The first 3000 samples are from class 0, second 3000 are from class 1\n",
    "'''\n",
    "# DATA_DIR = ''\n",
    "CLASS_NUM = 2       #there are 2 classes\n",
    "SPLIT_PERCENT = 0.8     #split the data into 80% for training and 20% for testing\n",
    "FEATURE_NUM = 1024   \n",
    "TRAIN_ITER = 1500    #the number of iterations for training\n",
    "display_step = 100        #how many iterations to display the results\n",
    "\n",
    "\n",
    "train_num = int(3000*SPLIT_PERCENT)     #the number of samples for training\n",
    "\n",
    "train_feature = train_list      #training features (list of list)\n",
    "train_y = train_label_list        #training lables    (list)\n",
    "test_feature = test_list       #test features  (list of list)\n",
    "test_y = test_label_list         #test labels    (list)\n",
    "\n",
    "\n",
    "y_m = np.eye(2)[train_y]\n",
    "test_y_m = np.eye(2)[test_y]\n",
    "\n",
    "'''\n",
    "y = wx+b        (vectors)\n",
    "'''\n",
    "#function to get variables 'w'\n",
    "def weight_variable(shape, num):\n",
    "    initial = tf.truncated_normal(shape, stddev=1/num)\n",
    "    return tf.Variable(initial, name='weight')\n",
    "\n",
    "#the bias 'b' in the equations\n",
    "def bias_variable(shape, num):\n",
    "    initial = tf.constant(0.0001, shape=shape)\n",
    "    return tf.Variable(initial, name='bias')\n",
    "\n",
    "#convolutional process\n",
    "def conv1d(x, W):\n",
    "    return tf.nn.conv1d(x, W, stride=1, padding='SAME')     #x: variable, w: weight, stride and padding (padding can be ignored currently) \n",
    "\n",
    "#pooling process\n",
    "def max_pool_1x1(x, shape):\n",
    "    x=tf.reshape(x,shape)       #it is transfered into four dimensions, but the other three are 1\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, 4, 1],\n",
    "                        strides=[1, 1, 2, 1], padding='SAME')\n",
    "\n",
    "'''\n",
    "The feature is 3 dimensional data.  [batch, length, channel] \n",
    "batch is usually ignored (for example there are 100 samples in a batch, so samples should not be modified mutually), length and channel are shown in the paper.\n",
    "At first, the length is 512, and channel is 1.\n",
    "Because our data are time series data, so length is enough, but for images, it may be [batch, length, width, channel]\n",
    "'''\n",
    "# the convolutional layer\n",
    "def layer(features, f, input_n, channel, hidden_units, layer_index):\n",
    "    \"\"\"Construct a convolutional layer\n",
    "    Args:\n",
    "    features: Features placeholder, from the previous layer.\n",
    "    f: the length\n",
    "    input_n: Size of the features used in the convention.\n",
    "    hidden_units: Size of the current hidden layer.\n",
    "    layer_index: the index of layer\n",
    "    Returns:\n",
    "    hidden units: The unit output for the next layer.\n",
    "    weights: the weights in the current hidden layer\n",
    "    \"\"\"\n",
    "    # Hidden 1\n",
    "    with tf.name_scope('hidden'+str(layer_index)) as scope:     # name scope may be ignored first\n",
    "        with tf.name_scope(\"weight\"):\n",
    "            weights = weight_variable([input_n, channel, hidden_units], math.sqrt(f))\n",
    "\n",
    "        with tf.name_scope(\"bias\"):\n",
    "            biases = bias_variable([hidden_units], math.sqrt(f))\n",
    "    hidden = relu(conv1d(features, weights) + biases, 0.01)\n",
    "    shape = [-1,1,f,hidden_units]\n",
    "    h_pool1 = max_pool_1x1(hidden,shape)\n",
    "    return h_pool1, weights\n",
    "\n",
    "# fully connected layer, here the data are two dimension, [batch, length]\n",
    "def densely_connect(features, input_n, hidden_units):\n",
    "    \"\"\"Construct a fully (densely) connected layer.\n",
    "    Args:\n",
    "    features: Features placeholder, from the previous layer.\n",
    "    input_n: Size of units in the previous layer.\n",
    "    hidden_units: Size of the current hidden layer.\n",
    "    Returns:\n",
    "    logits: The estimated output in last layer.\n",
    "    weights: the weights in the hidden layer\n",
    "    \"\"\"\n",
    "    with tf.name_scope('softmax_linear') as dense:\n",
    "        with tf.name_scope(\"weight\"):\n",
    "            weights = weight_variable([input_n, hidden_units], math.sqrt(input_n))\n",
    "        with tf.name_scope(\"bias\"):\n",
    "            biases = bias_variable([hidden_units], math.sqrt(input_n))\n",
    "    logits = relu(tf.matmul(features, weights) + biases, 0.01)      # the matrix product operation\n",
    "    return logits, weights\n",
    "\n",
    "# dropout layer (it is not necessary)\n",
    "# randomly set (1-keep_prob) percentage of units to be zero\n",
    "def dropout(features, input_n, hidden_units, keep_prob):\n",
    "    with tf.name_scope('dropout'):\n",
    "        with tf.name_scope(\"weight\"):\n",
    "            weights = weight_variable([input_n, hidden_units], math.sqrt(input_n))\n",
    "        with tf.name_scope(\"bias\"):\n",
    "            biases = bias_variable([hidden_units], math.sqrt(input_n))\n",
    "    h_fc1_drop = tf.nn.dropout(features, keep_prob)\n",
    "    drop_out = relu(tf.matmul(features, weights) + biases, 0.01)\n",
    "    return drop_out\n",
    "\n",
    "# calculate the loss in the neural network\n",
    "def loss(logits, labels):\n",
    "    \"\"\"Calculates the loss from the logits and the labels.\n",
    "    Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int32 - [batch_size, NUM_CLASSES].\n",
    "    Returns:\n",
    "    loss: Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"Loss\"):\n",
    "        labels = tf.to_int64(labels)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=labels, logits=logits, name='xentropy')\n",
    "    # tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "    return tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "\n",
    "def next_batch(data, label, num):\n",
    "    \"\"\"Generate the next batch randomly\n",
    "    Args:\n",
    "    data: training data.\n",
    "    label: training label.\n",
    "    num: the size in a batch\n",
    "    Returns:\n",
    "    next batch's training features and labels.\n",
    "    \"\"\"\n",
    "    index = np.arange(len(data))\n",
    "    np.random.shuffle(index)\n",
    "#     train_feature = data[np.array(index)[0:num]]\n",
    "#     train_label = label[np.array(index)[0:num]]\n",
    "    train_feature_batch = [data[b] for b in index[0:num]]\n",
    "    train_feature_batch = np.asarray(train_feature_batch)\n",
    "    train_label_batch = [label[b] for b in index[0:num]]\n",
    "    train_label_batch = np.asarray(train_label_batch)\n",
    "    return train_feature_batch, train_label_batch\n",
    "\n",
    "def relu(x, alpha=0., max_value=None):\n",
    "    '''ReLU.\n",
    "    alpha: slope of negative section.\n",
    "    '''\n",
    "    negative_part = tf.nn.relu(-x)\n",
    "    x = tf.nn.relu(x)\n",
    "    if max_value is not None:\n",
    "        x = tf.clip_by_value(x, tf.cast(0., dtype=tf.float32),\n",
    "                             tf.cast(max_value, dtype=tf.float32))\n",
    "    x -= tf.constant(alpha, dtype=tf.float32) * negative_part\n",
    "    return x\n",
    "\n",
    "#define a session to run the model\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#place holders for training features and label\n",
    "#None means the value is variable\n",
    "x = tf.placeholder(tf.float32, shape=[None, FEATURE_NUM])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, CLASS_NUM])\n",
    "\n",
    "# decide whether it is training or testing, it is not used in our model, but it may be used\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "#from [-1, 512, 1] -> [-1, 256, 32] -> [-1, 128, 64] -> [-1, 64, 64] -> [-1, 32, 64] -> [-1, 16, 64] -> [-1, 8, 64] -> [-1, 200]\n",
    "\n",
    "#6 hidden layers\n",
    "x_1 = tf.reshape(x, [-1,FEATURE_NUM,1])\n",
    "h_pool0, w0 = layer(x_1, FEATURE_NUM, 15, 1, 32, 0)\n",
    "h_pool0 = tf.reshape(h_pool0, [-1,512,32])\n",
    "h_pool1, w1 = layer(h_pool0, 512, 10, 32, 64, 1)\n",
    "\n",
    "h_pool1 = tf.reshape(h_pool1, [-1,256,64])\n",
    "h_pool2, w2 = layer(h_pool1, 256, 10, 64, 64, 2)\n",
    "h_pool2 = tf.reshape(h_pool2, [-1,128,64])\n",
    "h_pool3, w3 = layer(h_pool2, 128, 10, 64, 64, 3)\n",
    "h_pool3 = tf.reshape(h_pool3, [-1,64,64])\n",
    "h_pool4, w4 = layer(h_pool3, 64, 5, 64, 64, 4)\n",
    "h_pool4 = tf.reshape(h_pool4, [-1,32,64])\n",
    "h_pool5, w5 = layer(h_pool4, 32, 5, 64, 64, 5)\n",
    "h_pool5 = tf.reshape(h_pool5, [-1,16,64])\n",
    "h_pool6, w6 = layer(h_pool5, 16, 5, 64, 64, 6)\n",
    "h_pool6 = tf.reshape(h_pool6, [-1,8,64])\n",
    "\n",
    "#densely connected: 200 units\n",
    "h_pool_flat = tf.reshape(h_pool6, [-1, 8*64])\n",
    "h_dc, w_d = densely_connect(h_pool_flat, 8*64, 200)\n",
    "\n",
    "#dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "y_conv=dropout(h_dc, (int)(h_dc.get_shape()[1]), CLASS_NUM, keep_prob)\n",
    "\n",
    "\n",
    "beta = 0.001\n",
    "cross_entropy = loss(y_conv, y_)\n",
    "loss = cross_entropy +beta*(tf.nn.l2_loss(w0) + tf.nn.l2_loss(w1)+tf.nn.l2_loss(w2)+tf.nn.l2_loss(w3)+tf.nn.l2_loss(w4)+tf.nn.l2_loss(w5)+tf.nn.l2_loss(w6)+tf.nn.l2_loss(w_d))  #L2 regularization\n",
    "epsilon = 1e-5      # learning rate\n",
    "train_step = tf.train.AdamOptimizer(epsilon).minimize(loss)     #optimization function, our goal is to minimize the loss\n",
    "\n",
    "predict = tf.argmax(y_conv,1)   #the predicted class\n",
    "\n",
    "# calculate the accuray, the corrected classified divided by the total size\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "#saver to save the training check point\n",
    "# variables can be restored in a new model by 'saver.restore(sess, save_path)'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())  #initialize the variables\n",
    "\n",
    "\n",
    "for i in range(1,TRAIN_ITER):       #training iterations\n",
    "    d, l = next_batch(train_feature, y_m, 100)      # get 100 samples in one batch\n",
    "#     print(\"d size is %s, l size is %s \"% (len(d), len(l)))\n",
    "#     print(\"d size is %s, l size is %s \"% (len(d[0]), len(l[0])))\n",
    "    _, ls=sess.run([train_step,cross_entropy], feed_dict={x: d, y_: l, keep_prob: 1, is_training:True})     #run the train step (optimization function), the second one is just to show the loss in this iteration.   THE FEED dictionary is to feed the place holders which are needed in the optimization function.\n",
    "    \n",
    "    if i%display_step==0:\n",
    "        print(_, i)\n",
    "        acc = sess.run([accuracy], feed_dict={x: d, y_: l, keep_prob: 1, is_training:False})\n",
    "        print(\"Train Loss:\", ls, \"Acc:\", acc)\n",
    "\n",
    "# sess.run  or tensor.eval are two ways\n",
    "# get the accuracy in the testing data\n",
    "print(accuracy.eval(session=sess, feed_dict={x:test_feature, y_:test_y_m, keep_prob: 1, is_training:False}))\n",
    "\n",
    "\n",
    "# save the model results\n",
    "save_path = saver.save(sess, \"./model-noleaky.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[  63  116  146  153  188  212  213  261  280  299  300  359  381  384\n",
      "  444  450  461  466  474  527  538  616  619  622  640  650  666  703\n",
      "  707  731  745  821  838  866  896  899  944  969  987 1021 1036 1039\n",
      " 1053 1064 1093 1100 1125 1178 1182]\n",
      "49\n",
      "index 63 predicted label 0, but true label is 1\n",
      "('74469006', '312918002') Concept Pairs: (hereditary choroidal dystrophy --- choroidal dystrophy)\n",
      "index 116 predicted label 1, but true label is 0\n",
      "('298225002', '71966008') Concept Pairs: (lamina propria mucosae --- subcutaneous tissue structure)\n",
      "index 146 predicted label 0, but true label is 1\n",
      "('360733009', '129456006') Concept Pairs: (deficiency of acetyl-coa hydrolase --- specific enzyme deficiency)\n",
      "index 153 predicted label 1, but true label is 0\n",
      "('718478002', '713765000') Concept Pairs: (anatomy reference area --- cephalometric nasion to pogonion line)\n",
      "index 188 predicted label 0, but true label is 1\n",
      "('712534002', '408767007') Concept Pairs: (assessment of chemical injury --- procedure with a clinical finding focus)\n",
      "index 212 predicted label 1, but true label is 0\n",
      "('726800007', '370085004') Concept Pairs: (entire third of esophagus --- circumferential portion of middle third of esophagus)\n",
      "index 213 predicted label 1, but true label is 0\n",
      "('425441005', '725234006') Concept Pairs: (group of hairs --- population of all spermatozoa with acrosome defects in portion of fluid)\n",
      "index 261 predicted label 0, but true label is 1\n",
      "('113265005', '369301009') Concept Pairs: (entire left posterior cerebral artery --- structure of left posterior cerebral artery)\n",
      "index 280 predicted label 0, but true label is 1\n",
      "('44060006', '62002006') Concept Pairs: (cucurbita lagenaria --- genus cucurbita)\n",
      "index 299 predicted label 1, but true label is 0\n",
      "('450807008', '53418001') Concept Pairs: (entire back --- structure of vertebral region of back)\n",
      "index 300 predicted label 0, but true label is 1\n",
      "('368068001', '29493001') Concept Pairs: (entire placental attachment of umbilical cord --- structure of placental attachment of umbilical cord)\n",
      "index 359 predicted label 1, but true label is 0\n",
      "('280488003', '280497004') Concept Pairs: (primary lower tooth socket --- permanent lower second premolar tooth socket)\n",
      "index 381 predicted label 0, but true label is 1\n",
      "('121657008', '430925007') Concept Pairs: (plutonium measurement --- measurement of substance)\n",
      "index 384 predicted label 0, but true label is 1\n",
      "('721976003', '85995004') Concept Pairs: (lung agenesis with heart defect and thumb anomaly syndrome --- autosomal recessive hereditary disorder)\n",
      "index 444 predicted label 0, but true label is 1\n",
      "('361777006', '18943002') Concept Pairs: (entire obturator foramen --- obturator foramen structure)\n",
      "index 450 predicted label 1, but true label is 0\n",
      "('127918005', '725170002') Concept Pairs: (megakaryocytic cell --- blast cell positive for cd34 antigen)\n",
      "index 461 predicted label 0, but true label is 1\n",
      "('279987004', '90887002') Concept Pairs: (entire posterior surface of pancreas --- structure of posterior surface of pancreas)\n",
      "index 466 predicted label 0, but true label is 1\n",
      "('32527003', '266077001') Concept Pairs: (staphylococcal enterocolitis --- staphylococcal gastrointestinal tract infection)\n",
      "index 474 predicted label 1, but true label is 0\n",
      "('360973009', '420546000') Concept Pairs: (type of bone marrow --- all marrow of a bone)\n",
      "index 527 predicted label 0, but true label is 1\n",
      "('128472006', '8711009') Concept Pairs: (structure of periapical tissue --- periodontal tissues structure)\n",
      "index 538 predicted label 1, but true label is 0\n",
      "('362300009', '180951006') Concept Pairs: (entire cerebral meninges --- middle fossa meninges)\n",
      "index 616 predicted label 1, but true label is 0\n",
      "('731188007', '422905005') Concept Pairs: (entire tributary of right atrium --- structure of tributary of accessory hemiazygous vein)\n",
      "index 619 predicted label 1, but true label is 0\n",
      "('731471008', '281415003') Concept Pairs: (entire shoulder girdle region --- joint structure of shoulder girdle)\n",
      "index 622 predicted label 0, but true label is 1\n",
      "('92296004', '255200003') Concept Pairs: (benign neoplasm of pituitary gland --- benign tumor of hypothalamus)\n",
      "index 640 predicted label 0, but true label is 1\n",
      "('240671002', '33937009') Concept Pairs: (lyme erosive synovitis --- lyme arthritis)\n",
      "index 650 predicted label 1, but true label is 0\n",
      "('361405003', '21241002') Concept Pairs: (nephrogenic cord --- mesonephric structure)\n",
      "index 666 predicted label 0, but true label is 1\n",
      "('38295006', '26472000') Concept Pairs: (involutional paraphrenia --- paraphrenia)\n",
      "index 703 predicted label 0, but true label is 1\n",
      "('720401009', '708164002') Concept Pairs: (cystic fibrosis with gastritis and megaloblastic anemia syndrome --- gastritis caused by helicobacter pylori)\n",
      "index 707 predicted label 0, but true label is 1\n",
      "('272124008', '57661005') Concept Pairs: (entire interstitial tissue of liver --- structure of interstitial tissue of liver)\n",
      "index 731 predicted label 1, but true label is 0\n",
      "('43487005', '7872004') Concept Pairs: (all chambers of the heart --- structure of myocardium of ventricle)\n",
      "index 745 predicted label 0, but true label is 1\n",
      "('39345001', '81016008') Concept Pairs: (structure of intralaminar part of optic nerve --- optic disc structure)\n",
      "index 821 predicted label 0, but true label is 1\n",
      "('78143004', '65801008') Concept Pairs: (open reduction of proximal tibiofibular joint dislocation with excision --- excision)\n",
      "index 838 predicted label 1, but true label is 0\n",
      "('280211001', '280236007') Concept Pairs: (entire maxillary nerve --- palpebral branch of maxillary nerve)\n",
      "index 866 predicted label 0, but true label is 1\n",
      "('249583002', '364181000') Concept Pairs: (position of kidney --- appearance of kidney)\n",
      "index 896 predicted label 1, but true label is 0\n",
      "('362311001', '46538004') Concept Pairs: (entire subarachnoid space --- cisterna superioris)\n",
      "index 899 predicted label 1, but true label is 0\n",
      "('280488003', '280498009') Concept Pairs: (primary lower tooth socket --- permanent lower first premolar tooth socket)\n",
      "index 944 predicted label 0, but true label is 1\n",
      "('48259001', '424477009') Concept Pairs: (posterior longitudinal ligament structure --- structure of longitudinal ligament)\n",
      "index 969 predicted label 0, but true label is 1\n",
      "('121658003', '430925007') Concept Pairs: (polybrominated biphenyl measurement --- measurement of substance)\n",
      "index 987 predicted label 0, but true label is 1\n",
      "('303058004', '66575002') Concept Pairs: (entire iliopectinate arch of iliac fascia --- structure of iliopectinate arch of iliac fascia)\n",
      "index 1021 predicted label 0, but true label is 1\n",
      "('46161009', '56278001') Concept Pairs: (advancement of tendon profundus --- advancement of tendon of hand)\n",
      "index 1036 predicted label 1, but true label is 0\n",
      "('5643001', '68560004') Concept Pairs: (structure of canal of stomach --- gastric corpus structure)\n",
      "index 1039 predicted label 1, but true label is 0\n",
      "('116209005', '68560004') Concept Pairs: (proximal stomach structure --- gastric corpus structure)\n",
      "index 1053 predicted label 1, but true label is 0\n",
      "('361711001', '244199003') Concept Pairs: (entire skin of finger --- nail bed of finger)\n",
      "index 1064 predicted label 0, but true label is 1\n",
      "('32530005', '12123001') Concept Pairs: (structure of inferior bulb of internal jugular vein --- internal jugular vein structure)\n",
      "index 1093 predicted label 1, but true label is 0\n",
      "('368376009', '51520007') Concept Pairs: (structure of tendon of index finger --- entire extensor tendon of finger)\n",
      "index 1100 predicted label 0, but true label is 1\n",
      "('71329008', '175818007') Concept Pairs: (ligation, division and complete stripping of short saphenous veins --- ligation of short saphenous vein)\n",
      "index 1125 predicted label 0, but true label is 1\n",
      "('308835001', '83876008') Concept Pairs: (excision of suprapatellar bursa --- bursectomy)\n",
      "index 1178 predicted label 1, but true label is 0\n",
      "('714631001', '4596009') Concept Pairs: (structure of subregion of neck --- laryngeal structure)\n",
      "index 1182 predicted label 0, but true label is 1\n",
      "('428375006', '416940007') Concept Pairs: (history of placement of stent for coronary artery disease --- past history of procedure)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = sess.run(predict, feed_dict={x:test_feature, keep_prob:1, is_training:False})\n",
    "print(y_pred[:20])\n",
    "print(test_y[:20])\n",
    "\n",
    "\n",
    "err_ids=np.flatnonzero(y_pred != test_y)\n",
    "\n",
    "print(err_ids)\n",
    "print(err_ids.size)\n",
    "for err_id in err_ids:\n",
    "    print(\"index %d predicted label %s, but true label is %s\" % (err_id, y_pred[err_id], test_y[err_id]))\n",
    "    idpair = test_list_ids[err_id] \n",
    "    concept1 = conceptLabelDict[idpair[0]]\n",
    "    concept2 = conceptLabelDict[idpair[1]]\n",
    "    print(\"%s Concept Pairs: (%s --- %s)\" % (idpair, concept1, concept2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9591666666666666\n",
      "0.9370727937043284\n",
      "0.959165277151792\n",
      "0.9591666666666666\n",
      "0.9591680561815413\n",
      "[0.95940348 0.95892707]\n",
      "[0.965      0.95333333]\n",
      "[0.9538715  0.96458685]\n",
      "0.9592291728596392\n"
     ]
    }
   ],
   "source": [
    "result = y_pred\n",
    "test_label_list = test_y\n",
    "\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "print(accuracy_score(result, test_label_list))\n",
    "print(average_precision_score(result, test_label_list))\n",
    "\n",
    "print(f1_score(result, test_label_list, average='macro') ) \n",
    "\n",
    "print(f1_score(result, test_label_list, average='micro')  )\n",
    "\n",
    "print(f1_score(result, test_label_list, average='weighted') )\n",
    "\n",
    "print(f1_score(result, test_label_list, average=None))\n",
    "\n",
    "print(precision_score(result, test_label_list, average=None))\n",
    "print(recall_score(result, test_label_list, average=None))\n",
    "\n",
    "print(roc_auc_score(result, test_label_list, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "err_ids=np.flatnonzero(result != test_label_list)\n",
    "\n",
    "print(err_ids)\n",
    "print(err_ids.size)\n",
    "for err_id in err_ids:\n",
    "    idpair = test_list_ids[err_id] \n",
    "    print(idpair)\n",
    "    concept1 = conceptLabelDict[idpair[0]]\n",
    "    concept2 = conceptLabelDict[idpair[1]]\n",
    "    print(\"(Concept 1 %s ---- Concept 2 %s)\" % (concept1, concept2 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plist = [[1,2,3], [3,4,5], [3,4,5], [5,6,7],[2,3,7]]\n",
    "\n",
    "plist.extend([1]*4)\n",
    "print(plist)\n",
    "\n",
    "index = np.arange(5)\n",
    "\n",
    "c = [plist[b] for b in index[:2]]\n",
    "print(c)\n",
    "c.extend([plist[b] for b in index[2:]])\n",
    "print(c)\n",
    "\n",
    "for i in range(3):      # i is the class index, for example, i==0 for class 0, i==1 for class 1 ...\n",
    "    index = np.arange(30)     #generate numbers from 0 to 2999\n",
    "    np.random.shuffle(index)        #shuffle the 3000 values\n",
    "    index = [int(300*i+j) for j in index]\n",
    "    print(index)\n",
    "    print(np.array(index)[0:5])\n",
    "    print(np.array(index)[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=np.array([1,2,3])\n",
    "y=np.append(y, [1]*4)\n",
    "y= np.append(y, [0])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"D:/MLOntology/model1\"\n",
    "\n",
    "print(path)\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(inferred_vector)\n",
    "print(inferred_vector.size)\n",
    "# pprint(model.docvecs.most_similar([inferred_vector], topn=20))\n",
    "\n",
    "\n",
    "path = \"D:/MLOntology/model0\"\n",
    "\n",
    "print(path)\n",
    "\n",
    "model = gensim.models.Doc2Vec.load(path)\n",
    "inferred_vector = model.infer_vector(['congenital', 'prolong', 'rupture', 'premature', 'membrane', 'lung'])\n",
    "pprint(inferred_vector)\n",
    "print(inferred_vector.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.docvecs['SENT_5690']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "print(X)\n",
    "print(y)\n",
    "train_errors=[]\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y)  \n",
    "\n",
    "train_errors.append(clf.score(X, y))\n",
    "print(train_errors)\n",
    "X_test=[[2,2]]\n",
    "y_test = [1]\n",
    "test_errors=[]\n",
    "clf.predict(X_test)\n",
    "\n",
    "test_errors.append(clf.score(X_test, y_test))\n",
    "print(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "a= model.docvecs[0]\n",
    "b= model.docvecs[1]\n",
    "m1 = np.array((a, b))\n",
    "\n",
    "# print(np.reshape(m1, 1024))\n",
    "# print(np.reshape(m1, 400, order='F')) # two ways of reshape\n",
    "\n",
    "c= model.docvecs[2]\n",
    "d= model.docvecs[3]\n",
    "print(c.shape)\n",
    "print(d.shape)\n",
    "print(c.shape[0]+d.shape[0])\n",
    "m2 = np.array((c, d))\n",
    "\n",
    "m1 = np.reshape(m1, 1024)\n",
    "m2 = np.reshape(m2, 1024)\n",
    "# m1 = np.reshape(m1, 1024, order='F')\n",
    "# m2 = np.reshape(m2, 1024, order='F')\n",
    "\n",
    "print(m1)\n",
    "\n",
    "X = [m1, m2]\n",
    "print(X)\n",
    "\n",
    "XX = np.append(m1, m2)\n",
    "print(XX)\n",
    "\n",
    "y = [0, 1]\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X, y)\n",
    "\n",
    "m3 = np.array((a,d))\n",
    "m3 = np.reshape(m3, 1024, order='F')\n",
    "\n",
    "result = clf.predict([m3])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a=  np.array([1,2,3])\n",
    "b = np.array([4,5,6])\n",
    "m1 = np.array((a, b))\n",
    "print(m1)\n",
    "\n",
    "m2 = np.vstack((a, b)).T\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDict={}\n",
    "testDict[0] = (\"a\", \"b\")\n",
    "print(testDict[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1,1,0,1,0,1,0])\n",
    "b = np.array([0,1,0,1,0,1,1])\n",
    "\n",
    "np.flatnonzero(a!=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
